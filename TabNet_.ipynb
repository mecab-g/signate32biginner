{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e99ea0f-3ced-46f4-a586-e7dfc25a697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch import nn\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "\n",
    "#データ読み込み\n",
    "train = pd.read_csv(\"data_EDA/train.csv\")\n",
    "test = pd.read_csv(\"data_EDA/test.csv\")\n",
    "\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c165e22-292a-4d50-996a-878715efc485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 27 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   index                     3000 non-null   int64  \n",
      " 1   Pregnancies               3000 non-null   int64  \n",
      " 2   Glucose                   3000 non-null   int64  \n",
      " 3   BloodPressure             3000 non-null   int64  \n",
      " 4   SkinThickness             3000 non-null   int64  \n",
      " 5   Insulin                   3000 non-null   int64  \n",
      " 6   BMI                       3000 non-null   float64\n",
      " 7   DiabetesPedigreeFunction  3000 non-null   float64\n",
      " 8   Age                       3000 non-null   int64  \n",
      " 9   Outcome                   3000 non-null   float64\n",
      " 10  BloodPressure_0           2887 non-null   float64\n",
      " 11  SkinThickness_0           1234 non-null   float64\n",
      " 12  Insulin_0                 256 non-null    float64\n",
      " 13  Pregnancies_0             2570 non-null   float64\n",
      " 14  SkinThickness_na          3000 non-null   int64  \n",
      " 15  BloodPressure_na          3000 non-null   int64  \n",
      " 16  Insulin_na                3000 non-null   int64  \n",
      " 17  Pregnancies_na            3000 non-null   int64  \n",
      " 18  Pre/age                   3000 non-null   float64\n",
      " 19  SkinThickness_mean        3000 non-null   float64\n",
      " 20  BloodPressure_mean        3000 non-null   float64\n",
      " 21  Insulin_dpf_mean          3000 non-null   float64\n",
      " 22  Pregnancies_bin           3000 non-null   object \n",
      " 23  Pregnancies_bin_0         3000 non-null   int64  \n",
      " 24  Pregnancies_bin_-1        3000 non-null   int64  \n",
      " 25  Pregnancies_bin_-3        3000 non-null   int64  \n",
      " 26  Pregnancies_bin_3-        3000 non-null   int64  \n",
      "dtypes: float64(11), int64(15), object(1)\n",
      "memory usage: 632.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52b0aeb2-a3f7-4c56-920d-d3d23a6bad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# まずは少ない特徴量から検討していく\n",
    "X_train = train[['DiabetesPedigreeFunction',\n",
    "                 'BMI',\n",
    "                 'Glucose',\n",
    "                 'Age',\n",
    "                 'Pregnancies',\n",
    "                 'SkinThickness',\n",
    "                 'Insulin',\n",
    "                 'BloodPressure',\n",
    "                 'Pre/age',\n",
    "                 \n",
    "                 \n",
    "                \n",
    "             ]]\n",
    "id_train = train[['index']]\n",
    "y_train = train[['Outcome']]\n",
    "\n",
    "\n",
    "X_test = test[X_train.columns]\n",
    "id_test = test[id_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14691ea3-b316-4838-aa02-3fb0fc098a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiabetesPedigreeFunction\n",
      "BMI\n",
      "Glucose\n",
      "Age\n",
      "Pregnancies\n",
      "SkinThickness\n",
      "Insulin\n",
      "BloodPressure\n",
      "Pre/age\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# 数値データ\n",
    "col_num = X_train.columns[X_train.dtypes!='object'].values.tolist()\n",
    "\n",
    "dict_num = {}\n",
    "for col in col_num:\n",
    "    print(col)\n",
    "    # 欠損値を0へ\n",
    "    value_fillna = 0 \n",
    "    X_train[col] = X_train[col].fillna(value_fillna)\n",
    "    # 正規化\n",
    "    value_min = X_train[col].min()\n",
    "    value_max = X_train[col].max()\n",
    "    value_mean = X_train[col].mean()\n",
    "    value_std = X_train[col].std()\n",
    "    # X_train[col] = (X_train[col] - value_min) / (value_max -value_min)\n",
    "    X_train[col] = (X_train[col] - value_mean) / value_std\n",
    "    \n",
    "    dict_num[col] = {}\n",
    "    dict_num[col]['fillna'] = value_fillna\n",
    "    dict_num[col]['min'] = value_min\n",
    "    dict_num[col]['max'] = value_max\n",
    "    dict_num[col]['mean'] = value_max    \n",
    "    dict_num[col]['std'] = value_max    \n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4775291d-8632-4bb6-b029-b4edbde59d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# カテゴリデータ\n",
    "col_cat = X_train.columns[X_train.dtypes=='object'].values.tolist()\n",
    "\n",
    "dict_cat = {}\n",
    "for col in col_cat:\n",
    "    print(col)\n",
    "    value_fillna = 'unknown'\n",
    "    X_train[col] = X_train[cal].fillna(value_fillna)\n",
    "    \n",
    "    X_train[caol] = X_train[col].astype(str)\n",
    "    # 整数に変換\n",
    "    le = LabelEncorder()\n",
    "    le.fit(X_train[col])\n",
    "    list_labelsorted(list(set(le.classes_) | set(['unknown'])))\n",
    "    map_label = {j:i for i,j in enumerate(list_label)}\n",
    "    X_train[col] = X_train[col].map(map_label)\n",
    "    \n",
    "    dict_cat[col] = {}\n",
    "    dict_cat[col]['fillna'] = value_fillna\n",
    "    dict_cat[col]['map_label'] = map_label\n",
    "    dict_cat[col]['num_label'] = len(list_label)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "874665d8-fb87-41e6-a83c-4047e4218092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(input_x):\n",
    "    output_x = input_x.copy()\n",
    "    \n",
    "    for col in col_num:\n",
    "        value_fillna = dict_num[col]['fillna']\n",
    "        output_x[col] = output_x[col].fillna(value_fillna)\n",
    "        \n",
    "        value_min = dict_num[col]['min']\n",
    "        value_max = dict_num[col]['max']\n",
    "        value_mean = dict_num[col]['mean']\n",
    "        value_std = dict_num[col]['std']\n",
    "        \n",
    "        # output_x[col]  = (output_x[col] - value_min ) / (value_max - value_min)\n",
    "        output_x[col]  = (output_x[col] - value_mean ) / value_std\n",
    "        \n",
    "        \n",
    "    for col in col_cat:\n",
    "        value_fillna = dict_cat[col]['fillna']\n",
    "        output_x[col] = output_x[col].fillna(value_fillna)\n",
    "        \n",
    "        output_x[col] = output_x[col].astype(str)\n",
    "        \n",
    "        map_label = dict_catt[col]['map_label']\n",
    "        output_x[col] = output_x[col].map(map_label)\n",
    "        \n",
    "        #対応するものがない場合はunkoumn\n",
    "        output_x[col] = output_x[col].fillna(map_label['unknown'])\n",
    "        \n",
    "    return output_x\n",
    "\n",
    "\n",
    "X_test = transform_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ca0a12f-adda-464e-883a-e894ea811394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   DiabetesPedigreeFunction  3000 non-null   float64\n",
      " 1   BMI                       3000 non-null   float64\n",
      " 2   Glucose                   3000 non-null   float64\n",
      " 3   Age                       3000 non-null   float64\n",
      " 4   Pregnancies               3000 non-null   float64\n",
      " 5   SkinThickness             3000 non-null   float64\n",
      " 6   Insulin                   3000 non-null   float64\n",
      " 7   BloodPressure             3000 non-null   float64\n",
      " 8   Pre/age                   3000 non-null   float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 211.1 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aef527-11fa-4c91-9ae5-d7e2ce47a210",
   "metadata": {},
   "source": [
    "## validation方法（ベースライン作成へ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aceea77a-bb08-4591-a561-dd086bc8eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 123\n",
    "params = {'n_d': 47, #値が大きいほど表現力と過学習のリスクがあがる\n",
    "          'n_a': 24, # n_dと同じ値にしておくのが良いらしい\n",
    "          'n_steps': 3,#TabNetEncoderのstepを何回繰り返すか\n",
    "          'gamma': 1.3,\n",
    "          'n_independent': 2,\n",
    "          'n_shared': 2,\n",
    "          'seed':random_state,\n",
    "          'lambda_sparse': 1e-3,\n",
    "          'optimizer_fn': torch.optim.Adam, \n",
    "          'optimizer_params': {'lr':2e-2},\n",
    "          'mask_type': \"entmax\",#AttentiveTransformerでマスク作るのにどっちの関数を使うか'sparsemax'or'entmax'\n",
    "          'scheduler_params':{'mode': \"min\",'patience': 5,'min_lr': 1e-5,'factor': 0.9},\n",
    "          'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "          'verbose':10\n",
    "         }\n",
    "#https://zenn.dev/nishimoto/articles/f2af21c24413d3\n",
    "#https://www.guruguru.science/competitions/16/discussions/70f25f95-4dcc-4733-9f9e-f7bc6472d7c0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43777692-d1d6-45ed-b5ae-e6c75760d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#不均衡データ用の重み\n",
    "class_weights = list(class_weight.compute_class_weight('balanced', \n",
    "                                                           classes=np.unique(y_train['Outcome']),\n",
    "                                                           y=y_train['Outcome'])\n",
    "                        )\n",
    "weights = torch.from_numpy(np.array(class_weights)).float()\n",
    "\n",
    "# lossを指定し重みを加える 重み無しならLossはNone\n",
    "cross_entropy_loss_wight = CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067feb6e-739a-471e-a6f4-5352e438b7ec",
   "metadata": {},
   "source": [
    "{'n_d': 47,\n",
    " 'n_a': 24,\n",
    " 'n_steps': 3,\n",
    " 'gamma': 1.5513147690828912,\n",
    " 'mask_type': 'entmax',\n",
    " 'optimizer_fn': torch.optim.adam.Adam,\n",
    " 'optimizer_params': {'lr': 0.02, 'weight_decay': 1e-05},\n",
    " 'scheduler_params': {'mode': 'min',\n",
    "  'patience': 5,\n",
    "  'min_lr': 1e-05,\n",
    "  'factor': 0.9,\n",
    "  'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau},\n",
    " 'verbose': 10,\n",
    " 'seed': 123}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6fb4ecee-6785-4fe1-acd8-a25d08168bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvでの評価用\n",
    "def train_tabnet(input_x,\n",
    "              input_y,\n",
    "              input_id,\n",
    "              params,\n",
    "              list_nfold=[0,1,2,3,4],\n",
    "              n_splits=5,\n",
    "              random_state=123\n",
    "            ):\n",
    "    train_oof = np.zeros(len(input_x))\n",
    "    # foldごとの推論値\n",
    "    metrics = []\n",
    "    imp = pd.DataFrame()\n",
    "                         \n",
    "    cv = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state).\n",
    "              split(input_x, input_y))\n",
    "    \n",
    "    for nfold in list_nfold:\n",
    "        print('-'*20, nfold, '-'*20)\n",
    "        \n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = input_x.loc[idx_tr, :], input_y.loc[idx_tr, :]\n",
    "        x_va, y_va = input_x.loc[idx_va, :], input_y.loc[idx_va, :]\n",
    "        print(x_tr.shape, y_tr.shape)\n",
    "        print(x_va.shape, y_va.shape)\n",
    "        print('y_train:{:.3f}, y_tr:{:.3f}, y_va{:.3f}'.\n",
    "              format(y_train['Outcome'].mean(), y_tr['Outcome'].mean(), y_va['Outcome'].mean(),))\n",
    "        \n",
    "        y_tr=np.squeeze(y_tr.values)\n",
    "        y_va=np.squeeze(y_va.values)\n",
    "        x_tr=x_tr.values\n",
    "        x_va=x_va.values\n",
    "        \n",
    "        print('-'*20, 'pretraining', '-'*20)\n",
    "        \n",
    "        pretrainer = TabNetPretrainer(**params)\n",
    "        pretrainer.fit(\n",
    "            X_train=x_tr,\n",
    "            eval_set=[x_va],\n",
    "            max_epochs=200,\n",
    "            patience=20, batch_size=256, virtual_batch_size=128,\n",
    "            num_workers=1, drop_last=True)\n",
    "        print('-'*20, 'maintraining', '-'*20)\n",
    "        \n",
    "        model = TabNetClassifier(**params)\n",
    "        model.fit(\n",
    "            X_train=x_tr,\n",
    "            y_train=y_tr,\n",
    "            eval_set=[(x_va, y_va)],\n",
    "            eval_name = [\"valid\"],\n",
    "            eval_metric = [\"auc\"],\n",
    "            loss_fn = cross_entropy_loss_wight,\n",
    "            max_epochs=200,\n",
    "            patience=20, \n",
    "            batch_size=256,\n",
    "            virtual_batch_size=128,\n",
    "            num_workers=0, \n",
    "            drop_last=False,\n",
    "            from_unsupervised=pretrainer\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # モデルの保存\n",
    "        fname_tabnet = 'model/tabnet/model_tabnet_fold{}.pickle'.format(nfold)\n",
    "        with open(fname_tabnet, 'wb')as f:\n",
    "            pickle.dump(model, f, protocol=4)\n",
    "            \n",
    "            \n",
    "        # 評価\n",
    "        y_tr_pred = model.predict_proba(x_tr)[:,1]\n",
    "        y_va_pred = model.predict_proba(x_va)[:,1]\n",
    "        \n",
    "        metric_tr = accuracy_score(y_tr, np.where(y_tr_pred>=0.5,1,0))\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>=0.5,1,0))\n",
    "        print('[accuracy] tr: {:.2f}, va: {:2f}'.\n",
    "             format(metric_tr, metric_va))\n",
    "        metrics.append([nfold, metric_tr, metric_va])\n",
    "        \n",
    "        # oof\n",
    "        train_oof[idx_va] = y_va_pred\n",
    "        \n",
    "         # imp\n",
    "        _imp = pd.DataFrame({'col':input_x.columns, 'imp':model.feature_importances_,'nfold':nfold})\n",
    "        imp = pd.concat([imp, _imp], axis=0, ignore_index=False)\n",
    "        \n",
    "        \n",
    "        print('-'*20, 'result', '-'*20)\n",
    "    \n",
    "    # metrix出力\n",
    "    metrics = np.array(metrics)\n",
    "    print(metrics)\n",
    "    print('[cv] tr: {:.2f}+-{:.2f}, va: {:.2f}'.format(\n",
    "        metrics[:,1].mean(), metrics[:,1].std(),\n",
    "        metrics[:,2].mean(), metrics[:,2].std()\n",
    "    ))\n",
    "    print('[oof] {:.4f}'.format(\n",
    "        accuracy_score(input_y, np.where(train_oof>=0.5,1,0))))\n",
    "    # oof出力  \n",
    "    train_oof = pd.concat([\n",
    "        input_id,\n",
    "        pd.DataFrame({'pred':train_oof})]\n",
    "        ,axis=1)\n",
    "    \n",
    "        # imp出力\n",
    "    imp = imp.groupby('col')['imp'].agg(['mean', 'std']).reset_index(drop=False)\n",
    "    imp.columns = ['col', 'imp', 'imp_std']\n",
    "\n",
    "    print('Done')\n",
    "    \n",
    "    return train_oof, imp, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec383631-7376-4685-9de1-83c4d88a1aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "(2400, 9) (2400, 1)\n",
      "(600, 9) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.240\n",
      "-------------------- pretraining --------------------\n",
      "epoch 0  | loss: 5.12427 | val_0_unsup_loss_numpy: 200.7672576904297|  0:00:00s\n",
      "epoch 10 | loss: 0.88773 | val_0_unsup_loss_numpy: 0.9824399948120117|  0:00:02s\n",
      "epoch 20 | loss: 0.86174 | val_0_unsup_loss_numpy: 0.925059974193573|  0:00:04s\n",
      "epoch 30 | loss: 0.87789 | val_0_unsup_loss_numpy: 0.9203299880027771|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 19 and best_val_0_unsup_loss_numpy = 0.8729100227355957\n",
      "-------------------- maintraining --------------------\n",
      "epoch 0  | loss: 1.16782 | valid_auc: 0.70459 |  0:00:00s\n",
      "epoch 10 | loss: 0.58975 | valid_auc: 0.75181 |  0:00:01s\n",
      "epoch 20 | loss: 0.54969 | valid_auc: 0.76942 |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_valid_auc = 0.79624\n",
      "[accuracy] tr: 0.72, va: 0.745000\n",
      "-------------------- result --------------------\n",
      "-------------------- 1 --------------------\n",
      "(2400, 9) (2400, 1)\n",
      "(600, 9) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.240\n",
      "-------------------- pretraining --------------------\n",
      "epoch 0  | loss: 4.52123 | val_0_unsup_loss_numpy: 69.87307739257812|  0:00:00s\n",
      "epoch 10 | loss: 0.89927 | val_0_unsup_loss_numpy: 0.9183800220489502|  0:00:02s\n",
      "epoch 20 | loss: 0.89211 | val_0_unsup_loss_numpy: 0.8816699981689453|  0:00:04s\n",
      "epoch 30 | loss: 0.86487 | val_0_unsup_loss_numpy: 0.8585900068283081|  0:00:07s\n",
      "epoch 40 | loss: 0.84393 | val_0_unsup_loss_numpy: 0.8809999823570251|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_unsup_loss_numpy = 0.8331199884414673\n",
      "-------------------- maintraining --------------------\n",
      "epoch 0  | loss: 1.15678 | valid_auc: 0.71178 |  0:00:00s\n",
      "epoch 10 | loss: 0.5795  | valid_auc: 0.74609 |  0:00:01s\n",
      "epoch 20 | loss: 0.55922 | valid_auc: 0.77004 |  0:00:02s\n",
      "epoch 30 | loss: 0.52287 | valid_auc: 0.7858  |  0:00:04s\n",
      "epoch 40 | loss: 0.50361 | valid_auc: 0.76748 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 29 and best_valid_auc = 0.79059\n",
      "[accuracy] tr: 0.76, va: 0.708333\n",
      "-------------------- result --------------------\n",
      "-------------------- 2 --------------------\n",
      "(2400, 9) (2400, 1)\n",
      "(600, 9) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.238\n",
      "-------------------- pretraining --------------------\n",
      "epoch 0  | loss: 4.51803 | val_0_unsup_loss_numpy: 125.8973617553711|  0:00:00s\n",
      "epoch 10 | loss: 0.94756 | val_0_unsup_loss_numpy: 0.972000002861023|  0:00:02s\n",
      "epoch 20 | loss: 0.85526 | val_0_unsup_loss_numpy: 0.9301499724388123|  0:00:04s\n",
      "epoch 30 | loss: 0.85059 | val_0_unsup_loss_numpy: 0.8865600228309631|  0:00:07s\n",
      "epoch 40 | loss: 0.82138 | val_0_unsup_loss_numpy: 0.832830011844635|  0:00:09s\n",
      "epoch 50 | loss: 0.85255 | val_0_unsup_loss_numpy: 0.8431199789047241|  0:00:11s\n",
      "epoch 60 | loss: 0.84369 | val_0_unsup_loss_numpy: 0.8416100144386292|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 0.8092600107192993\n",
      "-------------------- maintraining --------------------\n",
      "epoch 0  | loss: 1.16552 | valid_auc: 0.64313 |  0:00:00s\n",
      "epoch 10 | loss: 0.55381 | valid_auc: 0.68834 |  0:00:01s\n",
      "epoch 20 | loss: 0.53664 | valid_auc: 0.7117  |  0:00:02s\n",
      "epoch 30 | loss: 0.51528 | valid_auc: 0.69454 |  0:00:04s\n",
      "epoch 40 | loss: 0.48618 | valid_auc: 0.72066 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 29 and best_valid_auc = 0.73021\n",
      "[accuracy] tr: 0.72, va: 0.673333\n",
      "-------------------- result --------------------\n",
      "-------------------- 3 --------------------\n",
      "(2400, 9) (2400, 1)\n",
      "(600, 9) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.238\n",
      "-------------------- pretraining --------------------\n",
      "epoch 0  | loss: 4.88033 | val_0_unsup_loss_numpy: 94.99549865722656|  0:00:00s\n",
      "epoch 10 | loss: 0.88975 | val_0_unsup_loss_numpy: 1.1946799755096436|  0:00:02s\n",
      "epoch 20 | loss: 0.8524  | val_0_unsup_loss_numpy: 0.9800900220870972|  0:00:04s\n",
      "epoch 30 | loss: 0.9204  | val_0_unsup_loss_numpy: 0.9061200022697449|  0:00:07s\n",
      "epoch 40 | loss: 0.84968 | val_0_unsup_loss_numpy: 0.9315900206565857|  0:00:09s\n",
      "epoch 50 | loss: 0.84979 | val_0_unsup_loss_numpy: 0.8982599973678589|  0:00:11s\n",
      "epoch 60 | loss: 0.80981 | val_0_unsup_loss_numpy: 0.8458799719810486|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 47 and best_val_0_unsup_loss_numpy = 0.8458200097084045\n",
      "-------------------- maintraining --------------------\n",
      "epoch 0  | loss: 0.96062 | valid_auc: 0.71411 |  0:00:00s\n",
      "epoch 10 | loss: 0.576   | valid_auc: 0.77673 |  0:00:01s\n",
      "epoch 20 | loss: 0.54374 | valid_auc: 0.79094 |  0:00:02s\n",
      "epoch 30 | loss: 0.51611 | valid_auc: 0.78681 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_valid_auc = 0.80121\n",
      "[accuracy] tr: 0.67, va: 0.685000\n",
      "-------------------- result --------------------\n",
      "-------------------- 4 --------------------\n",
      "(2400, 9) (2400, 1)\n",
      "(600, 9) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.238\n",
      "-------------------- pretraining --------------------\n",
      "epoch 0  | loss: 5.2333  | val_0_unsup_loss_numpy: 69.34603881835938|  0:00:00s\n",
      "epoch 10 | loss: 0.87933 | val_0_unsup_loss_numpy: 0.8627200126647949|  0:00:02s\n",
      "epoch 20 | loss: 0.87921 | val_0_unsup_loss_numpy: 0.8245199918746948|  0:00:04s\n",
      "epoch 30 | loss: 0.81677 | val_0_unsup_loss_numpy: 0.8399900197982788|  0:00:07s\n",
      "epoch 40 | loss: 0.82849 | val_0_unsup_loss_numpy: 0.854640007019043|  0:00:09s\n",
      "epoch 50 | loss: 0.78943 | val_0_unsup_loss_numpy: 0.8522899746894836|  0:00:11s\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 33 and best_val_0_unsup_loss_numpy = 0.8016600012779236\n",
      "-------------------- maintraining --------------------\n",
      "epoch 0  | loss: 1.19219 | valid_auc: 0.65913 |  0:00:00s\n",
      "epoch 10 | loss: 0.55528 | valid_auc: 0.70752 |  0:00:01s\n",
      "epoch 20 | loss: 0.53397 | valid_auc: 0.72311 |  0:00:03s\n",
      "epoch 30 | loss: 0.52482 | valid_auc: 0.70429 |  0:00:04s\n",
      "epoch 40 | loss: 0.49874 | valid_auc: 0.70302 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_auc = 0.72741\n",
      "[accuracy] tr: 0.77, va: 0.715000\n",
      "-------------------- result --------------------\n",
      "[[0.         0.72041667 0.745     ]\n",
      " [1.         0.75625    0.70833333]\n",
      " [2.         0.71625    0.67333333]\n",
      " [3.         0.6725     0.685     ]\n",
      " [4.         0.76541667 0.715     ]]\n",
      "[cv] tr: 0.73+-0.03, va: 0.71\n",
      "[oof] 0.7053\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "train_oof, imp, metrics = train_tabnet(X_train, y_train, id_train, params,list_nfold=[0,1,2,3,4], n_splits=5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c2424f03-5613-41bb-9d06-ea248c810c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "      <th>imp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.233866</td>\n",
       "      <td>0.072493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pre/age</td>\n",
       "      <td>0.152465</td>\n",
       "      <td>0.043466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.143735</td>\n",
       "      <td>0.060510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.139835</td>\n",
       "      <td>0.031411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.082146</td>\n",
       "      <td>0.021943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.077161</td>\n",
       "      <td>0.039307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.075873</td>\n",
       "      <td>0.034943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.057526</td>\n",
       "      <td>0.027119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.037395</td>\n",
       "      <td>0.024443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        col       imp   imp_std\n",
       "7               Pregnancies  0.233866  0.072493\n",
       "6                   Pre/age  0.152465  0.043466\n",
       "0                       Age  0.143735  0.060510\n",
       "1                       BMI  0.139835  0.031411\n",
       "2             BloodPressure  0.082146  0.021943\n",
       "3  DiabetesPedigreeFunction  0.077161  0.039307\n",
       "8             SkinThickness  0.075873  0.034943\n",
       "5                   Insulin  0.057526  0.027119\n",
       "4                   Glucose  0.037395  0.024443"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b2994ca2-aa55-495c-822c-d27a93ddc4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.560029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3832</td>\n",
       "      <td>0.061435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4927</td>\n",
       "      <td>0.655945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      pred\n",
       "0    200  0.560029\n",
       "1   3832  0.061435\n",
       "2   4927  0.655945"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oof[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9e9c6-be14-4a58-a9f9-e72e71079b5c",
   "metadata": {},
   "source": [
    "## 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9417f870-fc65-4d11-9e4e-72c820cccdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tabnet(input_x,\n",
    "                   input_id,\n",
    "                   list_nfold=[0,1,2,3,4],\n",
    "                  ):\n",
    "    pred = np.zeros((len(input_x), len(list_nfold)))\n",
    "    for nfold in list_nfold:\n",
    "        print('-'*20, nfold, '-'*20)\n",
    "        fname_tabnet = 'model/tabnet/model_tabnet_fold{}.pickle'.format(nfold)\n",
    "        with open(fname_tabnet, 'rb')as f:\n",
    "            model = pickle.load(f)\n",
    "        pred[:,nfold] = model.predict_proba(input_x.values)[:,1]\n",
    "        \n",
    "    pred = pd.concat([\n",
    "        input_id,\n",
    "        pd.DataFrame({'pred':pred.mean(axis=1)}),], axis=1)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca6dde1a-f537-4165-a503-d37ce37d70d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "test_pred_proba = predict_tabnet(X_test,\n",
    "                    id_test,\n",
    "                    list_nfold=[0,1,2,3,4],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "25255935-76a3-4311-ba6b-7e05419577ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>0.093004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3833</td>\n",
       "      <td>0.068320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4836</td>\n",
       "      <td>0.068616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      pred\n",
       "0    398  0.093004\n",
       "1   3833  0.068320\n",
       "2   4836  0.068616"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_proba[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cf440de5-6160-4a11-af4f-e8a27558c054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  pred\n",
       "0    398     0\n",
       "1   3833     0\n",
       "2   4836     0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = test_pred_proba.copy()  \n",
    "test_pred['pred']=np.where(test_pred['pred'] < 0.5, 0, 1)\n",
    "test_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bec98b8e-4e78-4305-9d30-6cc90b56bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.to_csv('ensamble/sub/submission_tabnet_w.csv', index=None, header=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d47b00-9bcc-4317-a177-29e4b6e4f9c6",
   "metadata": {},
   "source": [
    "## アンサンブル用データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "369dd9a3-a781-46a2-84ab-e1c51af64c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "with open('ensamble/tabnet_w_train.pickle', mode='wb') as fo:\n",
    "    pickle.dump(train_oof, fo)\n",
    "    \n",
    "with open('ensamble/tabnet_w_test.pickle', mode='wb') as fo:\n",
    "    pickle.dump(test_pred_proba, fo)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7bef2c-2d7e-496a-8300-a04d382fb75b",
   "metadata": {},
   "source": [
    "## ベースライン検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78b218b4-b634-4f14-961f-c34c9d220abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証データ:  (2400, 9) (2400, 1)\n",
      "ベースライン検証データ:  (600, 9) (600, 1)\n",
      "検証データ(train):  (1920, 9) (1920, 1)\n",
      "検証データ(test):  (480, 9) (480, 1)\n",
      "-------------------- tabnet用にunsqueze --------------------\n",
      "ベースライン検証データ:  (600, 9) (600,)\n",
      "検証データ(train):  (1920, 9) (1920,)\n",
      "検証データ(test):  (480, 9) (480,)\n"
     ]
    }
   ],
   "source": [
    "random_state=123\n",
    "\n",
    "x_tr, x_va2, y_tr, y_va2 = train_test_split(X_train,\n",
    "                                           y_train,\n",
    "                                           test_size=0.2,\n",
    "                                           shuffle=True,\n",
    "                                           stratify=y_train,\n",
    "                                           random_state=random_state)\n",
    "print('検証データ: ',x_tr.shape, y_tr.shape)\n",
    "print('ベースライン検証データ: ',x_va2.shape, y_va2.shape)\n",
    "\n",
    "x_tr1, x_va1, y_tr1, y_va1 = train_test_split(x_tr,\n",
    "                                              y_tr,\n",
    "                                              test_size=0.2,\n",
    "                                              shuffle=True,\n",
    "                                              stratify=y_tr,\n",
    "                                              random_state=random_state)\n",
    "print('検証データ(train): ',x_tr1.shape, y_tr1.shape)\n",
    "print('検証データ(test): ',x_va1.shape, y_va1.shape)\n",
    "\n",
    "y_tr1=np.squeeze(y_tr1.values)\n",
    "y_va1=np.squeeze(y_va1.values)\n",
    "y_va2=np.squeeze(y_va2.values)\n",
    "\n",
    "x_tr1=x_tr1.values\n",
    "x_va1=x_va1.values\n",
    "x_va2=x_va2.values\n",
    "\n",
    "print('-'*20,'tabnet用にunsqueze','-'*20)\n",
    "print('ベースライン検証データ: ',x_va2.shape, y_va2.shape)\n",
    "print('検証データ(train): ',x_tr1.shape, y_tr1.shape)\n",
    "print('検証データ(test): ',x_va1.shape, y_va1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a8ab0e25-c221-4477-9610-d177b1a72b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.56109 | val_0_unsup_loss_numpy: 164.60769653320312|  0:00:00s\n",
      "epoch 10 | loss: 0.91191 | val_0_unsup_loss_numpy: 0.9158899784088135|  0:00:02s\n",
      "epoch 20 | loss: 0.91583 | val_0_unsup_loss_numpy: 0.8389000296592712|  0:00:04s\n",
      "epoch 30 | loss: 0.8828  | val_0_unsup_loss_numpy: 0.8041800260543823|  0:00:06s\n",
      "epoch 40 | loss: 0.82442 | val_0_unsup_loss_numpy: 0.8322700262069702|  0:00:08s\n",
      "epoch 50 | loss: 0.86601 | val_0_unsup_loss_numpy: 0.8119699954986572|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 33 and best_val_0_unsup_loss_numpy = 0.7945299744606018\n",
      "epoch 0  | loss: 1.21084 | valid_auc: 0.67426 |  0:00:00s\n",
      "epoch 10 | loss: 0.58573 | valid_auc: 0.71631 |  0:00:01s\n",
      "epoch 20 | loss: 0.54524 | valid_auc: 0.73401 |  0:00:02s\n",
      "epoch 30 | loss: 0.53755 | valid_auc: 0.72198 |  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_valid_auc = 0.75857\n"
     ]
    }
   ],
   "source": [
    "#validation結果\n",
    "pretrainer = TabNetPretrainer(**params)\n",
    "pretrainer.fit(\n",
    "    X_train=x_tr1,\n",
    "    eval_set=[x_va1],\n",
    "    max_epochs=200,\n",
    "    patience=20, batch_size=256, virtual_batch_size=128,\n",
    "    num_workers=1, drop_last=True)\n",
    "model = TabNetClassifier(**params)\n",
    "model.fit(\n",
    "    X_train=x_tr1,\n",
    "    y_train=y_tr1,\n",
    "    eval_set=[(x_va1, y_va1)],\n",
    "    eval_name = [\"valid\"],\n",
    "    eval_metric = [\"auc\"],\n",
    "    loss_fn = cross_entropy_loss_wight,\n",
    "    max_epochs=200,\n",
    "    patience=20, \n",
    "    batch_size=256,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0, \n",
    "    drop_last=False,\n",
    "    from_unsupervised=pretrainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "31d4307d-4a67-4228-85a7-140c68b0f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[検証データ] acc: 0.6875\n",
      "[ベースライン検証データ] acc: 0.6867\n",
      "[検証データ] auc: 0.7586\n",
      "[ベースライン検証データ] auc: 0.7685\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEGCAYAAAB1iW6ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAApcUlEQVR4nO3deXRddb3+8fcnycmcNG3SpqXpTFsonVMLlCkFwQLKLIJahgsWh171ol7E5QV+qNereMUJReQioEBAQMGKoEJKmelAgQ5QSseUjmlLkraZP78/zkkIIXNOeqbntVZWzrDPPk/Oap7sfvfe323ujoiIxL6kSAcQEZHwUKGLiMQJFbqISJxQoYuIxAkVuohInEiJ1BsXFBT46NGje/XaAwcOkJWVFd5AYRTt+SD6Mypf3yhf30RzvuXLl+9x98HtPunuEfkqLi723iorK+v1aw+HaM/nHv0Zla9vlK9vojkfsMw76FUNuYiIxAkVuohInFChi4jEiYjtFBURCYf6+nrKy8upqakJ2zoHDBjA2rVrw7a+3khPT6eoqIhAINDt16jQRSSmlZeXk5OTw+jRozGzsKyzqqqKnJycsKyrN9ydiooKysvLGTNmTLdfpyEXEYlpNTU15Ofnh63Mo4GZkZ+f3+P/dajQRSTmxVOZN+vNzxRzhf72jioeWVfH3gN1kY4iIhJVuix0M7vLzHaZ2aoOnv+cmb1hZm+a2YtmNi38MT+wcc8B/rqhnh3vh28HiIhIX2RnZ0c6AtC9LfS7gXmdPL8ROMXdpwDfA+4IQ64O5aYH9+NW1tT359uIiMScLgvd3ZcAezt5/kV33xe6+zJQFKZs7crNCB7CU3lIhS4i0cXd+da3vsXkyZOZMmUKDz74IADbt2/n5JNPZvr06UyePJnnnnuOxsZGrrjiipZlb7311j6/f7gPW7wK+HtHT5rZAmABQGFhIYsXL+7xG+w62ATAqyvfJHX3W70K2d+qq6t79bMdTtGeUfn6JpHyDRgwgKqqKgB+9I93eWtndZ/X6e4tOyWPKszmujPGdfmaqqoqHnvsMZYvX87zzz9PRUUFJSUlzJw5kz/96U+UlJTwrW99i8bGRg4ePMgLL7zAli1beOmllwDYv39/y8/RrKampkefU9gK3czmEiz0Eztaxt3vIDQkM2vWLC8pKenx++w/WMd/LvknR4w6kpITu3985uG0ePFievOzHU7RnlH5+iaR8q1du7blmPFAaoDk5OQ+r7OxsbFlPYHUQLeOSc/JyWH58uV8/vOfJy8vj7y8PEpKSli7di0nnngi//Zv/0ZSUhLnnXce06dPJyMjg82bN/Od73yHs88+mzPOOIOkpA8PmqSnpzNjxoxu5w5LoZvZVOBO4Ex3rwjHOjuSnRaMXFXT0J9vIyIx6MZPHROW9YT7xKKTTz6ZJUuW8Le//Y0rrriCa6+9lssuu4zXX3+dp556ittvv52HHnqIu+66q0/v0+fDFs1sJPAoMN/d1/V1fV1JSU4iPVk7RUUk+px00kk8+OCDNDY2snv3bpYsWcLs2bPZvHkzhYWFfOELX+Dqq69mxYoV7Nmzh6amJi688EK+//3vs2LFij6/f5db6Gb2AFACFJhZOXAjEABw99uBG4B84NehMacGd5/V52SdyAyYdoqKSNQ5//zzeemll5g2bRpmxo9//GOGDh3KPffcwy233EIgECA7O5t7772Xbdu2ceWVV9LUFNwv+MMf/rDP799lobv7pV08fzVwdZ+T9EBmirbQRSR6VFcHd8SaGbfccgu33HLLh56//PLLufzyyz/yunBslbcWc2eKQvMWusbQRURai8lCz0gxbaGLiLQRk4WeGdBRLiLygeClNuNLb36m2Cx0baGLSEh6ejoVFRVxVerN86Gnp6f36HUxeYGL5qNcWp/NJSKJqaioiPLycnbv3h22ddbU1PS4TMOt+YpFPRGbhZ5iNDkcqGtsOdFIRBJTIBDo0VV9umPx4sU9OkMzWsTokEvwu45FFxH5QGwWeiA4zKJxdBGRD8RmoacEC11HuoiIfCA2Cz04JbqGXEREWonNQk/RkIuISFsxWegZzWPoOv1fRKRFTBa6jnIREfmomCz0lCQjI5CsIRcRkVZistABcjNSdJSLiEgrsVvo6QFtoYuItBK7hZ4R0E5REZFWYrbQc9JTtIUuItJKzBZ6bnpAR7mIiLTSZaGb2V1mtsvMVnXw/FFm9pKZ1ZrZN8MfsX25GSlUaqeoiEiL7myh3w3M6+T5vcBXgZ+EI1B3NW+hx9Ok9iIifdFlobv7EoKl3dHzu9x9KXBYxz9yMwI0NDk19U2H821FRKKWdWcL18xGA4vcfXIny9wEVLt7h1vqZrYAWABQWFhYXFpa2tO8AFRXV7NsXxp3r67j1pIMBqZH166A6upqsrOzIx2jU9GeUfn6Rvn6JprzzZ07d7m7z2r3SXfv8gsYDazqYpmbgG92Z33uTnFxsfdWWVmZP75ym4+6bpGv21HZ6/X0l7KyskhH6FK0Z1S+vlG+vonmfMAy76BXo2vTtgdyM4Jz6OrQRRGRoNgt9PTgDF06uUhEJKjLKyyb2QNACVBgZuXAjUAAwN1vN7OhwDIgF2gys68Dk9y9sr9Cg7bQRUTa6rLQ3f3SLp7fARSFLVE35aY3F7q20EVEIIaHXHJahly0hS4iAjFc6OmBZNJSkjTkIiISErOFDpCTrhkXRUSaxXShB+dz0Ra6iAjEeqFrxkURkRaxXegZAV2GTkQkJLYLXRe5EBFpEduFrsvQiYi0iOlC12XoREQ+ENOFnpseoK6hiZr6xkhHERGJuNgudM3nIiLSIrYLPXT6v450ERGJ9UJv3kLXsegiIjFe6JpxUUSkRYwXumZcFBFpFtuFrp2iIiItYrvQm4dcdHKRiEhsF3p6IIlAslGlLXQRka4L3czuMrNdZraqg+fNzH5hZuvN7A0zmxn+mB1mC864qEIXEenWFvrdwLxOnj8TGB/6WgD8pu+xuk/zuYiIBHVZ6O6+BNjbySLnAvd60MtAnpkNC1fArmg+FxGRIHP3rhcyGw0scvfJ7Ty3CPgfd38+dP9p4Dp3X9bOsgsIbsVTWFhYXFpa2qvQ1dXVZGdnA3DL0kPUNsJ3j8vo1br6Q+t80SraMypf3yhf30Rzvrlz5y5391ntPunuXX4Bo4FVHTy3CDix1f2ngVldrbO4uNh7q6ysrOX2l/64zE/738W9Xld/aJ0vWkV7RuXrG+Xrm2jOByzzDno1HEe5bANGtLpfFHrssNBl6EREgsJR6I8Dl4WOdjkOeN/dt4dhvd2iy9CJiASldLWAmT0AlAAFZlYO3AgEANz9duAJ4CxgPXAQuLK/wrYnNz2FQ/WN1DU0kZoS04fVi4j0SZeF7u6XdvG8A18JW6Ieaj79v6qmnvzstEjFEBGJuJjfpM1pnqBLwy4ikuBivtA/mM9FO0ZFJLHFfqFrxkURESAeCj29eQxdQy4ikthiv9AzdJELERGIh0JP15CLiAjEQaFnpiaTnGSacVFEEl7MF7qZacZFERHioNBB87mIiEC8FHpGio5yEZGEFx+FrsvQiYjEUaFrp6iIJLi4KHTtFBURiZNCD14oWoUuIoktPgo9PcCBukYaGpsiHUVEJGLio9BDp/9X12ocXUQSV3wUessUuip0EUlc8VHomkJXRCQ+Cr3lqkXaMSoiCaxbhW5m88zsbTNbb2bfbuf5UWb2tJm9YWaLzawo/FE7phkXRUS6UehmlgzcBpwJTAIuNbNJbRb7CXCvu08FbgZ+GO6gnflgTnSNoYtI4urOFvpsYL27b3D3OqAUOLfNMpOAZ0K3y9p5vl9pDF1EBMzdO1/A7CJgnrtfHbo/HzjW3Re2WuZ+4BV3/7mZXQA8AhS4e0WbdS0AFgAUFhYWl5aW9ip0dXU12dnZLfeb3LnqqYOcMy7A+eNTe7XOcGqbLxpFe0bl6xvl65tozjd37tzl7j6r3SfdvdMv4CLgzlb35wO/arPMEcCjwGvAz4FyIK+z9RYXF3tvlZWVfeSxKTc+6Tc+tqrX6wyn9vJFm2jPqHx9o3x9E835gGXeQa+mdOMPwjZgRKv7RaHHWv9ReA+4AMDMsoEL3X1/9/7ehEduhmZcFJHE1p0x9KXAeDMbY2apwCXA460XMLMCM2te1/XAXeGN2bUczbgoIgmuy0J39wZgIfAUsBZ4yN1Xm9nNZnZOaLES4G0zWwcUAj/op7wdytWMiyKS4Loz5IK7PwE80eaxG1rdfhh4OLzReiY3I0D5vkORjCAiElFxcaYo6LqiIiLxU+gZGnIRkcQWP4WeHqC6toGmps6PqxcRiVdxU+g56Sm4Q5XmRBeRBBU3hd5y+r/G0UUkQcVPoWvGRRFJcPFT6KEZF6tqNOQiIokpfgo9XUMuIpLY4qbQB7RMoastdBFJTHFT6LoMnYgkurgp9Oy0UKFrp6iIJKi4KfSU5CSy01I046KIJKy4KXQIzrhYpS10EUlQ8VXousiFiCSw+Cp0XeRCRBJYXBV6ji5yISIJLK4KXUMuIpLI4qvQ03WUi4gkrm4VupnNM7O3zWy9mX27nedHmlmZmb1mZm+Y2Vnhj9q13IwAVTX1uGtOdBFJPF0WupklA7cBZwKTgEvNbFKbxb5L8OLRM4BLgF+HO2h35KYHaHI4UNcYibcXEYmo7myhzwbWu/sGd68DSoFz2yzjQG7o9gDgvfBF7L7mGRd1+r+IJCLranjCzC4C5rn71aH784Fj3X1hq2WGAf8ABgJZwMfdfXk761oALAAoLCwsLi0t7VXo6upqsrOzP/L40h0N3Laylu+dkMGInMjtHugoXzSJ9ozK1zfK1zfRnG/u3LnL3X1Wu0+6e6dfwEXAna3uzwd+1WaZa4FvhG4fD6wBkjpbb3FxsfdWWVlZu48/t263j7pukb+yoaLX6w6HjvJFk2jPqHx9o3x9E835gGXeQa92ZzN2GzCi1f2i0GOtXQU8FPoD8RKQDhR0Y91hpSEXEUlk3Sn0pcB4MxtjZqkEd3o+3maZLcBpAGZ2NMFC3x3OoN3RfJGLqloVuogkni4L3d0bgIXAU8BagkezrDazm83snNBi3wC+YGavAw8AV4T+a3BYfXChaB2LLiKJJ6U7C7n7E8ATbR67odXtNcAJ4Y3Wc7rIhYgksrg6UzSQnERmarJO/xeRhBRXhQ6hCbo05CIiCSjuCj03XRN0iUhiir9CzwhQVaMtdBFJPPFX6JoTXUQSVPwVekZAR7mISEKKv0JPD1CpIRcRSUBxV+jBo1w0J7qIJJ64K/TcjAANTc6hes2JLiKJJf4KvXk+Fw27iEiCibtCHxCaz2VnZU2Ek4iIHF5xV+izxwwiOcl44s0dkY4iInJYxV2hD85Jo2TCYP78WjmNTdoxKiKJI+4KHeDC4iJ2Vtbywvo9kY4iInLYxGWhn3b0EAZkBHhkRXmko4iIHDZxWehpKcl8atownlq9gypNAyAiCSIuCx3gwplF1NQ38cSb2yMdRUTksIjbQp8+Io+xg7N4ZHnb61mLiMSnuC10M+PCmUW8umkvWyoORjqOiEi/61ahm9k8M3vbzNab2bfbef5WM1sZ+lpnZvvDnrQXzp8xHDO0c1REEkKXhW5mycBtwJnAJOBSM5vUehl3/w93n+7u04FfAo/2Q9YeOyIvgznj8nn0tXKadEy6iMS57myhzwbWu/sGd68DSoFzO1n+UuCBcIQLhwtnFrF17yGWbtob6SgiIv3Kuppm1swuAua5+9Wh+/OBY919YTvLjgJeBorc/SPTHZrZAmABQGFhYXFpaWmvQldXV5Odnd2tZWsbnK+VHeRjQ1O4akpar96vp3qSL1KiPaPy9Y3y9U0055s7d+5yd5/V3nMpYX6vS4CH2ytzAHe/A7gDYNasWV5SUtKrN1m8eDE9ee0n973Ok6t2cOyck8hITe7Ve/ZET/NFQrRnVL6+Ub6+ifZ8HenOkMs2YESr+0Whx9pzCVE03NLswplFVNc28NRqTdglIvGrO4W+FBhvZmPMLJVgaT/ediEzOwoYCLwU3oh9d+yYQQzPy9DRLiIS17osdHdvABYCTwFrgYfcfbWZ3Wxm57Ra9BKg1KPw2m9JScaFM4fz/Po9bH//UKTjiIj0i24dh+7uT7j7BHcf5+4/CD12g7s/3mqZm9z9I8eoR4sLZhbhDn9+TWeOikh8itszRdsaXZDFrFEDeWR5uS4gLSJxKWEKHYLzpL+7+wCvl78f6SgiImGXUIV+9tRhpKUk8chy7RwVkfiTUIWemx7gjGOG8vjr73Gort1D5UVEYlZCFTrA544dyfuH6vncnS9TUV0b6TgiImGTcIV+3Nh8fv25max+r5ILfvMiG3ZXRzqSiEhYJFyhA5w1ZRgPLDiO6poGLvjNi7y6URN3iUjsS8hCB5g5ciB//vIJDMpK5fN3vsJjK3V8uojEtoQtdICR+Zk8+qU5zBiZx9dKV/KrZ97RMeoiErMSutAB8jJTufeq2Zw/Yzg/+cc6rnvkDeobmyIdS0Skx8I9fW5MSktJ5qcXT2PEoEx+8fQ7lO87xL+fOp7ZYwaRnGSRjici0i0q9BAz49rTJzByUCb/9ZdVXPq7lynITuUTxwzlrCnDOHbMIFKSE/4/NCISxVTobVxUXMRZU4ZS9tZunli1nUdXbOO+V7YwMDPAJ44ZyplThjFnXD4BlbuIRBkVejsyU1M4e+owzp46jEN1jTy7bjd/X7WdRW9sp3TpVgZlpfLLS2dwwpEFkY4qItJChd6FjNRk5k0eyrzJQ6mpb+S5d/bwk6fe5srfL+XWz0zn7KnDIh1RRATQUS49kh5I5vRJhTx0zfFMLRrAwgdW8IeXN0c6logIoELvlQGZAf5w1bGcOnEI//WXVfz8Xzp+XUQiT4XeSxmpydw+v5gLZxZx67/WcePjq2lqUqmLSOR0q9DNbJ6ZvW1m682s3cvMmdnFZrbGzFab2f3hjRmdAslJ/OTTU1lw8ljufWkzXy19jboGnZQkIpHR5U5RM0sGbgNOB8qBpWb2uLuvabXMeOB64AR332dmQ/orcLQxM75z1tHkZ6Xyw7+/FZyad9RHt9RrGxrZe6COiuo6DtU3MmlYLllp2ictIuHTnUaZDax39w0AZlYKnAusabXMF4Db3H0fgLvvCnfQaHfNKeMYmJXK9Y++ycbt8Mh7y6iorm0p8arahg8tn5JkTBuRx5xx+Rw/Lp+ZIweSHkiOUHoRiQfdKfThwNZW98uBY9ssMwHAzF4AkoGb3P3JsCSMIRfPGsHAzFT+65HlbN17kPzsVKYOzGNQVir5WakMyk4lPyuNQLKxfPM+Xny3gtvK1vPLZ9aTlpLErNEDmTOugBOOLGBa0QDMNO2AiHSfdXV0hpldBMxz96tD9+cDx7r7wlbLLALqgYuBImAJMMXd97dZ1wJgAUBhYWFxaWlpr0JXV1eTnZ3dq9ceDj3Jd7DeWbevkbUVjazZ28TWquAY/MSBSXx6QipHDuyfrfZ4+gwjQfn6Rvl6b+7cucvdfVa7T7p7p1/A8cBTre5fD1zfZpnbgStb3X8a+Fhn6y0uLvbeKisr6/VrD4e+5NtTVeN3v7DRi7/3Tx913SK/+p6lvm5HZfjChcTzZ3g4KF/fKF/vAcu8g17tzpDLUmC8mY0BtgGXAJ9ts8xfgEuB35tZAcEhmA09+KMjIfnZaVw+ZzQXFRfx+xc28ttnN/CJny3hwplF/MfpEzgiL6NP669taGTF5v28uqOBHa9uobKmnspDDVTV1FNZE/xe1+icNXko580YrnF9kRjSZaG7e4OZLQSeIjg+fpe7rzazmwn+pXg89NwZZrYGaAS+5e4V/Rk83mWlpbDw1PF89thR/LpsPfe+tJnHXn+Py48fxZdLjmRgVmq311Xf2MQL6/fw19e38481O6iqCe2gXfkmAEkGOekBcjNSyEkLUNPQyLcffZNbnnqb+cePYv5xo8jPTuuPH1NEwqhbx825+xPAE20eu6HVbQeuDX1JGA3KSuW7n5zElSeO4dZ/ruP/nt/Ifa9sYfLwAUwszGHi0ODXhMIcBmQEWl7X2OS8srGCv76+nSdXbWffwXpy0lL4xOShnDl5KO+tX81pJx1PbkaArNTkD+2AdXde2lDB/z23kZ/96x1+s/hdLphZxFUnjuHIIdE5rigimpwrZgzPy+Ann54WOolpE2u3V/GX17Z96HDIYQPSmTg0h4LsNJ5dt5vdVbVkpibz8aML+dS0Izh5QgFpKcEhlMU713Y4fGNmzBlXwJxxBazfVc1dL2zkkeXlPPDqFk49aghXnziG48fl6ygckSijQo8xEwpz+P55U4DglvR779fw9o5K3t5RzbqdVby1o4rXtuzn+LH5fGraEZx61BAyUns/Dn7kkGz++/wpfOP0Cfzx5S384eVNfPbOV5g+Io+vnTaekomDVewiUUKFHsPMjOF5GQzPy+DUowr79b3ys9P42sfHc80pY3l0xTZ+vXg9V969lCnDB/DV08bz8aOHqNhFIkyTc0mPpAeS+eyxIyn7Zgk/vmgqlTX1fOHeZZz1i+d5ctV2TVAmEkEqdOmVQHISF88awdPXnsJPL55GbX0jX/zjCs78+XM8tnIbVTX1kY4oknA05CJ9kpKcxAUzizh3+nAWvfEev3xmPV8rXYkZjB+SzfQReUwfMZAZI/OYUJhDclLPh2X2H6xjzfZK1m6vYu32SjbtOcDogixmjMxj+og8Jhbm9OkC3k1Nzls7qnhpQwUvvVvBmvfe55SJQ/jiKWMZlZ/V6/WKHG4qdAmL5CTj3OnD+dTUI3jx3QqWbd7Lyq37+ceanTy0rByAzNRkpgwfwNSiAeSmBwikJJGSZKSmJBFI/uC2Ozy9ro4/bFrK2u2VvPd+Tcv7FGSnMaYgk7K3dvHw8uB6MwLJTCkawIyRecwYkcfUojxyMwKkJBmB5KSP/BFxd9bvqm4p8Jc3VLDvYPB/FKPyMzlm+AAeWVHOg0u3cM60I/jy3COZUJhzmD5Jkd5ToUtYJSUZJ44v4MTxwQtouzubKg6ycus+Vm7Zz8qt+7n7xU3UN3Y+1p5kcOSQg3xszCAmDcvl6NDX4Jy0lvVu3XuI17bu47XQeu96fmO7602y4P8kAklGSnISTU3ecrhn8w7l5lkvmw/l3FVZw53Pb+SPL2/mLyvf44xJhSw89UimFuWF8dMSCS8VuvQrM2NMQRZjCrI4f0YRECzjhianvrGJ+sbg94bG5vtNNDlseHMpZ5x2SqfrHZmfycj8TM6dPhwITmuw5r1KVr1XycHahpb3aGh06puC3xtC6z/miFzmjCtgxKCMdo/OGZKbznfOOpovnTKO37+4ibtf2Mg/1uzkpPEFfOmUceytaWL7+4eCWbBWuYJfAzNTCfRhGKg/le87SHogmfysVB2ZFGdU6HLYmRmBZOu08MqTe140aSnJzBg5kBkjB/Yl3ocMzErl2tMn8IWTxnDfK1u487kNfPbOV4JPLn6mw9eZQX5WGkMHpDE0N53C3PSW70fkZfCxMQNbTvI6HOobm3hy1Q7ufWkTSzftA4JDYCMGZjJiUCYjBmUwclAmIwdlMio/k3GDs1X2MUiFLtINOekBvnjKOK6YM5p/rtnJijdWM3HiRJoHeFrPQt3Y1MSe6jp2Vtawo7KG8n2HWL55X8s4PQTP6r3m5LFcMntkv06Atquyhvtf3cL9r2xhV1Uto/Iz+faZR5GeksSWvYfYsvcg5fsO8uK7ezhY19jyujMmFfK/F08jJz3Qydol2qjQRXogPZDMp6YdQc6+dZTMHtmj19bUN7Krspa3d1bxuyUbuOmva/hV2btcc/JYPnfcSDJTw/Pr6O68s6+RRx54jb+/uZ2GJqdk4mB+dPxoTpkwmKR2jjRydyoO1LF170Gef2cPP3v6Hc7/9YvcMb+YsYN7Nn/Pht3VbNh9gF1VteyuqmVXVQ27qmqD9ytr2HewnpmDjWkfq+vRJHPSNRW6yGGSHkhuGfc/fVIhL2+o4JfPvMMPnljLb559l6tOHMNlx4/q8VZxQ2MT63dX88bW93m9fD9LN+1l3c4actJ3cfmc0cw/bhSjCzo//NLMKMhOoyA7jRkjB1I8eiBfuW8F5972Aj+/ZHq3zkTeuvcgP3ryLRa9sf1Djw/KSmVwdhpDctMYNzifZDMeXVHOaT99lhs+OYlzpx+h4Z0wUaGLRMhxY/M5bmw+yzfv45fPvMMtT73Nb599lyvmjOboYbkEkpMIpCQRSDZSk4OHdjbvd3hnVxWvb32fN7ftZ9W2Sg7VB4dLctJSmFI0gDkFdfznZ+b2eqt/zrgC/vrvJ3LNH5Zz1T3L+MbpE/jK3CPbLd7Kmnp+XfYud72wkSSDr556JKceXciQnOAfiNSUj+4rmZpewSNb0vj6gyt59LVt/OC8yYwYlNmrrPIBFbpIhBWPGsjdV87mjfL9/OqZ9fzimfXdel1aShLHHJHLZz42gmkjBjC1KI8x+VkkJRmLFy/u8xBO0cBMHv7iHK5/9A1+8o91rNpWyU8unkZ2WnC9DY1NlC7dyq3/XEfFgTounFnENz8xgWEDur4Iy4icJB750hz++PJmfvzkW5xx6xKuPX0CV54wuk8niSU6FbpIlJhalMcdl81ix/s17D9UR32DUxc6lLO+sYm6huD3hiZnTEEWEwpz+v3QyIzUZG79zHQmDx/Afz+xlvNvq+Z3l81iU8UBfvC3tbyzq5rZYwZx99mTmFI0oEfrTk4yLp8zmtMnFXLDY6v4wRNreez1bfzPBVOZPLxn65IgFbpIlBk6IJ2hA9IjHaOFmXH1SWM5elguC+9fwRm3LqGusYnR+Zn8dn4xZ0wq7NMY+BF5Gfzusln8fdUObnx8Nef86nk+XTyCL88dp6kXekiFLiLdcsKRBTy+8ES+t2gNs8cM4rLjR7c7Pt4bZsZZU4ZxwrgCbv3XOu5/dQsPryjn3NDUC7pSVveo0EWk20YMyuSOy2b12/oHZAa46Zxj+HLJOO5YsoH7XtnCn1du4+wpw1h46pEcNTS33947HGrqG3lq9Q4mFOZw9LDDn7VbhW5m84CfE7xI9J3u/j9tnr8CuAXYFnroV+5+ZxhzikgCGZKbznc/OYkvlYzjzuc3cu+Lm1j0xnbOmFTIV08b3+MxdndnZ2UtG3ZXs7HiAKPzs5g1Onxn69bUN3L/K1v4zbPvsruqliSDS2aP5BunTzisF1jvstDNLBm4DTgdKAeWmtnj7r6mzaIPuvvCfsgoIgkqPzuN6+YdxTUnj+WuFzbx+9CcOnmZAQpz0hmSm8aQnHQKc9MYkpNGYW46BTlp7Kmq5d3d1by7+0Dw+65qDrQ6ExaCUx/MGVdAycTBlEwcTNHAnh82eaiukfte2cxvl2xgd1Utx40dxI8vmsqSdbu596XNLHr9Pb7+8QnMP37UYZnbpztb6LOB9e6+AcDMSoFzgbaFLiLSL/Iyg3PqXH3SGB5ZXh46E7WGnZW1vLtrD7uqamlo52pZRwxIZ9yQbD49awTjBmcxbnA2IwZl8vaOKhav28Xit3fzr7U7ARg3OIuSiUMomTiYfTXBo4o62kfQXOS3P7uBPdW1HD82n19eOoPjxuYDMHfiED47eyQ3L1rDzYvWcP+rW7jhk5M4ecLg/vuQAHPvfBpTM7sImOfuV4fuzweObb01Hhpy+SGwG1gH/Ie7b21nXQuABQCFhYXFpaWlvQpdXV1Ndnb07iSJ9nwQ/RmVr28SLV+TO9V1sK+2ifdrndxUY2hWEukpnR994+5sP+C8uaeRN3c38ta+RhqaPng+IwVyU42cVGv5npYML29voLIOJuUnce64VCYOan/oxt1ZubuRB96qY9dBZ/rgZC45KpWhWb3fWp87d+5yd293R0a4Cj0fqHb3WjO7BviMu5/a2XpnzZrly5Yt6+GPErR48WJKSkp69drDIdrzQfRnVL6+Ub7eOVjXwNJN+yh7ZSX5R4ym4kBd8Ku6lr0H6thTXcf+g3UcNzafr318PB8bPahb661taOT3L2zil0+/Q11jE9fNO4qrTxrbq4xm1mGhd2fIZRswotX9Ij7Y+QmAu1e0unsn8OOehhQRibTM1BROmTAYfy9AScn4dpdx9x4fd5+WkswXTxnHBTOHc8uTbzOyn6Y56E6hLwXGm9kYgkV+CfDZ1guY2TB3b56R5xxgbVhTiohEib6cRDUkJ51bPj0tjGk+rMtCd/cGM1sIPEXwsMW73H21md0MLHP3x4Gvmtk5QAOwF7ii3xKLiEi7unUcurs/ATzR5rEbWt2+Hrg+vNFERKQnNK2ZiEicUKGLiMQJFbqISJxQoYuIxAkVuohInFChi4jEiS5P/e+3NzbbDWzu5csLgD1hjBNu0Z4Poj+j8vWN8vVNNOcb5e7tzvIVsULvCzNb1tFcBtEg2vNB9GdUvr5Rvr6J9nwd0ZCLiEicUKGLiMSJWC30OyIdoAvRng+iP6Py9Y3y9U2052tXTI6hi4jIR8XqFrqIiLShQhcRiRMxV+hmNs/M3jaz9Wb27UjnacvMNpnZm2a20sx6d4298Oa5y8x2mdmqVo8NMrN/mtk7oe8DoyzfTWa2LfQZrjSzsyKYb4SZlZnZGjNbbWZfCz0eFZ9hJ/mi4jM0s3Qze9XMXg/l+3+hx8eY2Suh3+MHzSw1yvLdbWYbW31+0yORr8fcPWa+CF5g411gLJAKvA5MinSuNhk3AQWRztEqz8nATGBVq8d+DHw7dPvbwI+iLN9NwDcj/dmFsgwDZoZu5xC8CPqkaPkMO8kXFZ8hYEB26HYAeAU4DngIuCT0+O3Al6Is393ARZH+/Hr6FWtb6LOB9e6+wd3rgFLg3AhnimruvoTgVaRaOxe4J3T7HuC8w5mptQ7yRQ133+7uK0K3qwheXnE4UfIZdpIvKnhQdehuIPTlwKnAw6HHI/n5dZQvJsVaoQ8Htra6X04U/eMNceAfZrbczBZEOkwHCv2Da8DuAAojGaYDC83sjdCQTMSGhFozs9HADIJbcVH3GbbJB1HyGZpZspmtBHYB/yT4v+z97t4QWiSiv8dt87l78+f3g9Dnd6uZpUUqX0/EWqHHghPdfSZwJvAVMzs50oE648H/a0bbFslvgHHAdGA78L8RTQOYWTbwCPB1d69s/Vw0fIbt5Iuaz9DdG919OlBE8H/ZR0UqS3va5jOzyQQvqXkU8DFgEHBd5BJ2X6wV+jZgRKv7RaHHooa7bwt93wX8meA/4Giz08yGAYS+74pwng9x952hX7Im4HdE+DM0swDBsrzP3R8NPRw1n2F7+aLtMwxl2g+UAccDeWbWfE3jqPg9bpVvXmgoy929Fvg9UfD5dUesFfpSYHxoD3kqcAnweIQztTCzLDPLab4NnAGs6vxVEfE4cHno9uXAYxHM8hHNRRlyPhH8DM3MgP8D1rr7T1s9FRWfYUf5ouUzNLPBZpYXup0BnE5wnL8MuCi0WCQ/v/byvdXqj7URHN+Pxt/jj4i5M0VDh1/9jOARL3e5+w8im+gDZjaW4FY5QApwf6TzmdkDQAnB6UB3AjcCfyF4lMFIglMYX+zuEdkx2UG+EoJDBU7wqKFrWo1XH+58JwLPAW8CTaGHv0NwnDrin2En+S4lCj5DM5tKcKdnMsENyIfc/ebQ70opweGM14DPh7aGoyXfM8BggkfBrAS+2GrnadSKuUIXEZH2xdqQi4iIdECFLiISJ1ToIiJxQoUuIhInVOgiInFChS7SC2ZWYmaLIp1DpDUVuohInFChS1wzs8+H5rteaWa/DU3EVB2acGm1mT1tZoNDy043s5dDEzL9uXlCKzM70sz+FZoze4WZjQutPtvMHjazt8zsvtBZhSIRo0KXuGVmRwOfAU4ITb7UCHwOyAKWufsxwLMEz04FuBe4zt2nEjzzsvnx+4Db3H0aMIfgZFcQnNnw6wTnHx8LnNDPP5JIp1K6XkQkZp0GFANLQxvPGQQn0WoCHgwt80fgUTMbAOS5+7Ohx+8B/hSam2e4u/8ZwN1rAELre9Xdy0P3VwKjgef7/acS6YAKXeKZAfe4+/UfetDsv9os19v5L1rPPdKIfp8kwjTkIvHsaeAiMxsCLdcBHUXw333zTH+fBZ539/eBfWZ2Uujx+cCzoasAlZvZeaF1pJlZ5uH8IUS6S1sUErfcfY2ZfZfgFaSSgHrgK8ABghcy+C7BIZjPhF5yOXB7qLA3AFeGHp8P/NbMbg6t49OH8ccQ6TbNtigJx8yq3T070jlEwk1DLiIicUJb6CIicUJb6CIicUKFLiISJ1ToIiJxQoUuIhInVOgiInHi/wOO0WVXLgdCmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#評価指標の差\n",
    "y_va1_pred = model.predict(x_va1)\n",
    "y_va2_pred = model.predict(x_va2)\n",
    "print('[検証データ] acc: {:.4f}'.format(accuracy_score(y_va1, y_va1_pred)))\n",
    "print('[ベースライン検証データ] acc: {:.4f}'.format(accuracy_score(y_va2, y_va2_pred)))\n",
    "\n",
    "y_va1_pred_proba = model.predict_proba(x_va1)\n",
    "y_va2_pred_proba = model.predict_proba(x_va2)\n",
    "print('[検証データ] auc: {:.4f}'.format(roc_auc_score(y_va1, y_va1_pred_proba[:,1])))\n",
    "print('[ベースライン検証データ] auc: {:.4f}'.format(roc_auc_score(y_va2, y_va2_pred_proba[:,1])))\n",
    "\n",
    "\n",
    "for param in ['loss', 'valid_auc']:\n",
    "    plt.plot(model.history[param], label=param)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0dc60f74-2285-4d97-981c-7bc45559170c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証データ\n",
      "[[242 123]\n",
      " [ 27  88]]\n",
      "[[0.50416667 0.25625   ]\n",
      " [0.05625    0.18333333]]\n",
      "ベースライン検証データ\n",
      "[[306 151]\n",
      " [ 37 106]]\n",
      "[[0.51       0.25166667]\n",
      " [0.06166667 0.17666667]]\n"
     ]
    }
   ],
   "source": [
    "#誤分類の分布\n",
    "print('検証データ')\n",
    "print(confusion_matrix(y_va1, y_va1_pred))\n",
    "print(confusion_matrix(y_va1, y_va1_pred, normalize='all'))\n",
    "\n",
    "print('ベースライン検証データ')\n",
    "print(confusion_matrix(y_va2, y_va2_pred))\n",
    "print(confusion_matrix(y_va2, y_va2_pred, normalize='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ff7889ac-c105-4fa2-9d93-d60b7a3b66d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xffff211e6a90>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 予測値の分布\n",
    "y_va1_pred_prob = model.predict_proba(x_va1)[:,1]\n",
    "y_va2_pred_prob = model.predict_proba(x_va2)[:,1]\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "fig.add_subplot(2,1,1)\n",
    "plt.title('validation_data')\n",
    "plt.hist(y_va1_pred_prob[np.array(y_va1).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va1_pred_prob[np.array(y_va1).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(2,1,2)\n",
    "plt.title('basreline_validation_data')\n",
    "plt.hist(y_va2_pred_prob[np.array(y_va2).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va2_pred_prob[np.array(y_va2).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328625a6-3203-4c10-b4de-62d8a519061d",
   "metadata": {},
   "source": [
    "## チューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a4209557-3c7f-4f15-8e61-4d7a3fda9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "raw",
   "id": "468b2b1a-4d31-4f98-bb7d-b4390a0480cf",
   "metadata": {},
   "source": [
    "params = {'n_d': 8, #値が大きいほど表現力と過学習のリスクがあがる\n",
    "          'n_a': 8, # n_dと同じ値にしておくのが良いらしい\n",
    "          'n_steps': 3,#TabNetEncoderのstepを何回繰り返すか\n",
    "          'gamma': 1.3,\n",
    "          'n_independent': 2,\n",
    "          'n_shared': 2,\n",
    "          'seed':random_state,\n",
    "          'lambda_sparse': 1e-3,\n",
    "          'optimizer_fn': torch.optim.Adam, \n",
    "          'optimizer_params': {'lr':2e-2},\n",
    "          'mask_type': \"entmax\",#AttentiveTransformerでマスク作るのにどっちの関数を使うか'sparsemax'or'entmax'\n",
    "          'scheduler_params':{'mode': \"min\",'patience': 5,'min_lr': 1e-5,'factor': 0.9},\n",
    "          'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "          'verbose':10\n",
    "         }\n",
    "         \n",
    "         n_d, n_a\t8-64\t8\n",
    "n_steps\t1-10\t3\n",
    "gamma\t1.0-2.0\t1.3\n",
    "mask_type\t\"entmatx\" or \"sparsemax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "534cd02b-5cdb-43d1-93d5-2fb92fcd7d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索しないパラメータ\n",
    "\n",
    "params_base = {\n",
    "   'optimizer_fn': torch.optim.Adam,\n",
    "   'optimizer_params': {'lr':2e-2,'weight_decay':1e-5},\n",
    "   'mask_type': \"entmax\",#AttentiveTransformerでマスク作るのにどっちの関数を使うか'sparsemax'or'entmax'\n",
    "   'scheduler_params':{'mode': \"min\",'patience': 5,'min_lr': 1e-5,'factor': 0.9, 'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,},\n",
    "   'verbose':10,\n",
    "   'seed': 123,\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # 探索するパラメータ\n",
    "    params_tuning = {\n",
    "        'n_d': trial.suggest_int('n_d',8,64),\n",
    "        'n_a': trial.suggest_int('n_a',8,64),\n",
    "        'n_steps': trial.suggest_int('n_steps', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n",
    "        'mask_type': trial.suggest_categorical('mask_type', ['entmatx','sparsemax']),\n",
    "    }\n",
    "    params_tuning.update(params_base)\n",
    "    \n",
    "    # モデル学習・評価\n",
    "    list_metrics = []\n",
    "    cv = list(StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state).split(X_train, y_train))\n",
    "    for nfold in np.arange(4):\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = X_train.loc[idx_tr, :], y_train.loc[idx_tr, :]\n",
    "        x_va, y_va = X_train.loc[idx_va, :], y_train.loc[idx_va, :]\n",
    "        y_tr=np.squeeze(y_tr.values)\n",
    "        y_va=np.squeeze(y_va.values)\n",
    "        x_tr=x_tr.values\n",
    "        x_va=x_va.values\n",
    "        pretrainer = TabNetPretrainer(**params)\n",
    "        pretrainer.fit(\n",
    "            X_train=x_tr,\n",
    "            eval_set=[x_va],\n",
    "            max_epochs=200,\n",
    "            patience=20, batch_size=256, virtual_batch_size=128,\n",
    "            num_workers=1, drop_last=True)\n",
    "        model = TabNetClassifier(**params)\n",
    "        model.fit(\n",
    "            X_train=x_tr,\n",
    "            y_train=y_tr,\n",
    "            eval_set=[(x_va, y_va)],\n",
    "            eval_name = [\"valid\"],\n",
    "            eval_metric = [\"auc\"],\n",
    "            max_epochs=200,\n",
    "            patience=20, \n",
    "            batch_size=256,\n",
    "            virtual_batch_size=128,\n",
    "            num_workers=0, \n",
    "            drop_last=False,\n",
    "            from_unsupervised=pretrainer\n",
    "        )\n",
    "        y_va_pred = model.predict_proba(x_va)[:,1]\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>0.5, 1, 0))\n",
    "        list_metrics.append(metric_va)\n",
    "        \n",
    "    # 評価値の計算\n",
    "    metrics = np.mean(list_metrics)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dfa2fe2d-edf5-416e-8b53-40cf1270f935",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:30:30,966]\u001b[0m A new study created in memory with name: no-name-97358861-6750-4be3-94dc-5e398a3eb469\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:02s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:11s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:11s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:02s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:31:44,567]\u001b[0m Trial 0 finished with value: 0.7753333333333332 and parameters: {'n_d': 47, 'n_a': 24, 'n_steps': 3, 'gamma': 1.5513147690828912, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:06s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:02s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:06s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:11s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:13s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:15s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:06s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:11s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:02s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:32:55,736]\u001b[0m Trial 1 finished with value: 0.7753333333333332 and parameters: {'n_d': 63, 'n_a': 47, 'n_steps': 5, 'gamma': 1.3921175181941505, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:06s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:02s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:06s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:11s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:13s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:15s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:06s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:11s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:02s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:34:07,213]\u001b[0m Trial 2 finished with value: 0.7753333333333332 and parameters: {'n_d': 32, 'n_a': 11, 'n_steps': 4, 'gamma': 1.7379954057320357, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:02s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:11s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:13s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:02s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:35:21,728]\u001b[0m Trial 3 finished with value: 0.7753333333333332 and parameters: {'n_d': 38, 'n_a': 38, 'n_steps': 7, 'gamma': 1.8494317940777896, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:02s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:02s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:36:38,123]\u001b[0m Trial 4 finished with value: 0.7753333333333332 and parameters: {'n_d': 49, 'n_a': 26, 'n_steps': 4, 'gamma': 1.2282632308789556, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:37:56,186]\u001b[0m Trial 5 finished with value: 0.7753333333333332 and parameters: {'n_d': 13, 'n_a': 32, 'n_steps': 5, 'gamma': 1.4936850976503062, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:39:13,485]\u001b[0m Trial 6 finished with value: 0.7753333333333332 and parameters: {'n_d': 32, 'n_a': 58, 'n_steps': 10, 'gamma': 1.5018366758843364, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:11s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:40:30,777]\u001b[0m Trial 7 finished with value: 0.7753333333333332 and parameters: {'n_d': 26, 'n_a': 31, 'n_steps': 9, 'gamma': 1.2504553653965067, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:10s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:41:47,958]\u001b[0m Trial 8 finished with value: 0.7753333333333332 and parameters: {'n_d': 37, 'n_a': 42, 'n_steps': 2, 'gamma': 1.8263408005068333, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:02s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:43:04,893]\u001b[0m Trial 9 finished with value: 0.7753333333333332 and parameters: {'n_d': 27, 'n_a': 25, 'n_steps': 5, 'gamma': 1.6813007657927965, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:44:23,374]\u001b[0m Trial 10 finished with value: 0.7753333333333332 and parameters: {'n_d': 56, 'n_a': 8, 'n_steps': 1, 'gamma': 1.0080611434040203, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:45:41,563]\u001b[0m Trial 11 finished with value: 0.7753333333333332 and parameters: {'n_d': 63, 'n_a': 51, 'n_steps': 3, 'gamma': 1.9862890564016848, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:46:58,772]\u001b[0m Trial 12 finished with value: 0.7753333333333332 and parameters: {'n_d': 48, 'n_a': 46, 'n_steps': 7, 'gamma': 1.555399472872045, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:48:16,133]\u001b[0m Trial 13 finished with value: 0.7753333333333332 and parameters: {'n_d': 64, 'n_a': 19, 'n_steps': 7, 'gamma': 1.3631357691972947, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:49:33,700]\u001b[0m Trial 14 finished with value: 0.7753333333333332 and parameters: {'n_d': 49, 'n_a': 59, 'n_steps': 3, 'gamma': 1.6071903264160659, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:50:51,407]\u001b[0m Trial 15 finished with value: 0.7753333333333332 and parameters: {'n_d': 56, 'n_a': 19, 'n_steps': 1, 'gamma': 1.4511497032783554, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:52:09,917]\u001b[0m Trial 16 finished with value: 0.7753333333333332 and parameters: {'n_d': 44, 'n_a': 49, 'n_steps': 6, 'gamma': 1.3844748717398336, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:10s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:15s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:10s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:53:30,394]\u001b[0m Trial 17 finished with value: 0.7753333333333332 and parameters: {'n_d': 57, 'n_a': 38, 'n_steps': 3, 'gamma': 1.6228321701158495, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:54:48,521]\u001b[0m Trial 18 finished with value: 0.7753333333333332 and parameters: {'n_d': 13, 'n_a': 54, 'n_steps': 6, 'gamma': 1.3222958430513911, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:56:06,843]\u001b[0m Trial 19 finished with value: 0.7753333333333332 and parameters: {'n_d': 43, 'n_a': 62, 'n_steps': 8, 'gamma': 1.5520330411371615, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:57:24,880]\u001b[0m Trial 20 finished with value: 0.7753333333333332 and parameters: {'n_d': 59, 'n_a': 15, 'n_steps': 4, 'gamma': 1.4356061202518677, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:58:43,370]\u001b[0m Trial 21 finished with value: 0.7753333333333332 and parameters: {'n_d': 21, 'n_a': 8, 'n_steps': 4, 'gamma': 1.7069340307634664, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:10s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:00:02,630]\u001b[0m Trial 22 finished with value: 0.7753333333333332 and parameters: {'n_d': 29, 'n_a': 14, 'n_steps': 2, 'gamma': 1.7163415570713012, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:10s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:15s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:10s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:01:23,283]\u001b[0m Trial 23 finished with value: 0.7753333333333332 and parameters: {'n_d': 20, 'n_a': 25, 'n_steps': 5, 'gamma': 1.6119687787895545, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:02:41,909]\u001b[0m Trial 24 finished with value: 0.7753333333333332 and parameters: {'n_d': 41, 'n_a': 31, 'n_steps': 4, 'gamma': 1.7913032879236999, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:04:00,353]\u001b[0m Trial 25 finished with value: 0.7753333333333332 and parameters: {'n_d': 33, 'n_a': 14, 'n_steps': 2, 'gamma': 1.494434901957632, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:05:18,450]\u001b[0m Trial 26 finished with value: 0.7753333333333332 and parameters: {'n_d': 52, 'n_a': 19, 'n_steps': 3, 'gamma': 1.7716585404282987, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:10s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:06:37,124]\u001b[0m Trial 27 finished with value: 0.7753333333333332 and parameters: {'n_d': 22, 'n_a': 42, 'n_steps': 6, 'gamma': 1.6495702502566643, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:10s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:15s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:10s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:07:56,480]\u001b[0m Trial 28 finished with value: 0.7753333333333332 and parameters: {'n_d': 53, 'n_a': 44, 'n_steps': 5, 'gamma': 1.570458959494639, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:10s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:15s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:10s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:09:16,939]\u001b[0m Trial 29 finished with value: 0.7753333333333332 and parameters: {'n_d': 39, 'n_a': 23, 'n_steps': 4, 'gamma': 1.864792365897348, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=random_state)\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3e7fef0c-0f29-45c8-ba99-18fd3708e29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(best)=0.7753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_d': 47,\n",
       " 'n_a': 24,\n",
       " 'n_steps': 3,\n",
       " 'gamma': 1.5513147690828912,\n",
       " 'mask_type': 'entmatx'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print('acc(best)={:.4f}'.format(trial.value))\n",
    "display(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7a422d94-c604-4bf8-b6ad-12586898ee99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_d': 47,\n",
       " 'n_a': 24,\n",
       " 'n_steps': 3,\n",
       " 'gamma': 1.5513147690828912,\n",
       " 'mask_type': 'entmax',\n",
       " 'optimizer_fn': torch.optim.adam.Adam,\n",
       " 'optimizer_params': {'lr': 0.02, 'weight_decay': 1e-05},\n",
       " 'scheduler_params': {'mode': 'min',\n",
       "  'patience': 5,\n",
       "  'min_lr': 1e-05,\n",
       "  'factor': 0.9,\n",
       "  'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau},\n",
       " 'verbose': 10,\n",
       " 'seed': 123}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_best = trial.params\n",
    "params_best.update(params_base)\n",
    "display(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ee80db-0b36-4869-86e9-98bb063d03c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
