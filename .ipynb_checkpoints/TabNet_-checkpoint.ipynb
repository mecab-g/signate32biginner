{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e99ea0f-3ced-46f4-a586-e7dfc25a697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "\n",
    "#データ読み込み\n",
    "train = pd.read_csv(\"data_EDA/train.csv\")\n",
    "test = pd.read_csv(\"data_EDA/test.csv\")\n",
    "\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7c165e22-292a-4d50-996a-878715efc485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 27 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   index                     3000 non-null   int64  \n",
      " 1   Pregnancies               3000 non-null   int64  \n",
      " 2   Glucose                   3000 non-null   int64  \n",
      " 3   BloodPressure             3000 non-null   int64  \n",
      " 4   SkinThickness             3000 non-null   int64  \n",
      " 5   Insulin                   3000 non-null   int64  \n",
      " 6   BMI                       3000 non-null   float64\n",
      " 7   DiabetesPedigreeFunction  3000 non-null   float64\n",
      " 8   Age                       3000 non-null   int64  \n",
      " 9   Outcome                   3000 non-null   float64\n",
      " 10  BloodPressure_0           2887 non-null   float64\n",
      " 11  SkinThickness_0           1234 non-null   float64\n",
      " 12  Insulin_0                 256 non-null    float64\n",
      " 13  Pregnancies_0             2570 non-null   float64\n",
      " 14  SkinThickness_na          3000 non-null   int64  \n",
      " 15  BloodPressure_na          3000 non-null   int64  \n",
      " 16  Insulin_na                3000 non-null   int64  \n",
      " 17  Pregnancies_na            3000 non-null   int64  \n",
      " 18  Pre/age                   3000 non-null   float64\n",
      " 19  SkinThickness_mean        3000 non-null   float64\n",
      " 20  BloodPressure_mean        3000 non-null   float64\n",
      " 21  Insulin_dpf_mean          3000 non-null   float64\n",
      " 22  Pregnancies_bin           3000 non-null   int64  \n",
      " 23  Pregnancies_bin_0         3000 non-null   int64  \n",
      " 24  Pregnancies_bin_1         3000 non-null   int64  \n",
      " 25  Pregnancies_bin_3         3000 non-null   int64  \n",
      " 26  Pregnancies_bin_10        3000 non-null   int64  \n",
      "dtypes: float64(11), int64(16)\n",
      "memory usage: 632.9 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "52b0aeb2-a3f7-4c56-920d-d3d23a6bad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# まずは少ない特徴量から検討していく\n",
    "X_train = train[['DiabetesPedigreeFunction',\n",
    "                 'BMI',\n",
    "                 'Glucose',\n",
    "                 'Age',\n",
    "                 'Pregnancies',\n",
    "                 'SkinThickness',\n",
    "                 'Insulin',\n",
    "                 'BloodPressure',\n",
    "                 'Pre/age',\n",
    "                 \n",
    "                 \n",
    "                \n",
    "             ]]\n",
    "id_train = train[['index']]\n",
    "y_train = train[['Outcome']]\n",
    "\n",
    "\n",
    "X_test = test[X_train.columns]\n",
    "id_test = test[id_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14691ea3-b316-4838-aa02-3fb0fc098a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiabetesPedigreeFunction\n",
      "BMI\n",
      "Glucose\n",
      "Age\n",
      "Pregnancies\n",
      "SkinThickness\n",
      "Insulin\n",
      "BloodPressure\n",
      "Pre/age\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# 数値データ\n",
    "col_num = X_train.columns[X_train.dtypes!='object'].values.tolist()\n",
    "\n",
    "dict_num = {}\n",
    "for col in col_num:\n",
    "    print(col)\n",
    "    # 欠損値を0へ\n",
    "    value_fillna = 0 \n",
    "    X_train[col] = X_train[col].fillna(value_fillna)\n",
    "    # 正規化\n",
    "    value_min = X_train[col].min()\n",
    "    value_max = X_train[col].max()\n",
    "    value_mean = X_train[col].mean()\n",
    "    value_std = X_train[col].std()\n",
    "    # X_train[col] = (X_train[col] - value_min) / (value_max -value_min)\n",
    "    X_train[col] = (X_train[col] - value_mean) / value_std\n",
    "    \n",
    "    dict_num[col] = {}\n",
    "    dict_num[col]['fillna'] = value_fillna\n",
    "    dict_num[col]['min'] = value_min\n",
    "    dict_num[col]['max'] = value_max\n",
    "    dict_num[col]['mean'] = value_max    \n",
    "    dict_num[col]['std'] = value_max    \n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4775291d-8632-4bb6-b029-b4edbde59d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# カテゴリデータ\n",
    "col_cat = X_train.columns[X_train.dtypes=='object'].values.tolist()\n",
    "\n",
    "dict_cat = {}\n",
    "for col in col_cat:\n",
    "    print(col)\n",
    "    value_fillna = 'unknown'\n",
    "    X_train[col] = X_train[cal].fillna(value_fillna)\n",
    "    \n",
    "    X_train[caol] = X_train[col].astype(str)\n",
    "    # 整数に変換\n",
    "    le = LabelEncorder()\n",
    "    le.fit(X_train[col])\n",
    "    list_labelsorted(list(set(le.classes_) | set(['unknown'])))\n",
    "    map_label = {j:i for i,j in enumerate(list_label)}\n",
    "    X_train[col] = X_train[col].map(map_label)\n",
    "    \n",
    "    dict_cat[col] = {}\n",
    "    dict_cat[col]['fillna'] = value_fillna\n",
    "    dict_cat[col]['map_label'] = map_label\n",
    "    dict_cat[col]['num_label'] = len(list_label)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "874665d8-fb87-41e6-a83c-4047e4218092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(input_x):\n",
    "    output_x = input_x.copy()\n",
    "    \n",
    "    for col in col_num:\n",
    "        value_fillna = dict_num[col]['fillna']\n",
    "        output_x[col] = output_x[col].fillna(value_fillna)\n",
    "        \n",
    "        value_min = dict_num[col]['min']\n",
    "        value_max = dict_num[col]['max']\n",
    "        value_mean = dict_num[col]['mean']\n",
    "        value_std = dict_num[col]['std']\n",
    "        \n",
    "        # output_x[col]  = (output_x[col] - value_min ) / (value_max - value_min)\n",
    "        output_x[col]  = (output_x[col] - value_mean ) / value_std\n",
    "        \n",
    "        \n",
    "    for col in col_cat:\n",
    "        value_fillna = dict_cat[col]['fillna']\n",
    "        output_x[col] = output_x[col].fillna(value_fillna)\n",
    "        \n",
    "        output_x[col] = output_x[col].astype(str)\n",
    "        \n",
    "        map_label = dict_catt[col]['map_label']\n",
    "        output_x[col] = output_x[col].map(map_label)\n",
    "        \n",
    "        #対応するものがない場合はunkoumn\n",
    "        output_x[col] = output_x[col].fillna(map_label['unknown'])\n",
    "        \n",
    "    return output_x\n",
    "\n",
    "\n",
    "X_test = transform_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2ca0a12f-adda-464e-883a-e894ea811394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   DiabetesPedigreeFunction  3000 non-null   float64\n",
      " 1   BMI                       3000 non-null   float64\n",
      " 2   Glucose                   3000 non-null   float64\n",
      " 3   Age                       3000 non-null   float64\n",
      " 4   Pregnancies               3000 non-null   float64\n",
      " 5   SkinThickness             3000 non-null   float64\n",
      " 6   Insulin                   3000 non-null   float64\n",
      " 7   BloodPressure             3000 non-null   float64\n",
      " 8   Pre/age                   3000 non-null   float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 211.1 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aef527-11fa-4c91-9ae5-d7e2ce47a210",
   "metadata": {},
   "source": [
    "## validation方法（ベースライン作成へ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aceea77a-bb08-4591-a561-dd086bc8eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 123\n",
    "params = {'n_d': 47, #値が大きいほど表現力と過学習のリスクがあがる\n",
    "          'n_a': 24, # n_dと同じ値にしておくのが良いらしい\n",
    "          'n_steps': 3,#TabNetEncoderのstepを何回繰り返すか\n",
    "          'gamma': 1.3,\n",
    "          'n_independent': 2,\n",
    "          'n_shared': 2,\n",
    "          'seed':random_state,\n",
    "          'lambda_sparse': 1e-3,\n",
    "          'optimizer_fn': torch.optim.Adam, \n",
    "          'optimizer_params': {'lr':2e-2},\n",
    "          'mask_type': \"entmax\",#AttentiveTransformerでマスク作るのにどっちの関数を使うか'sparsemax'or'entmax'\n",
    "          'scheduler_params':{'mode': \"min\",'patience': 5,'min_lr': 1e-5,'factor': 0.9},\n",
    "          'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "          'verbose':10\n",
    "         }\n",
    "#https://zenn.dev/nishimoto/articles/f2af21c24413d3\n",
    "#https://www.guruguru.science/competitions/16/discussions/70f25f95-4dcc-4733-9f9e-f7bc6472d7c0/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067feb6e-739a-471e-a6f4-5352e438b7ec",
   "metadata": {},
   "source": [
    "{'n_d': 47,\n",
    " 'n_a': 24,\n",
    " 'n_steps': 3,\n",
    " 'gamma': 1.5513147690828912,\n",
    " 'mask_type': 'entmax',\n",
    " 'optimizer_fn': torch.optim.adam.Adam,\n",
    " 'optimizer_params': {'lr': 0.02, 'weight_decay': 1e-05},\n",
    " 'scheduler_params': {'mode': 'min',\n",
    "  'patience': 5,\n",
    "  'min_lr': 1e-05,\n",
    "  'factor': 0.9,\n",
    "  'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau},\n",
    " 'verbose': 10,\n",
    " 'seed': 123}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6fb4ecee-6785-4fe1-acd8-a25d08168bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvでの評価用\n",
    "def train_tabnet(input_x,\n",
    "              input_y,\n",
    "              input_id,\n",
    "              params,\n",
    "              list_nfold=[0,1,2,3,4],\n",
    "              n_splits=5,\n",
    "              random_state=123\n",
    "            ):\n",
    "    train_oof = np.zeros(len(input_x))\n",
    "    # foldごとの推論値\n",
    "    metrics = []\n",
    "    imp = pd.DataFrame()\n",
    "                         \n",
    "    cv = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state).\n",
    "              split(input_x, input_y))\n",
    "    \n",
    "    for nfold in list_nfold:\n",
    "        print('-'*20, nfold, '-'*20)\n",
    "        \n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = input_x.loc[idx_tr, :], input_y.loc[idx_tr, :]\n",
    "        x_va, y_va = input_x.loc[idx_va, :], input_y.loc[idx_va, :]\n",
    "        print(x_tr.shape, y_tr.shape)\n",
    "        print(x_va.shape, y_va.shape)\n",
    "        print('y_train:{:.3f}, y_tr:{:.3f}, y_va{:.3f}'.\n",
    "              format(y_train['Outcome'].mean(), y_tr['Outcome'].mean(), y_va['Outcome'].mean(),))\n",
    "        \n",
    "        y_tr=np.squeeze(y_tr.values)\n",
    "        y_va=np.squeeze(y_va.values)\n",
    "        x_tr=x_tr.values\n",
    "        x_va=x_va.values\n",
    "        \n",
    "        print('-'*20, 'pretraining', '-'*20)\n",
    "        \n",
    "        pretrainer = TabNetPretrainer(**params_best)\n",
    "        pretrainer.fit(\n",
    "            X_train=x_tr,\n",
    "            eval_set=[x_va],\n",
    "            max_epochs=200,\n",
    "            patience=20, batch_size=256, virtual_batch_size=128,\n",
    "            num_workers=1, drop_last=True)\n",
    "        print('-'*20, 'maintraining', '-'*20)\n",
    "        \n",
    "        model = TabNetClassifier(**params_best)\n",
    "        model.fit(\n",
    "            X_train=x_tr,\n",
    "            y_train=y_tr,\n",
    "            eval_set=[(x_va, y_va)],\n",
    "            eval_name = [\"valid\"],\n",
    "            eval_metric = [\"auc\"],\n",
    "            max_epochs=200,\n",
    "            patience=20, \n",
    "            batch_size=256,\n",
    "            virtual_batch_size=128,\n",
    "            num_workers=0, \n",
    "            drop_last=False,\n",
    "            from_unsupervised=pretrainer\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # モデルの保存\n",
    "        fname_tabnet = 'model/tabnet/model_tabnet_fold{}.pickle'.format(nfold)\n",
    "        with open(fname_tabnet, 'wb')as f:\n",
    "            pickle.dump(model, f, protocol=4)\n",
    "            \n",
    "            \n",
    "        # 評価\n",
    "        y_tr_pred = model.predict_proba(x_tr)[:,1]\n",
    "        y_va_pred = model.predict_proba(x_va)[:,1]\n",
    "        \n",
    "        metric_tr = accuracy_score(y_tr, np.where(y_tr_pred>=0.5,1,0))\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>=0.5,1,0))\n",
    "        print('[accuracy] tr: {:.2f}, va: {:2f}'.\n",
    "             format(metric_tr, metric_va))\n",
    "        metrics.append([nfold, metric_tr, metric_va])\n",
    "        \n",
    "        # oof\n",
    "        train_oof[idx_va] = y_va_pred\n",
    "        \n",
    "         # imp\n",
    "        _imp = pd.DataFrame({'col':input_x.columns, 'imp':model.feature_importances_,'nfold':nfold})\n",
    "        imp = pd.concat([imp, _imp], axis=0, ignore_index=False)\n",
    "        \n",
    "        \n",
    "        print('-'*20, 'result', '-'*20)\n",
    "    \n",
    "    # metrix出力\n",
    "    metrics = np.array(metrics)\n",
    "    print(metrics)\n",
    "    print('[cv] tr: {:.2f}+-{:.2f}, va: {:.2f}'.format(\n",
    "        metrics[:,1].mean(), metrics[:,1].std(),\n",
    "        metrics[:,2].mean(), metrics[:,2].std()\n",
    "    ))\n",
    "    print('[oof] {:.4f}'.format(\n",
    "        accuracy_score(input_y, np.where(train_oof>=0.5,1,0))))\n",
    "    # oof出力  \n",
    "    train_oof = pd.concat([\n",
    "        input_id,\n",
    "        pd.DataFrame({'pred':train_oof})]\n",
    "        ,axis=1)\n",
    "    \n",
    "        # imp出力\n",
    "    imp = imp.groupby('col')['imp'].agg(['mean', 'std']).reset_index(drop=False)\n",
    "    imp.columns = ['col', 'imp', 'imp_std']\n",
    "\n",
    "    print('Done')\n",
    "    \n",
    "    return train_oof, imp, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ec383631-7376-4685-9de1-83c4d88a1aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "(2400, 9) (2400, 1)\n",
      "(600, 9) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.240\n",
      "-------------------- pretraining --------------------\n",
      "epoch 0  | loss: 4.71509 | val_0_unsup_loss_numpy: 99.27549743652344|  0:00:00s\n",
      "epoch 10 | loss: 0.891   | val_0_unsup_loss_numpy: 0.9001299738883972|  0:00:02s\n",
      "epoch 20 | loss: 0.86041 | val_0_unsup_loss_numpy: 0.8606899976730347|  0:00:05s\n",
      "epoch 30 | loss: 0.88399 | val_0_unsup_loss_numpy: 0.8350399732589722|  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_unsup_loss_numpy = 0.8190400004386902\n",
      "-------------------- maintraining --------------------\n",
      "epoch 0  | loss: 0.90241 | valid_auc: 0.70868 |  0:00:00s\n",
      "epoch 10 | loss: 0.49047 | valid_auc: 0.77126 |  0:00:01s\n",
      "epoch 20 | loss: 0.45603 | valid_auc: 0.78259 |  0:00:03s\n",
      "epoch 30 | loss: 0.43558 | valid_auc: 0.75439 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.79276\n",
      "[accuracy] tr: 0.79, va: 0.785000\n",
      "-------------------- result --------------------\n",
      "-------------------- 1 --------------------\n",
      "(2400, 9) (2400, 1)\n",
      "(600, 9) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.240\n",
      "-------------------- pretraining --------------------\n",
      "epoch 0  | loss: 4.75152 | val_0_unsup_loss_numpy: 111.42877197265625|  0:00:00s\n",
      "epoch 10 | loss: 0.91734 | val_0_unsup_loss_numpy: 0.8874499797821045|  0:00:02s\n",
      "epoch 20 | loss: 0.90416 | val_0_unsup_loss_numpy: 0.8037199974060059|  0:00:05s\n",
      "epoch 30 | loss: 0.85294 | val_0_unsup_loss_numpy: 0.8065699934959412|  0:00:07s\n",
      "epoch 40 | loss: 0.84032 | val_0_unsup_loss_numpy: 0.8154100179672241|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_val_0_unsup_loss_numpy = 0.7833399772644043\n",
      "-------------------- maintraining --------------------\n",
      "epoch 0  | loss: 1.41958 | valid_auc: 0.57797 |  0:00:00s\n",
      "epoch 10 | loss: 0.46742 | valid_auc: 0.75647 |  0:00:01s\n",
      "epoch 20 | loss: 0.44682 | valid_auc: 0.77619 |  0:00:03s\n",
      "epoch 30 | loss: 0.43581 | valid_auc: 0.74896 |  0:00:04s\n",
      "epoch 40 | loss: 0.42764 | valid_auc: 0.79261 |  0:00:05s\n",
      "epoch 50 | loss: 0.41176 | valid_auc: 0.77458 |  0:00:07s\n",
      "epoch 60 | loss: 0.41294 | valid_auc: 0.76157 |  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 40 and best_valid_auc = 0.79261\n",
      "[accuracy] tr: 0.82, va: 0.783333\n",
      "-------------------- result --------------------\n",
      "-------------------- 2 --------------------\n",
      "(2400, 9) (2400, 1)\n",
      "(600, 9) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.238\n",
      "-------------------- pretraining --------------------\n",
      "epoch 0  | loss: 4.80851 | val_0_unsup_loss_numpy: 81.86451721191406|  0:00:00s\n",
      "epoch 10 | loss: 0.93326 | val_0_unsup_loss_numpy: 0.8899999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.84944 | val_0_unsup_loss_numpy: 0.8632500171661377|  0:00:05s\n",
      "epoch 30 | loss: 0.83428 | val_0_unsup_loss_numpy: 0.8610799908638|  0:00:07s\n",
      "epoch 40 | loss: 0.81007 | val_0_unsup_loss_numpy: 0.865369975566864|  0:00:10s\n",
      "epoch 50 | loss: 0.84454 | val_0_unsup_loss_numpy: 0.8541200160980225|  0:00:12s\n",
      "epoch 60 | loss: 0.83993 | val_0_unsup_loss_numpy: 0.8721399903297424|  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 47 and best_val_0_unsup_loss_numpy = 0.8337900042533875\n",
      "-------------------- maintraining --------------------\n",
      "epoch 0  | loss: 0.93477 | valid_auc: 0.61939 |  0:00:00s\n",
      "epoch 10 | loss: 0.46316 | valid_auc: 0.70074 |  0:00:01s\n",
      "epoch 20 | loss: 0.44884 | valid_auc: 0.70775 |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_valid_auc = 0.73269\n",
      "[accuracy] tr: 0.79, va: 0.763333\n",
      "-------------------- result --------------------\n",
      "-------------------- 3 --------------------\n",
      "(2400, 9) (2400, 1)\n",
      "(600, 9) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.238\n",
      "-------------------- pretraining --------------------\n",
      "epoch 0  | loss: 4.8668  | val_0_unsup_loss_numpy: 84.59361267089844|  0:00:00s\n",
      "epoch 10 | loss: 0.89856 | val_0_unsup_loss_numpy: 0.9729499816894531|  0:00:02s\n",
      "epoch 20 | loss: 0.87259 | val_0_unsup_loss_numpy: 0.9272500276565552|  0:00:05s\n",
      "epoch 30 | loss: 0.91417 | val_0_unsup_loss_numpy: 0.8906999826431274|  0:00:07s\n",
      "epoch 40 | loss: 0.84653 | val_0_unsup_loss_numpy: 0.8852999806404114|  0:00:10s\n",
      "epoch 50 | loss: 0.85015 | val_0_unsup_loss_numpy: 0.8520200252532959|  0:00:12s\n",
      "epoch 60 | loss: 0.81836 | val_0_unsup_loss_numpy: 0.889710009098053|  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 47 and best_val_0_unsup_loss_numpy = 0.8384000062942505\n",
      "-------------------- maintraining --------------------\n",
      "epoch 0  | loss: 1.15755 | valid_auc: 0.65085 |  0:00:00s\n",
      "epoch 10 | loss: 0.47283 | valid_auc: 0.77821 |  0:00:01s\n",
      "epoch 20 | loss: 0.44155 | valid_auc: 0.79172 |  0:00:02s\n",
      "epoch 30 | loss: 0.43563 | valid_auc: 0.78974 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_valid_auc = 0.80312\n",
      "[accuracy] tr: 0.78, va: 0.791667\n",
      "-------------------- result --------------------\n",
      "-------------------- 4 --------------------\n",
      "(2400, 9) (2400, 1)\n",
      "(600, 9) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.238\n",
      "-------------------- pretraining --------------------\n",
      "epoch 0  | loss: 4.72841 | val_0_unsup_loss_numpy: 90.81400299072266|  0:00:00s\n",
      "epoch 10 | loss: 0.8962  | val_0_unsup_loss_numpy: 0.9593200087547302|  0:00:02s\n",
      "epoch 20 | loss: 0.87175 | val_0_unsup_loss_numpy: 0.8054900169372559|  0:00:05s\n",
      "epoch 30 | loss: 0.81311 | val_0_unsup_loss_numpy: 0.8070099949836731|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_unsup_loss_numpy = 0.7986000180244446\n",
      "-------------------- maintraining --------------------\n",
      "epoch 0  | loss: 1.16734 | valid_auc: 0.64218 |  0:00:00s\n",
      "epoch 10 | loss: 0.46364 | valid_auc: 0.71345 |  0:00:01s\n",
      "epoch 20 | loss: 0.43837 | valid_auc: 0.74031 |  0:00:02s\n",
      "epoch 30 | loss: 0.4436  | valid_auc: 0.69939 |  0:00:04s\n",
      "epoch 40 | loss: 0.42145 | valid_auc: 0.72391 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.74031\n",
      "[accuracy] tr: 0.80, va: 0.785000\n",
      "-------------------- result --------------------\n",
      "[[0.         0.79125    0.785     ]\n",
      " [1.         0.81583333 0.78333333]\n",
      " [2.         0.78666667 0.76333333]\n",
      " [3.         0.78375    0.79166667]\n",
      " [4.         0.8025     0.785     ]]\n",
      "[cv] tr: 0.80+-0.01, va: 0.78\n",
      "[oof] 0.7817\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "train_oof, imp, metrics = train_tabnet(X_train, y_train, id_train, params,list_nfold=[0,1,2,3,4], n_splits=5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c2424f03-5613-41bb-9d06-ea248c810c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "      <th>imp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.296342</td>\n",
       "      <td>0.129490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pre/age</td>\n",
       "      <td>0.144582</td>\n",
       "      <td>0.057679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.140789</td>\n",
       "      <td>0.054995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.127101</td>\n",
       "      <td>0.023778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.088547</td>\n",
       "      <td>0.070988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.063475</td>\n",
       "      <td>0.030108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.056633</td>\n",
       "      <td>0.027068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.049732</td>\n",
       "      <td>0.036081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.008819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        col       imp   imp_std\n",
       "7               Pregnancies  0.296342  0.129490\n",
       "6                   Pre/age  0.144582  0.057679\n",
       "1                       BMI  0.140789  0.054995\n",
       "0                       Age  0.127101  0.023778\n",
       "8             SkinThickness  0.088547  0.070988\n",
       "2             BloodPressure  0.063475  0.030108\n",
       "3  DiabetesPedigreeFunction  0.056633  0.027068\n",
       "4                   Glucose  0.049732  0.036081\n",
       "5                   Insulin  0.032800  0.008819"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b2994ca2-aa55-495c-822c-d27a93ddc4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.560029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3832</td>\n",
       "      <td>0.061435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4927</td>\n",
       "      <td>0.655945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      pred\n",
       "0    200  0.560029\n",
       "1   3832  0.061435\n",
       "2   4927  0.655945"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oof[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9e9c6-be14-4a58-a9f9-e72e71079b5c",
   "metadata": {},
   "source": [
    "## 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9417f870-fc65-4d11-9e4e-72c820cccdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tabnet(input_x,\n",
    "                   input_id,\n",
    "                   list_nfold=[0,1,2,3,4],\n",
    "                  ):\n",
    "    pred = np.zeros((len(input_x), len(list_nfold)))\n",
    "    for nfold in list_nfold:\n",
    "        print('-'*20, nfold, '-'*20)\n",
    "        fname_tabnet = 'model/tabnet/model_tabnet_fold{}.pickle'.format(nfold)\n",
    "        with open(fname_tabnet, 'rb')as f:\n",
    "            model = pickle.load(f)\n",
    "        pred[:,nfold] = model.predict_proba(input_x.values)[:,1]\n",
    "        \n",
    "    pred = pd.concat([\n",
    "        input_id,\n",
    "        pd.DataFrame({'pred':pred.mean(axis=1)}),], axis=1)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ca6dde1a-f537-4165-a503-d37ce37d70d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "-------------------- 1 --------------------\n",
      "-------------------- 2 --------------------\n",
      "-------------------- 3 --------------------\n",
      "-------------------- 4 --------------------\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "test_pred_proba = predict_tabnet(X_test,\n",
    "                    id_test,\n",
    "                    list_nfold=[0,1,2,3,4],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "25255935-76a3-4311-ba6b-7e05419577ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>0.349645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3833</td>\n",
       "      <td>0.156456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4836</td>\n",
       "      <td>0.110531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      pred\n",
       "0    398  0.349645\n",
       "1   3833  0.156456\n",
       "2   4836  0.110531"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_proba[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cf440de5-6160-4a11-af4f-e8a27558c054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  pred\n",
       "0    398     0\n",
       "1   3833     0\n",
       "2   4836     0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = test_pred_proba.copy()  \n",
    "test_pred['pred']=np.where(test_pred['pred'] < 0.5, 0, 1)\n",
    "test_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bec98b8e-4e78-4305-9d30-6cc90b56bf99",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'sub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [121]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub/submission_tabnet.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3540\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3542\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3543\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3544\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3548\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3549\u001b[0m )\n\u001b[0;32m-> 3551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mline_terminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_terminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3554\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3556\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3568\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/formats/format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1162\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1163\u001b[0m     line_terminator\u001b[38;5;241m=\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1179\u001b[0m )\n\u001b[0;32m-> 1180\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/formats/csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/common.py:697\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 697\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/common.py:571\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    569\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'sub'"
     ]
    }
   ],
   "source": [
    "test_pred.to_csv('sub/submission_tabnet.csv', index=None, header=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d47b00-9bcc-4317-a177-29e4b6e4f9c6",
   "metadata": {},
   "source": [
    "## アンサンブル用データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "369dd9a3-a781-46a2-84ab-e1c51af64c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "with open('ensamble/tabnet_train.pickle', mode='wb') as fo:\n",
    "    pickle.dump(train_oof, fo)\n",
    "    \n",
    "with open('ensamble/tabnet_test.pickle', mode='wb') as fo:\n",
    "    pickle.dump(test_pred_proba, fo)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7bef2c-2d7e-496a-8300-a04d382fb75b",
   "metadata": {},
   "source": [
    "## ベースライン検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "78b218b4-b634-4f14-961f-c34c9d220abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 9) (3000, 1) (3000, 1)\n",
      "検証データ:  (2400, 9) (2400, 1)\n",
      "ベースライン検証データ:  (600, 9) (600, 1)\n",
      "検証データ(train):  (1920, 9) (1920, 1)\n",
      "検証データ(test):  (480, 9) (480, 1)\n",
      "-------------------- tabnet用 --------------------\n",
      "ベースライン検証データ:  (600, 9) (600,)\n",
      "検証データ(train):  (1920, 9) (1920,)\n",
      "検証データ(test):  (480, 9) (480,)\n"
     ]
    }
   ],
   "source": [
    "# 標準化\n",
    "change_cloumns = X_train.columns\n",
    "\n",
    "for col in change_cloumns :\n",
    "    value_mean = X_train[col].mean()\n",
    "    value_std = X_train[col].std()\n",
    "    X_train[col] = (X_train[col] - value_mean) /  value_std\n",
    "    \n",
    "for col in change_cloumns :\n",
    "    value_mean = X_test[col].mean()\n",
    "    value_std = X_test[col].std()\n",
    "    X_test[col] = (X_test[col] - value_mean) / value_std\n",
    "    \n",
    "print(X_train.shape, y_train.shape, id_train.shape)  \n",
    "\n",
    "x_tr, x_va2, y_tr, y_va2 = train_test_split(X_train,\n",
    "                                           y_train,\n",
    "                                           test_size=0.2,\n",
    "                                           shuffle=True,\n",
    "                                           stratify=y_train,\n",
    "                                           random_state=random_state)\n",
    "print('検証データ: ',x_tr.shape, y_tr.shape)\n",
    "print('ベースライン検証データ: ',x_va2.shape, y_va2.shape)\n",
    "\n",
    "x_tr1, x_va1, y_tr1, y_va1 = train_test_split(x_tr,\n",
    "                                              y_tr,\n",
    "                                              test_size=0.2,\n",
    "                                              shuffle=True,\n",
    "                                              stratify=y_tr,\n",
    "                                              random_state=random_state)\n",
    "print('検証データ(train): ',x_tr1.shape, y_tr1.shape)\n",
    "print('検証データ(test): ',x_va1.shape, y_va1.shape)\n",
    "\n",
    "y_tr1=np.squeeze(y_tr1.values)\n",
    "y_va1=np.squeeze(y_va1.values)\n",
    "y_va2=np.squeeze(y_va2.values)\n",
    "\n",
    "x_tr1=x_tr1.values\n",
    "x_va1=x_va1.values\n",
    "x_va2=x_va2.values\n",
    "\n",
    "print('-'*20,'tabnet用','-'*20)\n",
    "print('ベースライン検証データ: ',x_va2.shape, y_va2.shape)\n",
    "print('検証データ(train): ',x_tr1.shape, y_tr1.shape)\n",
    "print('検証データ(test): ',x_va1.shape, y_va1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a8ab0e25-c221-4477-9610-d177b1a72b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.56109 | val_0_unsup_loss_numpy: 164.60769653320312|  0:00:00s\n",
      "epoch 10 | loss: 0.91191 | val_0_unsup_loss_numpy: 0.9158899784088135|  0:00:02s\n",
      "epoch 20 | loss: 0.91583 | val_0_unsup_loss_numpy: 0.8389000296592712|  0:00:04s\n",
      "epoch 30 | loss: 0.8828  | val_0_unsup_loss_numpy: 0.8041800260543823|  0:00:06s\n",
      "epoch 40 | loss: 0.82442 | val_0_unsup_loss_numpy: 0.8322700262069702|  0:00:08s\n",
      "epoch 50 | loss: 0.86601 | val_0_unsup_loss_numpy: 0.8119699954986572|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 33 and best_val_0_unsup_loss_numpy = 0.7945299744606018\n",
      "epoch 0  | loss: 1.27547 | valid_auc: 0.66521 |  0:00:00s\n",
      "epoch 10 | loss: 0.46441 | valid_auc: 0.70492 |  0:00:01s\n",
      "epoch 20 | loss: 0.43486 | valid_auc: 0.67533 |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_valid_auc = 0.72117\n"
     ]
    }
   ],
   "source": [
    "#validation結果\n",
    "pretrainer = TabNetPretrainer(**params)\n",
    "pretrainer.fit(\n",
    "    X_train=x_tr1,\n",
    "    eval_set=[x_va1],\n",
    "    max_epochs=200,\n",
    "    patience=20, batch_size=256, virtual_batch_size=128,\n",
    "    num_workers=1, drop_last=True)\n",
    "model = TabNetClassifier(**params)\n",
    "model.fit(\n",
    "    X_train=x_tr1,\n",
    "    y_train=y_tr1,\n",
    "    eval_set=[(x_va1, y_va1)],\n",
    "    eval_name = [\"valid\"],\n",
    "    eval_metric = [\"auc\"],\n",
    "    max_epochs=200,\n",
    "    patience=20, \n",
    "    batch_size=256,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0, \n",
    "    drop_last=False,\n",
    "    from_unsupervised=pretrainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "31d4307d-4a67-4228-85a7-140c68b0f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[検証データ] acc: 0.7729\n",
      "[ベースライン検証データ] acc: 0.7667\n",
      "[検証データ] auc: 0.7212\n",
      "[ベースライン検証データ] auc: 0.7820\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#評価指標の差\n",
    "y_va1_pred = model.predict(x_va1)\n",
    "y_va2_pred = model.predict(x_va2)\n",
    "print('[検証データ] acc: {:.4f}'.format(accuracy_score(y_va1, y_va1_pred)))\n",
    "print('[ベースライン検証データ] acc: {:.4f}'.format(accuracy_score(y_va2, y_va2_pred)))\n",
    "\n",
    "y_va1_pred_proba = model.predict_proba(x_va1)\n",
    "y_va2_pred_proba = model.predict_proba(x_va2)\n",
    "print('[検証データ] auc: {:.4f}'.format(roc_auc_score(y_va1, y_va1_pred_proba[:,1])))\n",
    "print('[ベースライン検証データ] auc: {:.4f}'.format(roc_auc_score(y_va2, y_va2_pred_proba[:,1])))\n",
    "\n",
    "\n",
    "for param in ['loss', 'valid_auc']:\n",
    "    plt.plot(model.history[param], label=param)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0dc60f74-2285-4d97-981c-7bc45559170c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証データ\n",
      "[[324  41]\n",
      " [ 68  47]]\n",
      "[[0.675      0.08541667]\n",
      " [0.14166667 0.09791667]]\n",
      "ベースライン検証データ\n",
      "[[413  44]\n",
      " [ 96  47]]\n",
      "[[0.68833333 0.07333333]\n",
      " [0.16       0.07833333]]\n"
     ]
    }
   ],
   "source": [
    "#誤分類の分布\n",
    "print('検証データ')\n",
    "print(confusion_matrix(y_va1, y_va1_pred))\n",
    "print(confusion_matrix(y_va1, y_va1_pred, normalize='all'))\n",
    "\n",
    "print('ベースライン検証データ')\n",
    "print(confusion_matrix(y_va2, y_va2_pred))\n",
    "print(confusion_matrix(y_va2, y_va2_pred, normalize='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ff7889ac-c105-4fa2-9d93-d60b7a3b66d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xffff3960a130>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 予測値の分布\n",
    "y_va1_pred_prob = model.predict_proba(x_va1)[:,1]\n",
    "y_va2_pred_prob = model.predict_proba(x_va2)[:,1]\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "fig.add_subplot(2,1,1)\n",
    "plt.title('validation_data')\n",
    "plt.hist(y_va1_pred_prob[np.array(y_va1).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va1_pred_prob[np.array(y_va1).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(2,1,2)\n",
    "plt.title('basreline_validation_data')\n",
    "plt.hist(y_va2_pred_prob[np.array(y_va2).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va2_pred_prob[np.array(y_va2).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328625a6-3203-4c10-b4de-62d8a519061d",
   "metadata": {},
   "source": [
    "## チューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a4209557-3c7f-4f15-8e61-4d7a3fda9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "raw",
   "id": "468b2b1a-4d31-4f98-bb7d-b4390a0480cf",
   "metadata": {},
   "source": [
    "params = {'n_d': 8, #値が大きいほど表現力と過学習のリスクがあがる\n",
    "          'n_a': 8, # n_dと同じ値にしておくのが良いらしい\n",
    "          'n_steps': 3,#TabNetEncoderのstepを何回繰り返すか\n",
    "          'gamma': 1.3,\n",
    "          'n_independent': 2,\n",
    "          'n_shared': 2,\n",
    "          'seed':random_state,\n",
    "          'lambda_sparse': 1e-3,\n",
    "          'optimizer_fn': torch.optim.Adam, \n",
    "          'optimizer_params': {'lr':2e-2},\n",
    "          'mask_type': \"entmax\",#AttentiveTransformerでマスク作るのにどっちの関数を使うか'sparsemax'or'entmax'\n",
    "          'scheduler_params':{'mode': \"min\",'patience': 5,'min_lr': 1e-5,'factor': 0.9},\n",
    "          'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "          'verbose':10\n",
    "         }\n",
    "         \n",
    "         n_d, n_a\t8-64\t8\n",
    "n_steps\t1-10\t3\n",
    "gamma\t1.0-2.0\t1.3\n",
    "mask_type\t\"entmatx\" or \"sparsemax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "534cd02b-5cdb-43d1-93d5-2fb92fcd7d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索しないパラメータ\n",
    "\n",
    "params_base = {\n",
    "   'optimizer_fn': torch.optim.Adam,\n",
    "   'optimizer_params': {'lr':2e-2,'weight_decay':1e-5},\n",
    "   'mask_type': \"entmax\",#AttentiveTransformerでマスク作るのにどっちの関数を使うか'sparsemax'or'entmax'\n",
    "   'scheduler_params':{'mode': \"min\",'patience': 5,'min_lr': 1e-5,'factor': 0.9, 'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,},\n",
    "   'verbose':10,\n",
    "   'seed': 123,\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # 探索するパラメータ\n",
    "    params_tuning = {\n",
    "        'n_d': trial.suggest_int('n_d',8,64),\n",
    "        'n_a': trial.suggest_int('n_a',8,64),\n",
    "        'n_steps': trial.suggest_int('n_steps', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n",
    "        'mask_type': trial.suggest_categorical('mask_type', ['entmatx','sparsemax']),\n",
    "    }\n",
    "    params_tuning.update(params_base)\n",
    "    \n",
    "    # モデル学習・評価\n",
    "    list_metrics = []\n",
    "    cv = list(StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state).split(X_train, y_train))\n",
    "    for nfold in np.arange(4):\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = X_train.loc[idx_tr, :], y_train.loc[idx_tr, :]\n",
    "        x_va, y_va = X_train.loc[idx_va, :], y_train.loc[idx_va, :]\n",
    "        y_tr=np.squeeze(y_tr.values)\n",
    "        y_va=np.squeeze(y_va.values)\n",
    "        x_tr=x_tr.values\n",
    "        x_va=x_va.values\n",
    "        pretrainer = TabNetPretrainer(**params)\n",
    "        pretrainer.fit(\n",
    "            X_train=x_tr,\n",
    "            eval_set=[x_va],\n",
    "            max_epochs=200,\n",
    "            patience=20, batch_size=256, virtual_batch_size=128,\n",
    "            num_workers=1, drop_last=True)\n",
    "        model = TabNetClassifier(**params)\n",
    "        model.fit(\n",
    "            X_train=x_tr,\n",
    "            y_train=y_tr,\n",
    "            eval_set=[(x_va, y_va)],\n",
    "            eval_name = [\"valid\"],\n",
    "            eval_metric = [\"auc\"],\n",
    "            max_epochs=200,\n",
    "            patience=20, \n",
    "            batch_size=256,\n",
    "            virtual_batch_size=128,\n",
    "            num_workers=0, \n",
    "            drop_last=False,\n",
    "            from_unsupervised=pretrainer\n",
    "        )\n",
    "        y_va_pred = model.predict_proba(x_va)[:,1]\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>0.5, 1, 0))\n",
    "        list_metrics.append(metric_va)\n",
    "        \n",
    "    # 評価値の計算\n",
    "    metrics = np.mean(list_metrics)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dfa2fe2d-edf5-416e-8b53-40cf1270f935",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:30:30,966]\u001b[0m A new study created in memory with name: no-name-97358861-6750-4be3-94dc-5e398a3eb469\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:02s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:11s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:11s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:02s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:31:44,567]\u001b[0m Trial 0 finished with value: 0.7753333333333332 and parameters: {'n_d': 47, 'n_a': 24, 'n_steps': 3, 'gamma': 1.5513147690828912, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:06s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:02s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:06s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:11s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:13s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:15s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:06s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:11s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:02s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:32:55,736]\u001b[0m Trial 1 finished with value: 0.7753333333333332 and parameters: {'n_d': 63, 'n_a': 47, 'n_steps': 5, 'gamma': 1.3921175181941505, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:06s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:02s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:06s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:11s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:13s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:15s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:06s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:11s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:02s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:34:07,213]\u001b[0m Trial 2 finished with value: 0.7753333333333332 and parameters: {'n_d': 32, 'n_a': 11, 'n_steps': 4, 'gamma': 1.7379954057320357, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:02s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:11s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:13s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:02s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:35:21,728]\u001b[0m Trial 3 finished with value: 0.7753333333333332 and parameters: {'n_d': 38, 'n_a': 38, 'n_steps': 7, 'gamma': 1.8494317940777896, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:02s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:02s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:36:38,123]\u001b[0m Trial 4 finished with value: 0.7753333333333332 and parameters: {'n_d': 49, 'n_a': 26, 'n_steps': 4, 'gamma': 1.2282632308789556, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:37:56,186]\u001b[0m Trial 5 finished with value: 0.7753333333333332 and parameters: {'n_d': 13, 'n_a': 32, 'n_steps': 5, 'gamma': 1.4936850976503062, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:39:13,485]\u001b[0m Trial 6 finished with value: 0.7753333333333332 and parameters: {'n_d': 32, 'n_a': 58, 'n_steps': 10, 'gamma': 1.5018366758843364, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:11s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:40:30,777]\u001b[0m Trial 7 finished with value: 0.7753333333333332 and parameters: {'n_d': 26, 'n_a': 31, 'n_steps': 9, 'gamma': 1.2504553653965067, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:10s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:41:47,958]\u001b[0m Trial 8 finished with value: 0.7753333333333332 and parameters: {'n_d': 37, 'n_a': 42, 'n_steps': 2, 'gamma': 1.8263408005068333, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:02s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:43:04,893]\u001b[0m Trial 9 finished with value: 0.7753333333333332 and parameters: {'n_d': 27, 'n_a': 25, 'n_steps': 5, 'gamma': 1.6813007657927965, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:44:23,374]\u001b[0m Trial 10 finished with value: 0.7753333333333332 and parameters: {'n_d': 56, 'n_a': 8, 'n_steps': 1, 'gamma': 1.0080611434040203, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:45:41,563]\u001b[0m Trial 11 finished with value: 0.7753333333333332 and parameters: {'n_d': 63, 'n_a': 51, 'n_steps': 3, 'gamma': 1.9862890564016848, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:46:58,772]\u001b[0m Trial 12 finished with value: 0.7753333333333332 and parameters: {'n_d': 48, 'n_a': 46, 'n_steps': 7, 'gamma': 1.555399472872045, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:48:16,133]\u001b[0m Trial 13 finished with value: 0.7753333333333332 and parameters: {'n_d': 64, 'n_a': 19, 'n_steps': 7, 'gamma': 1.3631357691972947, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:04s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:16s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:49:33,700]\u001b[0m Trial 14 finished with value: 0.7753333333333332 and parameters: {'n_d': 49, 'n_a': 59, 'n_steps': 3, 'gamma': 1.6071903264160659, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:02s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:50:51,407]\u001b[0m Trial 15 finished with value: 0.7753333333333332 and parameters: {'n_d': 56, 'n_a': 19, 'n_steps': 1, 'gamma': 1.4511497032783554, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:52:09,917]\u001b[0m Trial 16 finished with value: 0.7753333333333332 and parameters: {'n_d': 44, 'n_a': 49, 'n_steps': 6, 'gamma': 1.3844748717398336, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:10s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:15s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:10s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:53:30,394]\u001b[0m Trial 17 finished with value: 0.7753333333333332 and parameters: {'n_d': 57, 'n_a': 38, 'n_steps': 3, 'gamma': 1.6228321701158495, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:04s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:54:48,521]\u001b[0m Trial 18 finished with value: 0.7753333333333332 and parameters: {'n_d': 13, 'n_a': 54, 'n_steps': 6, 'gamma': 1.3222958430513911, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:56:06,843]\u001b[0m Trial 19 finished with value: 0.7753333333333332 and parameters: {'n_d': 43, 'n_a': 62, 'n_steps': 8, 'gamma': 1.5520330411371615, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:57:24,880]\u001b[0m Trial 20 finished with value: 0.7753333333333332 and parameters: {'n_d': 59, 'n_a': 15, 'n_steps': 4, 'gamma': 1.4356061202518677, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 15:58:43,370]\u001b[0m Trial 21 finished with value: 0.7753333333333332 and parameters: {'n_d': 21, 'n_a': 8, 'n_steps': 4, 'gamma': 1.7069340307634664, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:10s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:00:02,630]\u001b[0m Trial 22 finished with value: 0.7753333333333332 and parameters: {'n_d': 29, 'n_a': 14, 'n_steps': 2, 'gamma': 1.7163415570713012, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:10s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:15s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:10s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:01:23,283]\u001b[0m Trial 23 finished with value: 0.7753333333333332 and parameters: {'n_d': 20, 'n_a': 25, 'n_steps': 5, 'gamma': 1.6119687787895545, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:04s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:02:41,909]\u001b[0m Trial 24 finished with value: 0.7753333333333332 and parameters: {'n_d': 41, 'n_a': 31, 'n_steps': 4, 'gamma': 1.7913032879236999, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:04:00,353]\u001b[0m Trial 25 finished with value: 0.7753333333333332 and parameters: {'n_d': 33, 'n_a': 14, 'n_steps': 2, 'gamma': 1.494434901957632, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:04s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:09s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:05:18,450]\u001b[0m Trial 26 finished with value: 0.7753333333333332 and parameters: {'n_d': 52, 'n_a': 19, 'n_steps': 3, 'gamma': 1.7716585404282987, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:10s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:14s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:09s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:02s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:06:37,124]\u001b[0m Trial 27 finished with value: 0.7753333333333332 and parameters: {'n_d': 22, 'n_a': 42, 'n_steps': 6, 'gamma': 1.6495702502566643, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:10s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:15s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:10s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:07:56,480]\u001b[0m Trial 28 finished with value: 0.7753333333333332 and parameters: {'n_d': 53, 'n_a': 44, 'n_steps': 5, 'gamma': 1.570458959494639, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n",
      "epoch 0  | loss: 4.66211 | val_0_unsup_loss_numpy: 76.14083099365234|  0:00:00s\n",
      "epoch 10 | loss: 0.88762 | val_0_unsup_loss_numpy: 0.8428900241851807|  0:00:02s\n",
      "epoch 20 | loss: 0.87122 | val_0_unsup_loss_numpy: 0.7876499891281128|  0:00:05s\n",
      "epoch 30 | loss: 0.84353 | val_0_unsup_loss_numpy: 0.8093299865722656|  0:00:07s\n",
      "epoch 40 | loss: 0.82703 | val_0_unsup_loss_numpy: 0.8175699710845947|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_unsup_loss_numpy = 0.7775300145149231\n",
      "epoch 0  | loss: 1.07158 | valid_auc: 0.64214 |  0:00:00s\n",
      "epoch 10 | loss: 0.45758 | valid_auc: 0.77826 |  0:00:01s\n",
      "epoch 20 | loss: 0.44223 | valid_auc: 0.75638 |  0:00:03s\n",
      "epoch 30 | loss: 0.40664 | valid_auc: 0.76662 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_auc = 0.78278\n",
      "epoch 0  | loss: 4.60201 | val_0_unsup_loss_numpy: 129.75033569335938|  0:00:00s\n",
      "epoch 10 | loss: 0.8818  | val_0_unsup_loss_numpy: 0.9970300197601318|  0:00:02s\n",
      "epoch 20 | loss: 0.82286 | val_0_unsup_loss_numpy: 0.8647300004959106|  0:00:05s\n",
      "epoch 30 | loss: 0.81636 | val_0_unsup_loss_numpy: 0.8932200074195862|  0:00:07s\n",
      "epoch 40 | loss: 0.82027 | val_0_unsup_loss_numpy: 0.7983300089836121|  0:00:10s\n",
      "epoch 50 | loss: 0.83469 | val_0_unsup_loss_numpy: 0.8058800101280212|  0:00:12s\n",
      "epoch 60 | loss: 0.82595 | val_0_unsup_loss_numpy: 0.7843300104141235|  0:00:15s\n",
      "epoch 70 | loss: 0.82171 | val_0_unsup_loss_numpy: 0.8266900181770325|  0:00:17s\n",
      "epoch 80 | loss: 0.81925 | val_0_unsup_loss_numpy: 0.8165299892425537|  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 63 and best_val_0_unsup_loss_numpy = 0.7755100131034851\n",
      "epoch 0  | loss: 1.13162 | valid_auc: 0.63005 |  0:00:00s\n",
      "epoch 10 | loss: 0.45399 | valid_auc: 0.76139 |  0:00:01s\n",
      "epoch 20 | loss: 0.42908 | valid_auc: 0.76709 |  0:00:03s\n",
      "epoch 30 | loss: 0.40213 | valid_auc: 0.74607 |  0:00:04s\n",
      "epoch 40 | loss: 0.39516 | valid_auc: 0.72823 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_auc = 0.76709\n",
      "epoch 0  | loss: 6.26678 | val_0_unsup_loss_numpy: 78.71250915527344|  0:00:00s\n",
      "epoch 10 | loss: 0.92316 | val_0_unsup_loss_numpy: 1.0149999856948853|  0:00:02s\n",
      "epoch 20 | loss: 0.8642  | val_0_unsup_loss_numpy: 0.8862800002098083|  0:00:05s\n",
      "epoch 30 | loss: 0.84024 | val_0_unsup_loss_numpy: 0.8609099984169006|  0:00:07s\n",
      "epoch 40 | loss: 0.83158 | val_0_unsup_loss_numpy: 0.8148900270462036|  0:00:10s\n",
      "epoch 50 | loss: 0.85151 | val_0_unsup_loss_numpy: 0.8342999815940857|  0:00:12s\n",
      "epoch 60 | loss: 0.82654 | val_0_unsup_loss_numpy: 0.8303200006484985|  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_unsup_loss_numpy = 0.7800400257110596\n",
      "epoch 0  | loss: 1.09798 | valid_auc: 0.66295 |  0:00:00s\n",
      "epoch 10 | loss: 0.45795 | valid_auc: 0.76339 |  0:00:01s\n",
      "epoch 20 | loss: 0.42373 | valid_auc: 0.74995 |  0:00:03s\n",
      "epoch 30 | loss: 0.40934 | valid_auc: 0.75313 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_valid_auc = 0.76972\n",
      "epoch 0  | loss: 5.26208 | val_0_unsup_loss_numpy: 58.24449157714844|  0:00:00s\n",
      "epoch 10 | loss: 0.91939 | val_0_unsup_loss_numpy: 0.8246099948883057|  0:00:02s\n",
      "epoch 20 | loss: 0.82179 | val_0_unsup_loss_numpy: 0.8249499797821045|  0:00:05s\n",
      "epoch 30 | loss: 0.90394 | val_0_unsup_loss_numpy: 0.8633400201797485|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_unsup_loss_numpy = 0.7854800224304199\n",
      "epoch 0  | loss: 1.04692 | valid_auc: 0.61381 |  0:00:00s\n",
      "epoch 10 | loss: 0.44337 | valid_auc: 0.72121 |  0:00:01s\n",
      "epoch 20 | loss: 0.43488 | valid_auc: 0.74492 |  0:00:03s\n",
      "epoch 30 | loss: 0.41006 | valid_auc: 0.73427 |  0:00:04s\n",
      "epoch 40 | loss: 0.38169 | valid_auc: 0.72516 |  0:00:06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 16:09:16,939]\u001b[0m Trial 29 finished with value: 0.7753333333333332 and parameters: {'n_d': 39, 'n_a': 23, 'n_steps': 4, 'gamma': 1.864792365897348, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7753333333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_auc = 0.75124\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=random_state)\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3e7fef0c-0f29-45c8-ba99-18fd3708e29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(best)=0.7753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_d': 47,\n",
       " 'n_a': 24,\n",
       " 'n_steps': 3,\n",
       " 'gamma': 1.5513147690828912,\n",
       " 'mask_type': 'entmatx'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print('acc(best)={:.4f}'.format(trial.value))\n",
    "display(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7a422d94-c604-4bf8-b6ad-12586898ee99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_d': 47,\n",
       " 'n_a': 24,\n",
       " 'n_steps': 3,\n",
       " 'gamma': 1.5513147690828912,\n",
       " 'mask_type': 'entmax',\n",
       " 'optimizer_fn': torch.optim.adam.Adam,\n",
       " 'optimizer_params': {'lr': 0.02, 'weight_decay': 1e-05},\n",
       " 'scheduler_params': {'mode': 'min',\n",
       "  'patience': 5,\n",
       "  'min_lr': 1e-05,\n",
       "  'factor': 0.9,\n",
       "  'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau},\n",
       " 'verbose': 10,\n",
       " 'seed': 123}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_best = trial.params\n",
    "params_best.update(params_base)\n",
    "display(params_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ee80db-0b36-4869-86e9-98bb063d03c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
