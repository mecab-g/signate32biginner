{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9828789-bec1-4170-8a76-262379ab71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "#データ読み込み\n",
    "train = pd.read_csv(\"data_EDA/train.csv\")\n",
    "test = pd.read_csv(\"data_EDA/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "564c7484-3a88-48b9-8538-8ce80818836e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>...</th>\n",
       "      <th>Insulin_na</th>\n",
       "      <th>Pregnancies_na</th>\n",
       "      <th>Pre/age</th>\n",
       "      <th>SkinThickness_mean</th>\n",
       "      <th>BloodPressure_mean</th>\n",
       "      <th>Insulin_dpf_mean</th>\n",
       "      <th>Pregnancies_bin_0</th>\n",
       "      <th>Pregnancies_bin_-1</th>\n",
       "      <th>Pregnancies_bin_-3</th>\n",
       "      <th>Pregnancies_bin_3-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2509</td>\n",
       "      <td>3.584</td>\n",
       "      <td>114.3</td>\n",
       "      <td>68.77</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.86</td>\n",
       "      <td>35.59</td>\n",
       "      <td>0.4018</td>\n",
       "      <td>29.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.1203</td>\n",
       "      <td>26.71</td>\n",
       "      <td>71.37</td>\n",
       "      <td>136.5</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1438</td>\n",
       "      <td>3.054</td>\n",
       "      <td>21.99</td>\n",
       "      <td>16.17</td>\n",
       "      <td>14.06</td>\n",
       "      <td>49.83</td>\n",
       "      <td>6.937</td>\n",
       "      <td>0.2671</td>\n",
       "      <td>8.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2729</td>\n",
       "      <td>0.1876</td>\n",
       "      <td>0.09919</td>\n",
       "      <td>5.128</td>\n",
       "      <td>9.077</td>\n",
       "      <td>29.91</td>\n",
       "      <td>0.3245</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>0.4456</td>\n",
       "      <td>0.4346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.286</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1285</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.58</td>\n",
       "      <td>0.2346</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04545</td>\n",
       "      <td>26.88</td>\n",
       "      <td>64</td>\n",
       "      <td>135.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2550</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.81</td>\n",
       "      <td>0.2713</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09717</td>\n",
       "      <td>26.88</td>\n",
       "      <td>71.41</td>\n",
       "      <td>135.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3744</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>78</td>\n",
       "      <td>24.25</td>\n",
       "      <td>0</td>\n",
       "      <td>39.69</td>\n",
       "      <td>0.5064</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>26.88</td>\n",
       "      <td>78</td>\n",
       "      <td>135.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4995</td>\n",
       "      <td>13</td>\n",
       "      <td>199</td>\n",
       "      <td>110</td>\n",
       "      <td>52</td>\n",
       "      <td>744</td>\n",
       "      <td>52.96</td>\n",
       "      <td>2.176</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>52</td>\n",
       "      <td>110</td>\n",
       "      <td>744</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  \\\n",
       "count   2000         2000     2000           2000           2000     2000   \n",
       "mean    2509        3.584    114.3          68.77           11.2    11.86   \n",
       "std     1438        3.054    21.99          16.17          14.06    49.83   \n",
       "min        1            0       57              0              0        0   \n",
       "25%     1285            1      100             64              0        0   \n",
       "50%     2550            3      111             70              0        0   \n",
       "75%     3744            6      125             78          24.25        0   \n",
       "max     4995           13      199            110             52      744   \n",
       "\n",
       "        BMI  DiabetesPedigreeFunction   Age  Outcome  ...  Insulin_na  \\\n",
       "count  2000                      2000  2000        0  ...        2000   \n",
       "mean  35.59                    0.4018 29.08      NaN  ...       0.919   \n",
       "std   6.937                    0.2671 8.572      NaN  ...      0.2729   \n",
       "min   9.286                    0.1374    21      NaN  ...           0   \n",
       "25%   32.58                    0.2346    22      NaN  ...           1   \n",
       "50%   33.81                    0.2713    26      NaN  ...           1   \n",
       "75%   39.69                    0.5064    33      NaN  ...           1   \n",
       "max   52.96                     2.176    67      NaN  ...           1   \n",
       "\n",
       "       Pregnancies_na  Pre/age  SkinThickness_mean  BloodPressure_mean  \\\n",
       "count            2000     2000                2000                2000   \n",
       "mean           0.0365   0.1203               26.71               71.37   \n",
       "std            0.1876  0.09919               5.128               9.077   \n",
       "min                 0        0                   8                  38   \n",
       "25%                 0  0.04545               26.88                  64   \n",
       "50%                 0  0.09717               26.88               71.41   \n",
       "75%                 0   0.1717               26.88                  78   \n",
       "max                 1   0.5909                  52                 110   \n",
       "\n",
       "       Insulin_dpf_mean  Pregnancies_bin_0  Pregnancies_bin_-1  \\\n",
       "count              2000               2000                2000   \n",
       "mean              136.5             0.1195               0.355   \n",
       "std               29.91             0.3245              0.4786   \n",
       "min                  15                  0                   0   \n",
       "25%               135.6                  0                   0   \n",
       "50%               135.6                  0                   0   \n",
       "75%               135.6                  0                   1   \n",
       "max                 744                  1                   1   \n",
       "\n",
       "       Pregnancies_bin_-3  Pregnancies_bin_3-  \n",
       "count                2000                2000  \n",
       "mean                0.273              0.2525  \n",
       "std                0.4456              0.4346  \n",
       "min                     0                   0  \n",
       "25%                     0                   0  \n",
       "50%                     0                   0  \n",
       "75%                     1                   1  \n",
       "max                     1                   1  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4df67cb-c4bd-4f8c-8fb7-ef2b18cc8a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>...</th>\n",
       "      <th>Insulin_na</th>\n",
       "      <th>Pregnancies_na</th>\n",
       "      <th>Pre/age</th>\n",
       "      <th>SkinThickness_mean</th>\n",
       "      <th>BloodPressure_mean</th>\n",
       "      <th>Insulin_dpf_mean</th>\n",
       "      <th>Pregnancies_bin_0</th>\n",
       "      <th>Pregnancies_bin_-1</th>\n",
       "      <th>Pregnancies_bin_-3</th>\n",
       "      <th>Pregnancies_bin_3-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>...</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2493</td>\n",
       "      <td>3.557</td>\n",
       "      <td>113.7</td>\n",
       "      <td>68.74</td>\n",
       "      <td>11.16</td>\n",
       "      <td>11.66</td>\n",
       "      <td>35.41</td>\n",
       "      <td>0.4005</td>\n",
       "      <td>28.93</td>\n",
       "      <td>0.239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9147</td>\n",
       "      <td>0.03767</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>26.98</td>\n",
       "      <td>71.43</td>\n",
       "      <td>135.7</td>\n",
       "      <td>0.1433</td>\n",
       "      <td>0.3307</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1447</td>\n",
       "      <td>3.032</td>\n",
       "      <td>20.89</td>\n",
       "      <td>16.33</td>\n",
       "      <td>14.35</td>\n",
       "      <td>45.06</td>\n",
       "      <td>6.99</td>\n",
       "      <td>0.2747</td>\n",
       "      <td>8.469</td>\n",
       "      <td>0.4265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2794</td>\n",
       "      <td>0.1904</td>\n",
       "      <td>0.1003</td>\n",
       "      <td>5.248</td>\n",
       "      <td>9.04</td>\n",
       "      <td>23.92</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.4705</td>\n",
       "      <td>0.4451</td>\n",
       "      <td>0.4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.748</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1219</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.3</td>\n",
       "      <td>0.231</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04545</td>\n",
       "      <td>26.88</td>\n",
       "      <td>64</td>\n",
       "      <td>135.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2466</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.84</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09878</td>\n",
       "      <td>26.88</td>\n",
       "      <td>71.41</td>\n",
       "      <td>135.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3750</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>78</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>39.58</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>26.88</td>\n",
       "      <td>78</td>\n",
       "      <td>135.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4999</td>\n",
       "      <td>13</td>\n",
       "      <td>196</td>\n",
       "      <td>110</td>\n",
       "      <td>49</td>\n",
       "      <td>579</td>\n",
       "      <td>53.4</td>\n",
       "      <td>2.302</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619</td>\n",
       "      <td>49</td>\n",
       "      <td>110</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  \\\n",
       "count   3000         3000     3000           3000           3000     3000   \n",
       "mean    2493        3.557    113.7          68.74          11.16    11.66   \n",
       "std     1447        3.032    20.89          16.33          14.35    45.06   \n",
       "min        0            0       57              0              0        0   \n",
       "25%     1219            1      100             64              0        0   \n",
       "50%     2466            3      111             70              0        0   \n",
       "75%     3750            6      125             78             24        0   \n",
       "max     4999           13      196            110             49      579   \n",
       "\n",
       "        BMI  DiabetesPedigreeFunction   Age  Outcome  ...  Insulin_na  \\\n",
       "count  3000                      3000  3000     3000  ...        3000   \n",
       "mean  35.41                    0.4005 28.93    0.239  ...      0.9147   \n",
       "std    6.99                    0.2747 8.469   0.4265  ...      0.2794   \n",
       "min   7.748                    0.1458    21        0  ...           0   \n",
       "25%    32.3                     0.231    22        0  ...           1   \n",
       "50%   33.84                    0.2687    26        0  ...           1   \n",
       "75%   39.58                    0.5068    33        0  ...           1   \n",
       "max    53.4                     2.302    67        1  ...           1   \n",
       "\n",
       "       Pregnancies_na  Pre/age  SkinThickness_mean  BloodPressure_mean  \\\n",
       "count            3000     3000                3000                3000   \n",
       "mean          0.03767   0.1201               26.98               71.43   \n",
       "std            0.1904   0.1003               5.248                9.04   \n",
       "min                 0        0                   7                  46   \n",
       "25%                 0  0.04545               26.88                  64   \n",
       "50%                 0  0.09878               26.88               71.41   \n",
       "75%                 0   0.1724               26.88                  78   \n",
       "max                 1    0.619                  49                 110   \n",
       "\n",
       "       Insulin_dpf_mean  Pregnancies_bin_0  Pregnancies_bin_-1  \\\n",
       "count              3000               3000                3000   \n",
       "mean              135.7             0.1433              0.3307   \n",
       "std               23.92             0.3505              0.4705   \n",
       "min                  15                  0                   0   \n",
       "25%               135.6                  0                   0   \n",
       "50%               135.6                  0                   0   \n",
       "75%               135.6                  0                   1   \n",
       "max                 579                  1                   1   \n",
       "\n",
       "       Pregnancies_bin_-3  Pregnancies_bin_3-  \n",
       "count                3000                3000  \n",
       "mean                0.272               0.254  \n",
       "std                0.4451              0.4354  \n",
       "min                     0                   0  \n",
       "25%                     0                   0  \n",
       "50%                     0                   0  \n",
       "75%                     1                   1  \n",
       "max                     1                   1  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d779c6c7-9002-4310-9dca-a315b29a770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# まずは少ない特徴量から検討していく\n",
    "X_train = train[['DiabetesPedigreeFunction',\n",
    "                 'BMI',\n",
    "                 'Glucose',\n",
    "                 'Age',\n",
    "                 'Pregnancies',\n",
    "                 'SkinThickness',\n",
    "                 'Insulin',\n",
    "                 'BloodPressure',\n",
    "                 \n",
    "                 \n",
    "                 \n",
    "                \n",
    "             ]]\n",
    "id_train = train[['index']]\n",
    "y_train = train[['Outcome']]\n",
    "\n",
    "\n",
    "X_test = test[X_train.columns]\n",
    "id_test = test[id_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9456c50-0e72-466d-85c5-662a952f5c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiabetesPedigreeFunction\n",
      "BMI\n",
      "Glucose\n",
      "Age\n",
      "Pregnancies\n",
      "SkinThickness\n",
      "Insulin\n",
      "BloodPressure\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# 数値データ\n",
    "col_num = X_train.columns[X_train.dtypes!='object'].values.tolist()\n",
    "\n",
    "dict_num = {}\n",
    "for col in col_num:\n",
    "    print(col)\n",
    "    # 欠損値を0へ\n",
    "    value_fillna = 0 \n",
    "    X_train[col] = X_train[col].fillna(value_fillna)\n",
    "    # 正規化\n",
    "    value_min = X_train[col].min()\n",
    "    value_max = X_train[col].max()\n",
    "    value_mean = X_train[col].mean()\n",
    "    value_std = X_train[col].std()\n",
    "    #X_train[col] = (X_train[col] - value_min) / (value_max -value_min)\n",
    "    X_train[col] = (X_train[col] - value_mean) / value_std\n",
    "    \n",
    "    dict_num[col] = {}\n",
    "    dict_num[col]['fillna'] = value_fillna\n",
    "    dict_num[col]['min'] = value_min\n",
    "    dict_num[col]['max'] = value_max\n",
    "    dict_num[col]['mean'] = value_mean    \n",
    "    dict_num[col]['std'] = value_std  \n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b441ffe4-8346-4f77-ade1-571a4a1d180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# カテゴリデータ\n",
    "# （embedding予定でラベルエンコーダー）\n",
    "col_cat = X_train.columns[X_train.dtypes=='object'].values.tolist()\n",
    "\n",
    "dict_cat = {}\n",
    "for col in col_cat:\n",
    "    print(col)\n",
    "    value_fillna = 'unknown'\n",
    "    X_train[col] = X_train[cal].fillna(value_fillna)\n",
    "    \n",
    "    X_train[caol] = X_train[col].astype(str)\n",
    "    # strに変換\n",
    "    le = LabelEncorder()\n",
    "    le.fit(X_train[col])\n",
    "    list_labelsorted(list(set(le.classes_) | set(['unknown'])))\n",
    "    map_label = {j:i for i,j in enumerate(list_label)}\n",
    "    X_train[col] = X_train[col].map(map_label)\n",
    "    \n",
    "    dict_cat[col] = {}\n",
    "    dict_cat[col]['fillna'] = value_fillna\n",
    "    dict_cat[col]['map_label'] = map_label\n",
    "    dict_cat[col]['num_label'] = len(list_label)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ca4da6d-792c-41f7-a397-68d69834b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(input_x):\n",
    "    output_x = input_x.copy()\n",
    "    \n",
    "    for col in col_num:\n",
    "        value_fillna = dict_num[col]['fillna']\n",
    "        output_x[col] = output_x[col].fillna(value_fillna)\n",
    "        \n",
    "        value_min = dict_num[col]['min']\n",
    "        value_max = dict_num[col]['max']\n",
    "        value_mean = dict_num[col]['mean']\n",
    "        value_std = dict_num[col]['std']\n",
    "        \n",
    "        output_x[col]  = (output_x[col] - value_mean ) / (value_std)\n",
    "        \n",
    "    for col in col_cat:\n",
    "        value_fillna = dict_cat[col]['fillna']\n",
    "        output_x[col] = output_x[col].fillna(value_fillna)\n",
    "        \n",
    "        output_x[col] = output_x[col].astype(str)\n",
    "        \n",
    "        map_label = dict_catt[col]['map_label']\n",
    "        output_x[col] = output_x[col].map(map_label)\n",
    "        \n",
    "        #対応するものがない場合はunkoumn\n",
    "        output_x[col] = output_x[col].fillna(map_label['unknown'])\n",
    "        \n",
    "    return output_x\n",
    "\n",
    "X_test = transform_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b322d24d-594b-43f5-98e9-037f78b28046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BloodPressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.599e-16</td>\n",
       "      <td>-5.797e-16</td>\n",
       "      <td>1.007e-16</td>\n",
       "      <td>1.563e-16</td>\n",
       "      <td>4.619e-17</td>\n",
       "      <td>1.451e-17</td>\n",
       "      <td>4.441e-17</td>\n",
       "      <td>-1.918e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.9271</td>\n",
       "      <td>-3.957</td>\n",
       "      <td>-2.716</td>\n",
       "      <td>-0.9366</td>\n",
       "      <td>-1.173</td>\n",
       "      <td>-0.7779</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>-4.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.6171</td>\n",
       "      <td>-0.4445</td>\n",
       "      <td>-0.6576</td>\n",
       "      <td>-0.8185</td>\n",
       "      <td>-0.8433</td>\n",
       "      <td>-0.7779</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>-0.2904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.4799</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.1309</td>\n",
       "      <td>-0.3462</td>\n",
       "      <td>-0.1837</td>\n",
       "      <td>-0.7779</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>0.07692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.387</td>\n",
       "      <td>0.5965</td>\n",
       "      <td>0.5394</td>\n",
       "      <td>0.4803</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>0.8944</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>0.5667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.923</td>\n",
       "      <td>2.574</td>\n",
       "      <td>3.939</td>\n",
       "      <td>4.495</td>\n",
       "      <td>3.114</td>\n",
       "      <td>2.636</td>\n",
       "      <td>12.59</td>\n",
       "      <td>2.526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DiabetesPedigreeFunction        BMI   Glucose       Age  Pregnancies  \\\n",
       "count                      3000       3000      3000      3000         3000   \n",
       "mean                  1.599e-16 -5.797e-16 1.007e-16 1.563e-16    4.619e-17   \n",
       "std                           1          1         1         1            1   \n",
       "min                     -0.9271     -3.957    -2.716   -0.9366       -1.173   \n",
       "25%                     -0.6171    -0.4445   -0.6576   -0.8185      -0.8433   \n",
       "50%                     -0.4799     -0.225   -0.1309   -0.3462      -0.1837   \n",
       "75%                       0.387     0.5965    0.5394    0.4803       0.8057   \n",
       "max                       6.923      2.574     3.939     4.495        3.114   \n",
       "\n",
       "       SkinThickness   Insulin  BloodPressure  \n",
       "count           3000      3000           3000  \n",
       "mean       1.451e-17 4.441e-17     -1.918e-16  \n",
       "std                1         1              1  \n",
       "min          -0.7779   -0.2588         -4.209  \n",
       "25%          -0.7779   -0.2588        -0.2904  \n",
       "50%          -0.7779   -0.2588        0.07692  \n",
       "75%           0.8944   -0.2588         0.5667  \n",
       "max            2.636     12.59          2.526  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.4g}'.format\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1638f98-c1b6-48ee-a765-6369e686e7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BloodPressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.01694</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.001398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.9723</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>1.053</td>\n",
       "      <td>1.012</td>\n",
       "      <td>1.007</td>\n",
       "      <td>0.9794</td>\n",
       "      <td>1.106</td>\n",
       "      <td>0.9903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.9579</td>\n",
       "      <td>-3.737</td>\n",
       "      <td>-2.716</td>\n",
       "      <td>-0.9366</td>\n",
       "      <td>-1.173</td>\n",
       "      <td>-0.7779</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>-4.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.6038</td>\n",
       "      <td>-0.4045</td>\n",
       "      <td>-0.6576</td>\n",
       "      <td>-0.8185</td>\n",
       "      <td>-0.8433</td>\n",
       "      <td>-0.7779</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>-0.2904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.4704</td>\n",
       "      <td>-0.2281</td>\n",
       "      <td>-0.1309</td>\n",
       "      <td>-0.3462</td>\n",
       "      <td>-0.1837</td>\n",
       "      <td>-0.7779</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>0.07692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.3858</td>\n",
       "      <td>0.6131</td>\n",
       "      <td>0.5394</td>\n",
       "      <td>0.4803</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>0.9118</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>0.5667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.464</td>\n",
       "      <td>2.511</td>\n",
       "      <td>4.083</td>\n",
       "      <td>4.495</td>\n",
       "      <td>3.114</td>\n",
       "      <td>2.845</td>\n",
       "      <td>16.25</td>\n",
       "      <td>2.526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DiabetesPedigreeFunction     BMI  Glucose     Age  Pregnancies  \\\n",
       "count                      2000    2000     2000    2000         2000   \n",
       "mean                   0.004658 0.02542   0.0268 0.01694     0.008905   \n",
       "std                      0.9723  0.9924    1.053   1.012        1.007   \n",
       "min                     -0.9579  -3.737   -2.716 -0.9366       -1.173   \n",
       "25%                     -0.6038 -0.4045  -0.6576 -0.8185      -0.8433   \n",
       "50%                     -0.4704 -0.2281  -0.1309 -0.3462      -0.1837   \n",
       "75%                      0.3858  0.6131   0.5394  0.4803       0.8057   \n",
       "max                       6.464   2.511    4.083   4.495        3.114   \n",
       "\n",
       "       SkinThickness  Insulin  BloodPressure  \n",
       "count           2000     2000           2000  \n",
       "mean        0.002787 0.004342       0.001398  \n",
       "std           0.9794    1.106         0.9903  \n",
       "min          -0.7779  -0.2588         -4.209  \n",
       "25%          -0.7779  -0.2588        -0.2904  \n",
       "50%          -0.7779  -0.2588        0.07692  \n",
       "75%           0.9118  -0.2588         0.5667  \n",
       "max            2.845    16.25          2.526  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b84c0a7-0533-442f-94a4-cf5d5b9720f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "random_state=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "188c5d42-7fcd-4c2c-a2d6-e9a8896de4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1,\n",
    "        inter_op_parallelism_threads=1\n",
    "    )\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11843a2-84ac-4a99-8f3d-bc716ae893f7",
   "metadata": {},
   "source": [
    "## validation方法 NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "81657fd1-039d-4c1a-a464-20b69ac9ff4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_num = Input(shape=(8,))\n",
    "    x_num = Dense(10, activation='relu')(input_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.3)(x_num)\n",
    "    x_num = Dense(10, activation='relu')(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.2)(x_num)\n",
    "    x_num = Dense(5, activation='relu')(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.1)(x_num)\n",
    "    out = Dense(1, activation='sigmoid')(x_num)\n",
    "    \n",
    "    model = Model(inputs=input_num, outputs=out,)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='Adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_crossentropy'],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "44798591-6ec9-4ec6-9d9a-d8fd8c8701a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 10)                90        \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 5)                20        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361\n",
      "Trainable params: 311\n",
      "Non-trainable params: 50\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデルの確認\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43777692-d1d6-45ed-b5ae-e6c75760d1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 2.092050209205021, 0.0: 0.657030223390276}\n"
     ]
    }
   ],
   "source": [
    "#不均衡データ用の重み\n",
    "class_weights = list(class_weight.compute_class_weight('balanced', \n",
    "                                                           classes=np.unique(y_train['Outcome']),\n",
    "                                                           y=y_train['Outcome'])\n",
    "                        )\n",
    "class_weights.reverse()\n",
    "# fit時にclass_weightに辞書でに有力\n",
    "weight_dict = dict(zip(y_train['Outcome'], class_weights))\n",
    "print(weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "79e21f82-16fc-49ed-b576-42909918c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvでの評価用\n",
    "def train_nn(input_x,\n",
    "              input_y,\n",
    "              input_id,\n",
    "              list_nfold=[0,1,2,3,4],\n",
    "              n_splits=5,\n",
    "              random_state=123\n",
    "            ):\n",
    "    train_oof = np.zeros(len(input_x))\n",
    "    # foldごとの推論値\n",
    "    metrics = []\n",
    "    imp = pd.DataFrame()\n",
    "                         \n",
    "    cv = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state).\n",
    "              split(input_x, input_y))\n",
    "    \n",
    "    for nfold in list_nfold:\n",
    "        print('-'*20, nfold, '-'*20)\n",
    "        \n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = input_x.loc[idx_tr, :], input_y.loc[idx_tr, :]\n",
    "        x_va, y_va = input_x.loc[idx_va, :], input_y.loc[idx_va, :]\n",
    "        print(x_tr.shape, y_tr.shape)\n",
    "        print(x_va.shape, y_va.shape)\n",
    "        print('y_train:{:.3f}, y_tr:{:.3f}, y_va{:.3f}'.\n",
    "              format(y_train['Outcome'].mean(), y_tr['Outcome'].mean(), y_va['Outcome'].mean(),))\n",
    "\n",
    "        model = create_model()\n",
    "        model.fit(x=x_tr,\n",
    "                  y=y_tr,\n",
    "                 validation_data=(x_va, y_va),\n",
    "                 batch_size=8,\n",
    "                 epochs=1000,\n",
    "                 class_weight=None,\n",
    "                 callbacks=[ModelCheckpoint(filepath='model_keras.h5',\n",
    "                                            moniter='val_loss',\n",
    "                                            mode='min', \n",
    "                                            verbose=1,\n",
    "                                            save_best_only=True,\n",
    "                                            ),\n",
    "                            EarlyStopping(monitor='val_loss',\n",
    "                                          mode='min',\n",
    "                                          min_delta=0,\n",
    "                                          patience=5,\n",
    "                                          verbose=1,\n",
    "                                          restore_best_weights=True),\n",
    "                            ReduceLROnPlateau(moniter='val_loss',\n",
    "                                             mode='min',\n",
    "                                             factor=0.1,\n",
    "                                             patience=5,\n",
    "                                             verbose=1),\n",
    "                           ],\n",
    "                  verbose=1,\n",
    "                 )\n",
    "\n",
    "        # モデルの保存\n",
    "        fname_nn = 'model/nn/model_nn_fold{}.pickle'.format(nfold)\n",
    "        with open(fname_nn, 'wb')as f:\n",
    "            pickle.dump(model, f, protocol=4)\n",
    "            \n",
    "            \n",
    "        # 評価\n",
    "        y_tr_pred = model.predict(x_tr)\n",
    "        y_va_pred = model.predict(x_va)\n",
    "        metric_tr = accuracy_score(y_tr, np.where(y_tr_pred>=0.5,1,0))\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>=0.5,1,0))\n",
    "        print('[accuracy] tr: {:.2f}, va: {:2f}'.\n",
    "             format(metric_tr, metric_va))\n",
    "        metrics.append([nfold, metric_tr, metric_va])\n",
    "        \n",
    "        # oof\n",
    "        train_oof[idx_va] = np.squeeze(y_va_pred)\n",
    "        \n",
    "        \n",
    "        print('-'*20, 'result', '-'*20)\n",
    "    \n",
    "    # metrix出力\n",
    "    metrics = np.array(metrics)\n",
    "    print(metrics)\n",
    "    print('[cv] tr: {:.2f}+-{:.2f}, va: {:.2f}'.format(\n",
    "        metrics[:,1].mean(), metrics[:,1].std(),\n",
    "        metrics[:,2].mean(), metrics[:,2].std()\n",
    "    ))\n",
    "    print('[oof] {:.4f}'.format(\n",
    "        accuracy_score(input_y, np.where(train_oof>=0.5,1,0))))\n",
    "    # oof出力  \n",
    "    train_oof = pd.concat([\n",
    "        input_id,\n",
    "        pd.DataFrame({'pred':train_oof})]\n",
    "        ,axis=1)\n",
    "\n",
    "    print('Done')\n",
    "    \n",
    "    return train_oof, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf1c7951-6b35-4f07-894d-814aa7eca215",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "(2400, 8) (2400, 1)\n",
      "(600, 8) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.240\n",
      "Epoch 1/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.6518 - binary_crossentropy: 0.6518\n",
      "Epoch 1: val_loss improved from inf to 0.54800, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.6505 - binary_crossentropy: 0.6505 - val_loss: 0.5480 - val_binary_crossentropy: 0.5480 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.5651 - binary_crossentropy: 0.5651\n",
      "Epoch 2: val_loss improved from 0.54800 to 0.51699, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5645 - binary_crossentropy: 0.5645 - val_loss: 0.5170 - val_binary_crossentropy: 0.5170 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.5432 - binary_crossentropy: 0.5432\n",
      "Epoch 3: val_loss improved from 0.51699 to 0.50391, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5450 - binary_crossentropy: 0.5450 - val_loss: 0.5039 - val_binary_crossentropy: 0.5039 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.5384 - binary_crossentropy: 0.5384\n",
      "Epoch 4: val_loss improved from 0.50391 to 0.49955, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5376 - binary_crossentropy: 0.5376 - val_loss: 0.4995 - val_binary_crossentropy: 0.4995 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5319 - binary_crossentropy: 0.5319\n",
      "Epoch 5: val_loss improved from 0.49955 to 0.49610, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5319 - binary_crossentropy: 0.5319 - val_loss: 0.4961 - val_binary_crossentropy: 0.4961 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.5261 - binary_crossentropy: 0.5261\n",
      "Epoch 6: val_loss improved from 0.49610 to 0.49338, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5272 - binary_crossentropy: 0.5272 - val_loss: 0.4934 - val_binary_crossentropy: 0.4934 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.5209 - binary_crossentropy: 0.5209\n",
      "Epoch 7: val_loss improved from 0.49338 to 0.48696, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5226 - binary_crossentropy: 0.5226 - val_loss: 0.4870 - val_binary_crossentropy: 0.4870 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.5234 - binary_crossentropy: 0.5234\n",
      "Epoch 8: val_loss improved from 0.48696 to 0.48487, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5209 - binary_crossentropy: 0.5209 - val_loss: 0.4849 - val_binary_crossentropy: 0.4849 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "283/300 [===========================>..] - ETA: 0s - loss: 0.5132 - binary_crossentropy: 0.5132\n",
      "Epoch 9: val_loss improved from 0.48487 to 0.48027, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5151 - binary_crossentropy: 0.5151 - val_loss: 0.4803 - val_binary_crossentropy: 0.4803 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.5149 - binary_crossentropy: 0.5149\n",
      "Epoch 10: val_loss improved from 0.48027 to 0.47767, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5154 - binary_crossentropy: 0.5154 - val_loss: 0.4777 - val_binary_crossentropy: 0.4777 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.5058 - binary_crossentropy: 0.5058\n",
      "Epoch 11: val_loss improved from 0.47767 to 0.47559, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5077 - binary_crossentropy: 0.5077 - val_loss: 0.4756 - val_binary_crossentropy: 0.4756 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.5162 - binary_crossentropy: 0.5162\n",
      "Epoch 12: val_loss improved from 0.47559 to 0.47341, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5116 - binary_crossentropy: 0.5116 - val_loss: 0.4734 - val_binary_crossentropy: 0.4734 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.5013 - binary_crossentropy: 0.5013\n",
      "Epoch 13: val_loss did not improve from 0.47341\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5040 - binary_crossentropy: 0.5040 - val_loss: 0.4740 - val_binary_crossentropy: 0.4740 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.5099 - binary_crossentropy: 0.5099\n",
      "Epoch 14: val_loss improved from 0.47341 to 0.47220, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5110 - binary_crossentropy: 0.5110 - val_loss: 0.4722 - val_binary_crossentropy: 0.4722 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.5092 - binary_crossentropy: 0.5092\n",
      "Epoch 15: val_loss improved from 0.47220 to 0.47000, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5077 - binary_crossentropy: 0.5077 - val_loss: 0.4700 - val_binary_crossentropy: 0.4700 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.5078 - binary_crossentropy: 0.5078\n",
      "Epoch 16: val_loss did not improve from 0.47000\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5080 - binary_crossentropy: 0.5080 - val_loss: 0.4708 - val_binary_crossentropy: 0.4708 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.4993 - binary_crossentropy: 0.4993\n",
      "Epoch 17: val_loss improved from 0.47000 to 0.46551, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5032 - binary_crossentropy: 0.5032 - val_loss: 0.4655 - val_binary_crossentropy: 0.4655 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.5042 - binary_crossentropy: 0.5042\n",
      "Epoch 18: val_loss did not improve from 0.46551\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5054 - binary_crossentropy: 0.5054 - val_loss: 0.4671 - val_binary_crossentropy: 0.4671 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.4964 - binary_crossentropy: 0.4964\n",
      "Epoch 19: val_loss improved from 0.46551 to 0.46383, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4950 - binary_crossentropy: 0.4950 - val_loss: 0.4638 - val_binary_crossentropy: 0.4638 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.5020 - binary_crossentropy: 0.5020\n",
      "Epoch 20: val_loss improved from 0.46383 to 0.46369, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5009 - binary_crossentropy: 0.5009 - val_loss: 0.4637 - val_binary_crossentropy: 0.4637 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.4962 - binary_crossentropy: 0.4962\n",
      "Epoch 21: val_loss improved from 0.46369 to 0.46217, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4963 - binary_crossentropy: 0.4963 - val_loss: 0.4622 - val_binary_crossentropy: 0.4622 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.4914 - binary_crossentropy: 0.4914\n",
      "Epoch 22: val_loss improved from 0.46217 to 0.46065, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4884 - binary_crossentropy: 0.4884 - val_loss: 0.4607 - val_binary_crossentropy: 0.4607 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "280/300 [===========================>..] - ETA: 0s - loss: 0.4919 - binary_crossentropy: 0.4919\n",
      "Epoch 23: val_loss improved from 0.46065 to 0.46044, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4935 - binary_crossentropy: 0.4935 - val_loss: 0.4604 - val_binary_crossentropy: 0.4604 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.4921 - binary_crossentropy: 0.4921\n",
      "Epoch 24: val_loss did not improve from 0.46044\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4916 - binary_crossentropy: 0.4916 - val_loss: 0.4628 - val_binary_crossentropy: 0.4628 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.4956 - binary_crossentropy: 0.4956\n",
      "Epoch 25: val_loss did not improve from 0.46044\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4947 - binary_crossentropy: 0.4947 - val_loss: 0.4626 - val_binary_crossentropy: 0.4626 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.4855 - binary_crossentropy: 0.4855\n",
      "Epoch 26: val_loss improved from 0.46044 to 0.45949, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4853 - binary_crossentropy: 0.4853 - val_loss: 0.4595 - val_binary_crossentropy: 0.4595 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.5013 - binary_crossentropy: 0.5013\n",
      "Epoch 27: val_loss did not improve from 0.45949\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5007 - binary_crossentropy: 0.5007 - val_loss: 0.4599 - val_binary_crossentropy: 0.4599 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.4981 - binary_crossentropy: 0.4981\n",
      "Epoch 28: val_loss improved from 0.45949 to 0.45947, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.4960 - binary_crossentropy: 0.4960 - val_loss: 0.4595 - val_binary_crossentropy: 0.4595 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4971 - binary_crossentropy: 0.4971\n",
      "Epoch 29: val_loss did not improve from 0.45947\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4978 - binary_crossentropy: 0.4978 - val_loss: 0.4598 - val_binary_crossentropy: 0.4598 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "298/300 [============================>.] - ETA: 0s - loss: 0.4910 - binary_crossentropy: 0.4910\n",
      "Epoch 30: val_loss improved from 0.45947 to 0.45676, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4911 - binary_crossentropy: 0.4911 - val_loss: 0.4568 - val_binary_crossentropy: 0.4568 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.4987 - binary_crossentropy: 0.4987\n",
      "Epoch 31: val_loss did not improve from 0.45676\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4956 - binary_crossentropy: 0.4956 - val_loss: 0.4580 - val_binary_crossentropy: 0.4580 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.4913 - binary_crossentropy: 0.4913\n",
      "Epoch 32: val_loss improved from 0.45676 to 0.45642, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4908 - binary_crossentropy: 0.4908 - val_loss: 0.4564 - val_binary_crossentropy: 0.4564 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "283/300 [===========================>..] - ETA: 0s - loss: 0.4968 - binary_crossentropy: 0.4968\n",
      "Epoch 33: val_loss improved from 0.45642 to 0.45448, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4917 - binary_crossentropy: 0.4917 - val_loss: 0.4545 - val_binary_crossentropy: 0.4545 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.5014 - binary_crossentropy: 0.5014\n",
      "Epoch 34: val_loss did not improve from 0.45448\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5003 - binary_crossentropy: 0.5003 - val_loss: 0.4552 - val_binary_crossentropy: 0.4552 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4925 - binary_crossentropy: 0.4925\n",
      "Epoch 35: val_loss did not improve from 0.45448\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4912 - binary_crossentropy: 0.4912 - val_loss: 0.4570 - val_binary_crossentropy: 0.4570 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.4959 - binary_crossentropy: 0.4959\n",
      "Epoch 36: val_loss did not improve from 0.45448\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.4960 - binary_crossentropy: 0.4960 - val_loss: 0.4565 - val_binary_crossentropy: 0.4565 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4921 - binary_crossentropy: 0.4921\n",
      "Epoch 37: val_loss did not improve from 0.45448\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.4921 - binary_crossentropy: 0.4921 - val_loss: 0.4560 - val_binary_crossentropy: 0.4560 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.4884 - binary_crossentropy: 0.4884\n",
      "Epoch 38: val_loss did not improve from 0.45448\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4884 - binary_crossentropy: 0.4884 - val_loss: 0.4573 - val_binary_crossentropy: 0.4573 - lr: 0.0010\n",
      "Epoch 38: early stopping\n",
      "INFO:tensorflow:Assets written to: ram://8e6d195f-a873-490c-8197-96a0ae9e3c0c/assets\n",
      "75/75 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[accuracy] tr: 0.78, va: 0.778333\n",
      "-------------------- result --------------------\n",
      "-------------------- 1 --------------------\n",
      "(2400, 8) (2400, 1)\n",
      "(600, 8) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.240\n",
      "Epoch 1/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.6704 - binary_crossentropy: 0.6704\n",
      "Epoch 1: val_loss improved from inf to 0.54090, saving model to model_keras.h5\n",
      "300/300 [==============================] - 4s 7ms/step - loss: 0.6697 - binary_crossentropy: 0.6697 - val_loss: 0.5409 - val_binary_crossentropy: 0.5409 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.5700 - binary_crossentropy: 0.5700\n",
      "Epoch 2: val_loss improved from 0.54090 to 0.51083, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.5686 - binary_crossentropy: 0.5686 - val_loss: 0.5108 - val_binary_crossentropy: 0.5108 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.5429 - binary_crossentropy: 0.5429\n",
      "Epoch 3: val_loss improved from 0.51083 to 0.50172, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.5435 - binary_crossentropy: 0.5435 - val_loss: 0.5017 - val_binary_crossentropy: 0.5017 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.5322 - binary_crossentropy: 0.5322\n",
      "Epoch 4: val_loss improved from 0.50172 to 0.49416, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5327 - binary_crossentropy: 0.5327 - val_loss: 0.4942 - val_binary_crossentropy: 0.4942 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.5282 - binary_crossentropy: 0.5282\n",
      "Epoch 5: val_loss improved from 0.49416 to 0.49178, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5278 - binary_crossentropy: 0.5278 - val_loss: 0.4918 - val_binary_crossentropy: 0.4918 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.5194 - binary_crossentropy: 0.5194\n",
      "Epoch 6: val_loss improved from 0.49178 to 0.48946, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5223 - binary_crossentropy: 0.5223 - val_loss: 0.4895 - val_binary_crossentropy: 0.4895 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.5054 - binary_crossentropy: 0.5054\n",
      "Epoch 7: val_loss improved from 0.48946 to 0.48794, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5097 - binary_crossentropy: 0.5097 - val_loss: 0.4879 - val_binary_crossentropy: 0.4879 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.5149 - binary_crossentropy: 0.5149\n",
      "Epoch 8: val_loss improved from 0.48794 to 0.48495, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5132 - binary_crossentropy: 0.5132 - val_loss: 0.4849 - val_binary_crossentropy: 0.4849 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.5074 - binary_crossentropy: 0.5074\n",
      "Epoch 9: val_loss improved from 0.48495 to 0.48076, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5071 - binary_crossentropy: 0.5071 - val_loss: 0.4808 - val_binary_crossentropy: 0.4808 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.5121 - binary_crossentropy: 0.5121\n",
      "Epoch 10: val_loss improved from 0.48076 to 0.47945, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5129 - binary_crossentropy: 0.5129 - val_loss: 0.4795 - val_binary_crossentropy: 0.4795 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "298/300 [============================>.] - ETA: 0s - loss: 0.5126 - binary_crossentropy: 0.5126\n",
      "Epoch 11: val_loss improved from 0.47945 to 0.47894, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5128 - binary_crossentropy: 0.5128 - val_loss: 0.4789 - val_binary_crossentropy: 0.4789 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.5068 - binary_crossentropy: 0.5068\n",
      "Epoch 12: val_loss improved from 0.47894 to 0.47696, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5054 - binary_crossentropy: 0.5054 - val_loss: 0.4770 - val_binary_crossentropy: 0.4770 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.5035 - binary_crossentropy: 0.5035\n",
      "Epoch 13: val_loss improved from 0.47696 to 0.47278, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5019 - binary_crossentropy: 0.5019 - val_loss: 0.4728 - val_binary_crossentropy: 0.4728 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.5047 - binary_crossentropy: 0.5047\n",
      "Epoch 14: val_loss improved from 0.47278 to 0.47002, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5009 - binary_crossentropy: 0.5009 - val_loss: 0.4700 - val_binary_crossentropy: 0.4700 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.5029 - binary_crossentropy: 0.5029\n",
      "Epoch 15: val_loss improved from 0.47002 to 0.46956, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5051 - binary_crossentropy: 0.5051 - val_loss: 0.4696 - val_binary_crossentropy: 0.4696 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.4993 - binary_crossentropy: 0.4993\n",
      "Epoch 16: val_loss improved from 0.46956 to 0.46799, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4999 - binary_crossentropy: 0.4999 - val_loss: 0.4680 - val_binary_crossentropy: 0.4680 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4983 - binary_crossentropy: 0.4983\n",
      "Epoch 17: val_loss did not improve from 0.46799\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4983 - binary_crossentropy: 0.4983 - val_loss: 0.4690 - val_binary_crossentropy: 0.4690 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.4954 - binary_crossentropy: 0.4954\n",
      "Epoch 18: val_loss did not improve from 0.46799\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4978 - binary_crossentropy: 0.4978 - val_loss: 0.4684 - val_binary_crossentropy: 0.4684 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.4971 - binary_crossentropy: 0.4971\n",
      "Epoch 19: val_loss did not improve from 0.46799\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4985 - binary_crossentropy: 0.4985 - val_loss: 0.4689 - val_binary_crossentropy: 0.4689 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4870 - binary_crossentropy: 0.4870\n",
      "Epoch 20: val_loss improved from 0.46799 to 0.46749, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4893 - binary_crossentropy: 0.4893 - val_loss: 0.4675 - val_binary_crossentropy: 0.4675 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.4988 - binary_crossentropy: 0.4988\n",
      "Epoch 21: val_loss did not improve from 0.46749\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4978 - binary_crossentropy: 0.4978 - val_loss: 0.4677 - val_binary_crossentropy: 0.4677 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.5061 - binary_crossentropy: 0.5061\n",
      "Epoch 22: val_loss did not improve from 0.46749\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5060 - binary_crossentropy: 0.5060 - val_loss: 0.4681 - val_binary_crossentropy: 0.4681 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "279/300 [==========================>...] - ETA: 0s - loss: 0.4975 - binary_crossentropy: 0.4975\n",
      "Epoch 23: val_loss improved from 0.46749 to 0.46690, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4993 - binary_crossentropy: 0.4993 - val_loss: 0.4669 - val_binary_crossentropy: 0.4669 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4988 - binary_crossentropy: 0.4988\n",
      "Epoch 24: val_loss did not improve from 0.46690\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4980 - binary_crossentropy: 0.4980 - val_loss: 0.4672 - val_binary_crossentropy: 0.4672 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4944 - binary_crossentropy: 0.4944\n",
      "Epoch 25: val_loss improved from 0.46690 to 0.46621, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4934 - binary_crossentropy: 0.4934 - val_loss: 0.4662 - val_binary_crossentropy: 0.4662 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.4912 - binary_crossentropy: 0.4912\n",
      "Epoch 26: val_loss improved from 0.46621 to 0.46583, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4929 - binary_crossentropy: 0.4929 - val_loss: 0.4658 - val_binary_crossentropy: 0.4658 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.4963 - binary_crossentropy: 0.4963\n",
      "Epoch 27: val_loss did not improve from 0.46583\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4947 - binary_crossentropy: 0.4947 - val_loss: 0.4661 - val_binary_crossentropy: 0.4661 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.4989 - binary_crossentropy: 0.4989\n",
      "Epoch 28: val_loss did not improve from 0.46583\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4971 - binary_crossentropy: 0.4971 - val_loss: 0.4682 - val_binary_crossentropy: 0.4682 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "283/300 [===========================>..] - ETA: 0s - loss: 0.4960 - binary_crossentropy: 0.4960\n",
      "Epoch 29: val_loss did not improve from 0.46583\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4945 - binary_crossentropy: 0.4945 - val_loss: 0.4677 - val_binary_crossentropy: 0.4677 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.4907 - binary_crossentropy: 0.4907\n",
      "Epoch 30: val_loss did not improve from 0.46583\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4898 - binary_crossentropy: 0.4898 - val_loss: 0.4659 - val_binary_crossentropy: 0.4659 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.4927 - binary_crossentropy: 0.4927\n",
      "Epoch 31: val_loss did not improve from 0.46583\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4946 - binary_crossentropy: 0.4946 - val_loss: 0.4663 - val_binary_crossentropy: 0.4663 - lr: 0.0010\n",
      "Epoch 31: early stopping\n",
      "INFO:tensorflow:Assets written to: ram://0b5ca33c-d5ce-4a71-97fe-9692659b6920/assets\n",
      "75/75 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[accuracy] tr: 0.77, va: 0.781667\n",
      "-------------------- result --------------------\n",
      "-------------------- 2 --------------------\n",
      "(2400, 8) (2400, 1)\n",
      "(600, 8) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.238\n",
      "Epoch 1/1000\n",
      "280/300 [===========================>..] - ETA: 0s - loss: 0.6998 - binary_crossentropy: 0.6998\n",
      "Epoch 1: val_loss improved from inf to 0.57170, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.6918 - binary_crossentropy: 0.6918 - val_loss: 0.5717 - val_binary_crossentropy: 0.5717 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.5679 - binary_crossentropy: 0.5679\n",
      "Epoch 2: val_loss improved from 0.57170 to 0.52232, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5700 - binary_crossentropy: 0.5700 - val_loss: 0.5223 - val_binary_crossentropy: 0.5223 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.5330 - binary_crossentropy: 0.5330\n",
      "Epoch 3: val_loss improved from 0.52232 to 0.51792, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5350 - binary_crossentropy: 0.5350 - val_loss: 0.5179 - val_binary_crossentropy: 0.5179 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.5385 - binary_crossentropy: 0.5385\n",
      "Epoch 4: val_loss improved from 0.51792 to 0.51295, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5387 - binary_crossentropy: 0.5387 - val_loss: 0.5129 - val_binary_crossentropy: 0.5129 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.5243 - binary_crossentropy: 0.5243\n",
      "Epoch 5: val_loss improved from 0.51295 to 0.50968, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5235 - binary_crossentropy: 0.5235 - val_loss: 0.5097 - val_binary_crossentropy: 0.5097 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.5221 - binary_crossentropy: 0.5221\n",
      "Epoch 6: val_loss improved from 0.50968 to 0.50830, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5225 - binary_crossentropy: 0.5225 - val_loss: 0.5083 - val_binary_crossentropy: 0.5083 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.5234 - binary_crossentropy: 0.5234\n",
      "Epoch 7: val_loss improved from 0.50830 to 0.50712, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5218 - binary_crossentropy: 0.5218 - val_loss: 0.5071 - val_binary_crossentropy: 0.5071 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.5187 - binary_crossentropy: 0.5187\n",
      "Epoch 8: val_loss improved from 0.50712 to 0.50707, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5185 - binary_crossentropy: 0.5185 - val_loss: 0.5071 - val_binary_crossentropy: 0.5071 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.5083 - binary_crossentropy: 0.5083\n",
      "Epoch 9: val_loss improved from 0.50707 to 0.50520, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5086 - binary_crossentropy: 0.5086 - val_loss: 0.5052 - val_binary_crossentropy: 0.5052 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.5143 - binary_crossentropy: 0.5143\n",
      "Epoch 10: val_loss improved from 0.50520 to 0.50234, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5112 - binary_crossentropy: 0.5112 - val_loss: 0.5023 - val_binary_crossentropy: 0.5023 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "282/300 [===========================>..] - ETA: 0s - loss: 0.5071 - binary_crossentropy: 0.5071\n",
      "Epoch 11: val_loss improved from 0.50234 to 0.49982, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5040 - binary_crossentropy: 0.5040 - val_loss: 0.4998 - val_binary_crossentropy: 0.4998 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.5089 - binary_crossentropy: 0.5089\n",
      "Epoch 12: val_loss improved from 0.49982 to 0.49920, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5105 - binary_crossentropy: 0.5105 - val_loss: 0.4992 - val_binary_crossentropy: 0.4992 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.4980 - binary_crossentropy: 0.4980\n",
      "Epoch 13: val_loss improved from 0.49920 to 0.49677, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4938 - binary_crossentropy: 0.4938 - val_loss: 0.4968 - val_binary_crossentropy: 0.4968 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.5046 - binary_crossentropy: 0.5046\n",
      "Epoch 14: val_loss improved from 0.49677 to 0.49557, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5019 - binary_crossentropy: 0.5019 - val_loss: 0.4956 - val_binary_crossentropy: 0.4956 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.5043 - binary_crossentropy: 0.5043\n",
      "Epoch 15: val_loss improved from 0.49557 to 0.49428, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5057 - binary_crossentropy: 0.5057 - val_loss: 0.4943 - val_binary_crossentropy: 0.4943 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.4976 - binary_crossentropy: 0.4976\n",
      "Epoch 16: val_loss improved from 0.49428 to 0.49361, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4970 - binary_crossentropy: 0.4970 - val_loss: 0.4936 - val_binary_crossentropy: 0.4936 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "283/300 [===========================>..] - ETA: 0s - loss: 0.4877 - binary_crossentropy: 0.4877\n",
      "Epoch 17: val_loss improved from 0.49361 to 0.49276, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4906 - binary_crossentropy: 0.4906 - val_loss: 0.4928 - val_binary_crossentropy: 0.4928 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4994 - binary_crossentropy: 0.4994\n",
      "Epoch 18: val_loss improved from 0.49276 to 0.49248, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4962 - binary_crossentropy: 0.4962 - val_loss: 0.4925 - val_binary_crossentropy: 0.4925 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.4959 - binary_crossentropy: 0.4959\n",
      "Epoch 19: val_loss did not improve from 0.49248\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4955 - binary_crossentropy: 0.4955 - val_loss: 0.4934 - val_binary_crossentropy: 0.4934 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4884 - binary_crossentropy: 0.4884\n",
      "Epoch 20: val_loss improved from 0.49248 to 0.49074, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4912 - binary_crossentropy: 0.4912 - val_loss: 0.4907 - val_binary_crossentropy: 0.4907 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "282/300 [===========================>..] - ETA: 0s - loss: 0.4910 - binary_crossentropy: 0.4910\n",
      "Epoch 21: val_loss improved from 0.49074 to 0.48960, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4913 - binary_crossentropy: 0.4913 - val_loss: 0.4896 - val_binary_crossentropy: 0.4896 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.4847 - binary_crossentropy: 0.4847\n",
      "Epoch 22: val_loss improved from 0.48960 to 0.48828, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4840 - binary_crossentropy: 0.4840 - val_loss: 0.4883 - val_binary_crossentropy: 0.4883 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.4927 - binary_crossentropy: 0.4927\n",
      "Epoch 23: val_loss improved from 0.48828 to 0.48651, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4892 - binary_crossentropy: 0.4892 - val_loss: 0.4865 - val_binary_crossentropy: 0.4865 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.4902 - binary_crossentropy: 0.4902\n",
      "Epoch 24: val_loss improved from 0.48651 to 0.48533, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4905 - binary_crossentropy: 0.4905 - val_loss: 0.4853 - val_binary_crossentropy: 0.4853 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.4892 - binary_crossentropy: 0.4892\n",
      "Epoch 25: val_loss improved from 0.48533 to 0.48524, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4874 - binary_crossentropy: 0.4874 - val_loss: 0.4852 - val_binary_crossentropy: 0.4852 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.4967 - binary_crossentropy: 0.4967\n",
      "Epoch 26: val_loss did not improve from 0.48524\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4948 - binary_crossentropy: 0.4948 - val_loss: 0.4866 - val_binary_crossentropy: 0.4866 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4971 - binary_crossentropy: 0.4971\n",
      "Epoch 27: val_loss did not improve from 0.48524\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4971 - binary_crossentropy: 0.4971 - val_loss: 0.4868 - val_binary_crossentropy: 0.4868 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "282/300 [===========================>..] - ETA: 0s - loss: 0.4971 - binary_crossentropy: 0.4971\n",
      "Epoch 28: val_loss did not improve from 0.48524\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4903 - binary_crossentropy: 0.4903 - val_loss: 0.4860 - val_binary_crossentropy: 0.4860 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4943 - binary_crossentropy: 0.4943\n",
      "Epoch 29: val_loss did not improve from 0.48524\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4917 - binary_crossentropy: 0.4917 - val_loss: 0.4854 - val_binary_crossentropy: 0.4854 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4892 - binary_crossentropy: 0.4892\n",
      "Epoch 30: val_loss did not improve from 0.48524\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4907 - binary_crossentropy: 0.4907 - val_loss: 0.4858 - val_binary_crossentropy: 0.4858 - lr: 1.0000e-04\n",
      "Epoch 30: early stopping\n",
      "INFO:tensorflow:Assets written to: ram://fba9d043-a82f-4536-8099-6079313a223e/assets\n",
      "75/75 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[accuracy] tr: 0.77, va: 0.771667\n",
      "-------------------- result --------------------\n",
      "-------------------- 3 --------------------\n",
      "(2400, 8) (2400, 1)\n",
      "(600, 8) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.238\n",
      "Epoch 1/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.7034 - binary_crossentropy: 0.7034\n",
      "Epoch 1: val_loss improved from inf to 0.55778, saving model to model_keras.h5\n",
      "300/300 [==============================] - 3s 7ms/step - loss: 0.7015 - binary_crossentropy: 0.7015 - val_loss: 0.5578 - val_binary_crossentropy: 0.5578 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.5839 - binary_crossentropy: 0.5839\n",
      "Epoch 2: val_loss improved from 0.55778 to 0.52593, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5824 - binary_crossentropy: 0.5824 - val_loss: 0.5259 - val_binary_crossentropy: 0.5259 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "298/300 [============================>.] - ETA: 0s - loss: 0.5542 - binary_crossentropy: 0.5542\n",
      "Epoch 3: val_loss improved from 0.52593 to 0.51513, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5546 - binary_crossentropy: 0.5546 - val_loss: 0.5151 - val_binary_crossentropy: 0.5151 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.5378 - binary_crossentropy: 0.5378\n",
      "Epoch 4: val_loss improved from 0.51513 to 0.51053, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5401 - binary_crossentropy: 0.5401 - val_loss: 0.5105 - val_binary_crossentropy: 0.5105 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.5336 - binary_crossentropy: 0.5336\n",
      "Epoch 5: val_loss improved from 0.51053 to 0.50244, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5353 - binary_crossentropy: 0.5353 - val_loss: 0.5024 - val_binary_crossentropy: 0.5024 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.5298 - binary_crossentropy: 0.5298\n",
      "Epoch 6: val_loss improved from 0.50244 to 0.49702, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5315 - binary_crossentropy: 0.5315 - val_loss: 0.4970 - val_binary_crossentropy: 0.4970 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.5330 - binary_crossentropy: 0.5330\n",
      "Epoch 7: val_loss improved from 0.49702 to 0.49357, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5303 - binary_crossentropy: 0.5303 - val_loss: 0.4936 - val_binary_crossentropy: 0.4936 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.5237 - binary_crossentropy: 0.5237\n",
      "Epoch 8: val_loss improved from 0.49357 to 0.49305, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5263 - binary_crossentropy: 0.5263 - val_loss: 0.4930 - val_binary_crossentropy: 0.4930 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.5191 - binary_crossentropy: 0.5191\n",
      "Epoch 9: val_loss improved from 0.49305 to 0.48916, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5196 - binary_crossentropy: 0.5196 - val_loss: 0.4892 - val_binary_crossentropy: 0.4892 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.5151 - binary_crossentropy: 0.5151\n",
      "Epoch 10: val_loss improved from 0.48916 to 0.48582, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5174 - binary_crossentropy: 0.5174 - val_loss: 0.4858 - val_binary_crossentropy: 0.4858 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.5073 - binary_crossentropy: 0.5073\n",
      "Epoch 11: val_loss did not improve from 0.48582\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5083 - binary_crossentropy: 0.5083 - val_loss: 0.4862 - val_binary_crossentropy: 0.4862 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "298/300 [============================>.] - ETA: 0s - loss: 0.5158 - binary_crossentropy: 0.5158\n",
      "Epoch 12: val_loss improved from 0.48582 to 0.48407, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5171 - binary_crossentropy: 0.5171 - val_loss: 0.4841 - val_binary_crossentropy: 0.4841 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.5049 - binary_crossentropy: 0.5049\n",
      "Epoch 13: val_loss improved from 0.48407 to 0.47943, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5040 - binary_crossentropy: 0.5040 - val_loss: 0.4794 - val_binary_crossentropy: 0.4794 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.5056 - binary_crossentropy: 0.5056\n",
      "Epoch 14: val_loss improved from 0.47943 to 0.47894, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5050 - binary_crossentropy: 0.5050 - val_loss: 0.4789 - val_binary_crossentropy: 0.4789 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.5064 - binary_crossentropy: 0.5064\n",
      "Epoch 15: val_loss did not improve from 0.47894\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5081 - binary_crossentropy: 0.5081 - val_loss: 0.4793 - val_binary_crossentropy: 0.4793 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.5094 - binary_crossentropy: 0.5094\n",
      "Epoch 16: val_loss did not improve from 0.47894\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5097 - binary_crossentropy: 0.5097 - val_loss: 0.4793 - val_binary_crossentropy: 0.4793 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.5049 - binary_crossentropy: 0.5049\n",
      "Epoch 17: val_loss improved from 0.47894 to 0.47672, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.5027 - binary_crossentropy: 0.5027 - val_loss: 0.4767 - val_binary_crossentropy: 0.4767 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "298/300 [============================>.] - ETA: 0s - loss: 0.5082 - binary_crossentropy: 0.5082\n",
      "Epoch 18: val_loss did not improve from 0.47672\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5080 - binary_crossentropy: 0.5080 - val_loss: 0.4768 - val_binary_crossentropy: 0.4768 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.5040 - binary_crossentropy: 0.5040\n",
      "Epoch 19: val_loss improved from 0.47672 to 0.47522, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5009 - binary_crossentropy: 0.5009 - val_loss: 0.4752 - val_binary_crossentropy: 0.4752 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "298/300 [============================>.] - ETA: 0s - loss: 0.4973 - binary_crossentropy: 0.4973\n",
      "Epoch 20: val_loss improved from 0.47522 to 0.47384, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4972 - binary_crossentropy: 0.4972 - val_loss: 0.4738 - val_binary_crossentropy: 0.4738 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.5026 - binary_crossentropy: 0.5026\n",
      "Epoch 21: val_loss did not improve from 0.47384\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5040 - binary_crossentropy: 0.5040 - val_loss: 0.4753 - val_binary_crossentropy: 0.4753 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4945 - binary_crossentropy: 0.4945\n",
      "Epoch 22: val_loss did not improve from 0.47384\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4965 - binary_crossentropy: 0.4965 - val_loss: 0.4745 - val_binary_crossentropy: 0.4745 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.4973 - binary_crossentropy: 0.4973\n",
      "Epoch 23: val_loss improved from 0.47384 to 0.47215, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4986 - binary_crossentropy: 0.4986 - val_loss: 0.4721 - val_binary_crossentropy: 0.4721 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.4969 - binary_crossentropy: 0.4969\n",
      "Epoch 24: val_loss did not improve from 0.47215\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4954 - binary_crossentropy: 0.4954 - val_loss: 0.4737 - val_binary_crossentropy: 0.4737 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4992 - binary_crossentropy: 0.4992\n",
      "Epoch 25: val_loss did not improve from 0.47215\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4981 - binary_crossentropy: 0.4981 - val_loss: 0.4727 - val_binary_crossentropy: 0.4727 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.5025 - binary_crossentropy: 0.5025\n",
      "Epoch 26: val_loss did not improve from 0.47215\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.5038 - binary_crossentropy: 0.5038 - val_loss: 0.4739 - val_binary_crossentropy: 0.4739 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.4967 - binary_crossentropy: 0.4967\n",
      "Epoch 27: val_loss did not improve from 0.47215\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4977 - binary_crossentropy: 0.4977 - val_loss: 0.4739 - val_binary_crossentropy: 0.4739 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4958 - binary_crossentropy: 0.4958\n",
      "Epoch 28: val_loss improved from 0.47215 to 0.47087, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4960 - binary_crossentropy: 0.4960 - val_loss: 0.4709 - val_binary_crossentropy: 0.4709 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4948 - binary_crossentropy: 0.4948\n",
      "Epoch 29: val_loss did not improve from 0.47087\n",
      "300/300 [==============================] - 5s 15ms/step - loss: 0.4976 - binary_crossentropy: 0.4976 - val_loss: 0.4711 - val_binary_crossentropy: 0.4711 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.4926 - binary_crossentropy: 0.4926\n",
      "Epoch 30: val_loss improved from 0.47087 to 0.46928, saving model to model_keras.h5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.4910 - binary_crossentropy: 0.4910 - val_loss: 0.4693 - val_binary_crossentropy: 0.4693 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.5002 - binary_crossentropy: 0.5002\n",
      "Epoch 31: val_loss did not improve from 0.46928\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4980 - binary_crossentropy: 0.4980 - val_loss: 0.4707 - val_binary_crossentropy: 0.4707 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.4958 - binary_crossentropy: 0.4958\n",
      "Epoch 32: val_loss did not improve from 0.46928\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4955 - binary_crossentropy: 0.4955 - val_loss: 0.4705 - val_binary_crossentropy: 0.4705 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.4937 - binary_crossentropy: 0.4937\n",
      "Epoch 33: val_loss did not improve from 0.46928\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4932 - binary_crossentropy: 0.4932 - val_loss: 0.4703 - val_binary_crossentropy: 0.4703 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.4978 - binary_crossentropy: 0.4978\n",
      "Epoch 34: val_loss did not improve from 0.46928\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4959 - binary_crossentropy: 0.4959 - val_loss: 0.4717 - val_binary_crossentropy: 0.4717 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.4946 - binary_crossentropy: 0.4946\n",
      "Epoch 35: val_loss did not improve from 0.46928\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4957 - binary_crossentropy: 0.4957 - val_loss: 0.4721 - val_binary_crossentropy: 0.4721 - lr: 0.0010\n",
      "Epoch 35: early stopping\n",
      "INFO:tensorflow:Assets written to: ram://47a8ac3b-b7dc-468a-9464-223fb1ee0d68/assets\n",
      "75/75 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 4ms/step\n",
      "[accuracy] tr: 0.77, va: 0.763333\n",
      "-------------------- result --------------------\n",
      "-------------------- 4 --------------------\n",
      "(2400, 8) (2400, 1)\n",
      "(600, 8) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.238\n",
      "Epoch 1/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.7126 - binary_crossentropy: 0.7126\n",
      "Epoch 1: val_loss improved from inf to 0.61437, saving model to model_keras.h5\n",
      "300/300 [==============================] - 3s 6ms/step - loss: 0.7116 - binary_crossentropy: 0.7116 - val_loss: 0.6144 - val_binary_crossentropy: 0.6144 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5880 - binary_crossentropy: 0.5880\n",
      "Epoch 2: val_loss improved from 0.61437 to 0.56712, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5880 - binary_crossentropy: 0.5880 - val_loss: 0.5671 - val_binary_crossentropy: 0.5671 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.5571 - binary_crossentropy: 0.5571\n",
      "Epoch 3: val_loss improved from 0.56712 to 0.54853, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5566 - binary_crossentropy: 0.5566 - val_loss: 0.5485 - val_binary_crossentropy: 0.5485 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.5469 - binary_crossentropy: 0.5469\n",
      "Epoch 4: val_loss improved from 0.54853 to 0.54138, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5475 - binary_crossentropy: 0.5475 - val_loss: 0.5414 - val_binary_crossentropy: 0.5414 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.5286 - binary_crossentropy: 0.5286\n",
      "Epoch 5: val_loss improved from 0.54138 to 0.53558, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5289 - binary_crossentropy: 0.5289 - val_loss: 0.5356 - val_binary_crossentropy: 0.5356 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.5313 - binary_crossentropy: 0.5313\n",
      "Epoch 6: val_loss improved from 0.53558 to 0.53039, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5315 - binary_crossentropy: 0.5315 - val_loss: 0.5304 - val_binary_crossentropy: 0.5304 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.5344 - binary_crossentropy: 0.5344\n",
      "Epoch 7: val_loss improved from 0.53039 to 0.52744, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5337 - binary_crossentropy: 0.5337 - val_loss: 0.5274 - val_binary_crossentropy: 0.5274 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5177 - binary_crossentropy: 0.5177\n",
      "Epoch 8: val_loss improved from 0.52744 to 0.52446, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5177 - binary_crossentropy: 0.5177 - val_loss: 0.5245 - val_binary_crossentropy: 0.5245 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.5160 - binary_crossentropy: 0.5160\n",
      "Epoch 9: val_loss improved from 0.52446 to 0.52206, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5178 - binary_crossentropy: 0.5178 - val_loss: 0.5221 - val_binary_crossentropy: 0.5221 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.5087 - binary_crossentropy: 0.5087\n",
      "Epoch 10: val_loss improved from 0.52206 to 0.51949, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5112 - binary_crossentropy: 0.5112 - val_loss: 0.5195 - val_binary_crossentropy: 0.5195 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.5138 - binary_crossentropy: 0.5138\n",
      "Epoch 11: val_loss improved from 0.51949 to 0.51672, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5129 - binary_crossentropy: 0.5129 - val_loss: 0.5167 - val_binary_crossentropy: 0.5167 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.5091 - binary_crossentropy: 0.5091\n",
      "Epoch 12: val_loss improved from 0.51672 to 0.51540, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5092 - binary_crossentropy: 0.5092 - val_loss: 0.5154 - val_binary_crossentropy: 0.5154 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.5055 - binary_crossentropy: 0.5055\n",
      "Epoch 13: val_loss improved from 0.51540 to 0.51078, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5055 - binary_crossentropy: 0.5055 - val_loss: 0.5108 - val_binary_crossentropy: 0.5108 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.5058 - binary_crossentropy: 0.5058\n",
      "Epoch 14: val_loss improved from 0.51078 to 0.50854, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5086 - binary_crossentropy: 0.5086 - val_loss: 0.5085 - val_binary_crossentropy: 0.5085 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.5086 - binary_crossentropy: 0.5086\n",
      "Epoch 15: val_loss did not improve from 0.50854\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5078 - binary_crossentropy: 0.5078 - val_loss: 0.5092 - val_binary_crossentropy: 0.5092 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.4980 - binary_crossentropy: 0.4980\n",
      "Epoch 16: val_loss did not improve from 0.50854\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4978 - binary_crossentropy: 0.4978 - val_loss: 0.5086 - val_binary_crossentropy: 0.5086 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.4995 - binary_crossentropy: 0.4995\n",
      "Epoch 17: val_loss did not improve from 0.50854\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5003 - binary_crossentropy: 0.5003 - val_loss: 0.5101 - val_binary_crossentropy: 0.5101 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.4959 - binary_crossentropy: 0.4959\n",
      "Epoch 18: val_loss did not improve from 0.50854\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4963 - binary_crossentropy: 0.4963 - val_loss: 0.5101 - val_binary_crossentropy: 0.5101 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.4904 - binary_crossentropy: 0.4904\n",
      "Epoch 19: val_loss did not improve from 0.50854\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4920 - binary_crossentropy: 0.4920 - val_loss: 0.5094 - val_binary_crossentropy: 0.5094 - lr: 0.0010\n",
      "Epoch 19: early stopping\n",
      "INFO:tensorflow:Assets written to: ram://2ef6251a-98c5-4f71-9c26-71415ce50a3e/assets\n",
      "75/75 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "[accuracy] tr: 0.76, va: 0.761667\n",
      "-------------------- result --------------------\n",
      "[[0.         0.77541667 0.77833333]\n",
      " [1.         0.77458333 0.78166667]\n",
      " [2.         0.77125    0.77166667]\n",
      " [3.         0.76666667 0.76333333]\n",
      " [4.         0.76083333 0.76166667]]\n",
      "[cv] tr: 0.77+-0.01, va: 0.77\n",
      "[oof] 0.7713\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "train_oof, metrics = train_nn(X_train, y_train, id_train, list_nfold=[0,1,2,3,4], n_splits=5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "669556ca-f257-450a-8f6b-17ea79cff3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.3985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3832</td>\n",
       "      <td>0.1144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4927</td>\n",
       "      <td>0.4139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   pred\n",
       "0    200 0.3985\n",
       "1   3832 0.1144\n",
       "2   4927 0.4139"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oof[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaffb7f-6fa3-431f-bd0a-26028e65a3f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0c6f5328-321e-4d4c-b9e3-54e304d25b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_nn(input_x,\n",
    "               input_id,\n",
    "               list_nfold=[0,1,2,3,4],\n",
    "               ):\n",
    "    pred = np.zeros((len(input_x), len(list_nfold)))\n",
    "    for nfold in list_nfold:\n",
    "        print('-'*20, nfold, '-'*20)\n",
    "        fname_nn = 'model/nn/model_nn_fold{}.pickle'.format(nfold)\n",
    "        with open(fname_nn, 'rb')as f:\n",
    "            model = pickle.load(f)\n",
    "        pred[:,nfold] = np.squeeze(model.predict(input_x))\n",
    "        \n",
    "    pred = pd.concat([\n",
    "        input_id,\n",
    "        pd.DataFrame({'pred':pred.mean(axis=1)}),], axis=1)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "52c0dba4-b4e5-4909-98a9-4e004551adef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "-------------------- 1 --------------------\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "-------------------- 2 --------------------\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "-------------------- 3 --------------------\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "-------------------- 4 --------------------\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "test_pred_proba = predict_nn(X_test,\n",
    "                    id_test,\n",
    "                    list_nfold=[0,1,2,3,4],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6c5584d0-f263-4fdf-a668-3baa08295883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>0.2608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3833</td>\n",
       "      <td>0.1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4836</td>\n",
       "      <td>0.1148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   pred\n",
       "0    398 0.2608\n",
       "1   3833 0.1209\n",
       "2   4836 0.1148"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_proba[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "107ce42c-c7be-4a6d-9cdf-a96ae39d26ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  pred\n",
       "0    398     0\n",
       "1   3833     0\n",
       "2   4836     0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = test_pred_proba.copy()  \n",
    "test_pred['pred']=np.where(test_pred['pred'] < 0.5, 0, 1)\n",
    "test_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ce77972c-1165-472e-b3ef-a618d3337493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.3985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3832</td>\n",
       "      <td>0.1144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4927</td>\n",
       "      <td>0.4139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   pred\n",
       "0    200 0.3985\n",
       "1   3832 0.1144\n",
       "2   4927 0.4139"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oof[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "25b5152f-4db6-4adf-95f5-e6ce25a30cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.to_csv('sub/submission_nn_weight.csv', index=None, header=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92863fdc-93b2-4de1-8c86-bc5de5eef7c5",
   "metadata": {},
   "source": [
    "## アンサンブル用データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0c848410-f964-4be3-bcd6-2af32407dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "with open('ensamble/nnw_train.pickle', mode='wb') as fo:\n",
    "    pickle.dump(train_oof, fo)\n",
    "    \n",
    "with open('ensamble/nnw_test.pickle', mode='wb') as fo:\n",
    "    pickle.dump(test_pred_proba, fo)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d692713-afd8-49ea-ad14-b8521a8744de",
   "metadata": {},
   "source": [
    "## ベースライン検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85d92d4c-6746-4881-be65-1672bae19199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証データ:  (2400, 8) (2400, 1)\n",
      "ベースライン検証データ:  (600, 8) (600, 1)\n",
      "検証データ(train):  (1920, 8) (1920, 1)\n",
      "検証データ(test):  (480, 8) (480, 1)\n"
     ]
    }
   ],
   "source": [
    "random_state=123\n",
    "\n",
    "x_tr, x_va2, y_tr, y_va2 = train_test_split(X_train,\n",
    "                                           y_train,\n",
    "                                           test_size=0.2,\n",
    "                                           shuffle=True,\n",
    "                                           stratify=y_train,\n",
    "                                           random_state=random_state)\n",
    "print('検証データ: ',x_tr.shape, y_tr.shape)\n",
    "print('ベースライン検証データ: ',x_va2.shape, y_va2.shape)\n",
    "\n",
    "x_tr1, x_va1, y_tr1, y_va1 = train_test_split(x_tr,\n",
    "                                              y_tr,\n",
    "                                              test_size=0.2,\n",
    "                                              shuffle=True,\n",
    "                                              stratify=y_tr,\n",
    "                                              random_state=random_state)\n",
    "print('検証データ(train): ',x_tr1.shape, y_tr1.shape)\n",
    "print('検証データ(test): ',x_va1.shape, y_va1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c8879aee-6be5-4f03-a54e-9e0c18a4514e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.09 , 2.09 , 0.657, ..., 0.657, 2.09 , 0.657], dtype=float16)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules import Add_class_wight\n",
    "class_weights = Add_class_wight(y_tr['Outcome'])\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8ab0e25-c221-4477-9610-d177b1a72b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.7275 - binary_crossentropy: 0.7274\n",
      "Epoch 1: val_loss improved from inf to 0.74773, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.7277 - binary_crossentropy: 0.7273 - val_loss: 0.7477 - val_binary_crossentropy: 0.7477 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "282/300 [===========================>..] - ETA: 0s - loss: 0.6852 - binary_crossentropy: 0.6915\n",
      "Epoch 2: val_loss improved from 0.74773 to 0.70938, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.6861 - binary_crossentropy: 0.6896 - val_loss: 0.7094 - val_binary_crossentropy: 0.7094 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.6730 - binary_crossentropy: 0.6779\n",
      "Epoch 3: val_loss improved from 0.70938 to 0.69369, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6741 - binary_crossentropy: 0.6782 - val_loss: 0.6937 - val_binary_crossentropy: 0.6937 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.6632 - binary_crossentropy: 0.6699\n",
      "Epoch 4: val_loss improved from 0.69369 to 0.67559, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6643 - binary_crossentropy: 0.6706 - val_loss: 0.6756 - val_binary_crossentropy: 0.6756 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.6557 - binary_crossentropy: 0.6588\n",
      "Epoch 5: val_loss improved from 0.67559 to 0.66059, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6529 - binary_crossentropy: 0.6593 - val_loss: 0.6606 - val_binary_crossentropy: 0.6606 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.6546 - binary_crossentropy: 0.6569\n",
      "Epoch 6: val_loss improved from 0.66059 to 0.65739, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6546 - binary_crossentropy: 0.6575 - val_loss: 0.6574 - val_binary_crossentropy: 0.6574 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.6427 - binary_crossentropy: 0.6495\n",
      "Epoch 7: val_loss did not improve from 0.65739\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6466 - binary_crossentropy: 0.6500 - val_loss: 0.6583 - val_binary_crossentropy: 0.6583 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.6440 - binary_crossentropy: 0.6511\n",
      "Epoch 8: val_loss improved from 0.65739 to 0.64248, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6431 - binary_crossentropy: 0.6493 - val_loss: 0.6425 - val_binary_crossentropy: 0.6425 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.6386 - binary_crossentropy: 0.6434\n",
      "Epoch 9: val_loss improved from 0.64248 to 0.64232, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6388 - binary_crossentropy: 0.6441 - val_loss: 0.6423 - val_binary_crossentropy: 0.6423 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.6358 - binary_crossentropy: 0.6391\n",
      "Epoch 10: val_loss did not improve from 0.64232\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6347 - binary_crossentropy: 0.6381 - val_loss: 0.6475 - val_binary_crossentropy: 0.6475 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.6299 - binary_crossentropy: 0.6324\n",
      "Epoch 11: val_loss improved from 0.64232 to 0.63472, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6327 - binary_crossentropy: 0.6334 - val_loss: 0.6347 - val_binary_crossentropy: 0.6347 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.6317 - binary_crossentropy: 0.6377\n",
      "Epoch 12: val_loss did not improve from 0.63472\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6300 - binary_crossentropy: 0.6374 - val_loss: 0.6405 - val_binary_crossentropy: 0.6405 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.6291 - binary_crossentropy: 0.6317\n",
      "Epoch 13: val_loss improved from 0.63472 to 0.62612, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6310 - binary_crossentropy: 0.6326 - val_loss: 0.6261 - val_binary_crossentropy: 0.6261 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.6234 - binary_crossentropy: 0.6265\n",
      "Epoch 14: val_loss did not improve from 0.62612\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6229 - binary_crossentropy: 0.6273 - val_loss: 0.6310 - val_binary_crossentropy: 0.6310 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.6175 - binary_crossentropy: 0.6242\n",
      "Epoch 15: val_loss improved from 0.62612 to 0.61559, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6203 - binary_crossentropy: 0.6241 - val_loss: 0.6156 - val_binary_crossentropy: 0.6156 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.6216 - binary_crossentropy: 0.6221\n",
      "Epoch 16: val_loss improved from 0.61559 to 0.61516, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6214 - binary_crossentropy: 0.6215 - val_loss: 0.6152 - val_binary_crossentropy: 0.6152 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.6317 - binary_crossentropy: 0.6295\n",
      "Epoch 17: val_loss did not improve from 0.61516\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6317 - binary_crossentropy: 0.6295 - val_loss: 0.6235 - val_binary_crossentropy: 0.6235 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.6152 - binary_crossentropy: 0.6159\n",
      "Epoch 18: val_loss did not improve from 0.61516\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6176 - binary_crossentropy: 0.6156 - val_loss: 0.6178 - val_binary_crossentropy: 0.6178 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.6107 - binary_crossentropy: 0.6163\n",
      "Epoch 19: val_loss did not improve from 0.61516\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6130 - binary_crossentropy: 0.6166 - val_loss: 0.6176 - val_binary_crossentropy: 0.6176 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.6162 - binary_crossentropy: 0.6225\n",
      "Epoch 20: val_loss improved from 0.61516 to 0.61396, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6187 - binary_crossentropy: 0.6218 - val_loss: 0.6140 - val_binary_crossentropy: 0.6140 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.6175 - binary_crossentropy: 0.6215\n",
      "Epoch 21: val_loss did not improve from 0.61396\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6172 - binary_crossentropy: 0.6224 - val_loss: 0.6193 - val_binary_crossentropy: 0.6193 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "298/300 [============================>.] - ETA: 0s - loss: 0.6209 - binary_crossentropy: 0.6184\n",
      "Epoch 22: val_loss did not improve from 0.61396\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6197 - binary_crossentropy: 0.6181 - val_loss: 0.6181 - val_binary_crossentropy: 0.6181 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.6202 - binary_crossentropy: 0.6224\n",
      "Epoch 23: val_loss improved from 0.61396 to 0.61386, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6199 - binary_crossentropy: 0.6224 - val_loss: 0.6139 - val_binary_crossentropy: 0.6139 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.6164 - binary_crossentropy: 0.6154\n",
      "Epoch 24: val_loss did not improve from 0.61386\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6200 - binary_crossentropy: 0.6183 - val_loss: 0.6200 - val_binary_crossentropy: 0.6200 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.6177 - binary_crossentropy: 0.6194\n",
      "Epoch 25: val_loss did not improve from 0.61386\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6177 - binary_crossentropy: 0.6194 - val_loss: 0.6174 - val_binary_crossentropy: 0.6174 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.6178 - binary_crossentropy: 0.6190\n",
      "Epoch 26: val_loss did not improve from 0.61386\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6156 - binary_crossentropy: 0.6177 - val_loss: 0.6200 - val_binary_crossentropy: 0.6200 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.6201 - binary_crossentropy: 0.6214\n",
      "Epoch 27: val_loss did not improve from 0.61386\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.6196 - binary_crossentropy: 0.6213 - val_loss: 0.6259 - val_binary_crossentropy: 0.6259 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "282/300 [===========================>..] - ETA: 0s - loss: 0.6160 - binary_crossentropy: 0.6180\n",
      "Epoch 28: val_loss did not improve from 0.61386\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6158 - binary_crossentropy: 0.6179 - val_loss: 0.6196 - val_binary_crossentropy: 0.6196 - lr: 1.0000e-04\n",
      "Epoch 28: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76387be880>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation結果\n",
    "model = create_model()\n",
    "model.fit(\n",
    "    x=x_tr,\n",
    "    y=y_tr,\n",
    "    validation_data=(x_va1, y_va1),\n",
    "    batch_size=8,\n",
    "    epochs=1000,\n",
    "    class_weight=weight_dict,\n",
    "    callbacks=[ModelCheckpoint(filepath='model_keras.h5',\n",
    "                            moniter='val_loss',\n",
    "                            mode='min', \n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            ),\n",
    "            EarlyStopping(monitor='val_loss',\n",
    "                          mode='min',\n",
    "                          min_delta=0,\n",
    "                          patience=5,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True),\n",
    "            ReduceLROnPlateau(moniter='val_loss',\n",
    "                             mode='min',\n",
    "                             factor=0.1,\n",
    "                             patience=5,\n",
    "                             verbose=1),\n",
    "           ],\n",
    "    verbose=1,\n",
    "\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "31d4307d-4a67-4228-85a7-140c68b0f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[検証データ] acc: 0.6667\n",
      "[ベースライン検証データ] acc: 0.7133\n",
      "[検証データ] auc: 0.7352\n",
      "[ベースライン検証データ] auc: 0.7854\n"
     ]
    }
   ],
   "source": [
    "#評価指標の差\n",
    "y_va1_pred = model.predict(x_va1)\n",
    "y_va2_pred = model.predict(x_va2)\n",
    "print('[検証データ] acc: {:.4f}'.format(accuracy_score(y_va1, np.where(y_va1_pred>=0.5,1,0))))\n",
    "print('[ベースライン検証データ] acc: {:.4f}'.format(accuracy_score(y_va2, np.where(y_va2_pred>=0.5,1,0))))\n",
    "\n",
    "\n",
    "print('[検証データ] auc: {:.4f}'.format(roc_auc_score(y_va1, y_va1_pred)))\n",
    "print('[ベースライン検証データ] auc: {:.4f}'.format(roc_auc_score(y_va2, y_va2_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "92b503ae-74e3-4b01-a728-9919ca203629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証データ\n",
      "[[237 128]\n",
      " [ 32  83]]\n",
      "[[0.49375    0.26666667]\n",
      " [0.06666667 0.17291667]]\n",
      "ベースライン検証データ\n",
      "[[321 136]\n",
      " [ 36 107]]\n",
      "[[0.535      0.22666667]\n",
      " [0.06       0.17833333]]\n"
     ]
    }
   ],
   "source": [
    "#誤分類の分布\n",
    "print('検証データ')\n",
    "print(confusion_matrix(y_va1, np.where(y_va1_pred>=0.5,1,0)))\n",
    "print(confusion_matrix(y_va1, np.where(y_va1_pred>=0.5,1,0), normalize='all'))\n",
    "\n",
    "print('ベースライン検証データ')\n",
    "print(confusion_matrix(y_va2, np.where(y_va2_pred>=0.5,1,0)))\n",
    "print(confusion_matrix(y_va2, np.where(y_va2_pred>=0.5,1,0), normalize='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1da92e26-8aee-4c0d-983d-d5e7271a59b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f76387d5b20>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 予測値の分布\n",
    "y_va1_pred_prob = model.predict(x_va1)\n",
    "y_va2_pred_prob = model.predict(x_va2)\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "fig.add_subplot(2,1,1)\n",
    "plt.title('validation_data')\n",
    "plt.hist(y_va1_pred_prob[np.array(y_va1).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va1_pred_prob[np.array(y_va1).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(2,1,2)\n",
    "plt.title('basreline_validation_data')\n",
    "plt.hist(y_va2_pred_prob[np.array(y_va2).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va2_pred_prob[np.array(y_va2).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537739d4-699c-4dde-ae15-fe05b29a4163",
   "metadata": {},
   "source": [
    "## チューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c70df6-ccf0-4d7b-87cb-e03980d2e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70364048-9098-4c29-aae7-26d2fc215125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索しないパラメータ\n",
    "\n",
    "params_base = {\n",
    "   'optimizer_fn': torch.optim.Adam,\n",
    "   'optimizer_params': {'lr':2e-2,'weight_decay':1e-5},\n",
    "   'mask_type': \"entmax\",#AttentiveTransformerでマスク作るのにどっちの関数を使うか'sparsemax'or'entmax'\n",
    "   'scheduler_params':{'mode': \"min\",'patience': 5,'min_lr': 1e-5,'factor': 0.9, 'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,},\n",
    "   'verbose':10,\n",
    "   'seed': 123,\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # 探索するパラメータ\n",
    "    params_tuning = {\n",
    "        'n_d': trial.suggest_int('n_d',8,64),\n",
    "        'n_a': trial.suggest_int('n_a',8,64),\n",
    "        'n_steps': trial.suggest_int('n_steps', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n",
    "        'mask_type': trial.suggest_categorical('mask_type', ['entmatx','sparsemax']),\n",
    "    }\n",
    "    params_tuning.update(params_base)\n",
    "    \n",
    "    # モデル学習・評価\n",
    "    list_metrics = []\n",
    "    cv = list(StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state).split(X_train, y_train))\n",
    "    for nfold in np.arange(4):\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = X_train.loc[idx_tr, :], y_train.loc[idx_tr, :]\n",
    "        x_va, y_va = X_train.loc[idx_va, :], y_train.loc[idx_va, :]\n",
    "       \n",
    "        y_va_pred = model.predict_proba(x_va)[:,1]\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>0.5, 1, 0))\n",
    "        list_metrics.append(metric_va)\n",
    "        \n",
    "    # 評価値の計算\n",
    "    metrics = np.mean(list_metrics)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "690a0925-a533-485e-94d9-ac5e95f7fab5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:25:48,430]\u001b[0m A new study created in memory with name: no-name-c35efe1d-ef61-45ef-ad8a-57bab052cf43\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:01s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:07s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:03s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:26:41,692]\u001b[0m Trial 0 finished with value: 0.7656666666666667 and parameters: {'n_d': 47, 'n_a': 24, 'n_step': 3, 'gamma': 1.5513147690828912, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:03s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:06s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:07s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:03s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:27:34,868]\u001b[0m Trial 1 finished with value: 0.7656666666666667 and parameters: {'n_d': 63, 'n_a': 47, 'n_step': 5, 'gamma': 1.3921175181941505, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:03s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:05s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:06s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:07s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:05s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:07s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:08s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:03s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:28:29,472]\u001b[0m Trial 2 finished with value: 0.7656666666666667 and parameters: {'n_d': 32, 'n_a': 11, 'n_step': 4, 'gamma': 1.7379954057320357, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:03s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:05s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:06s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:07s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:29:23,197]\u001b[0m Trial 3 finished with value: 0.7656666666666667 and parameters: {'n_d': 38, 'n_a': 38, 'n_step': 7, 'gamma': 1.8494317940777896, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:06s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:07s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:08s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:05s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:06s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n",
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:30:20,692]\u001b[0m Trial 4 finished with value: 0.7656666666666667 and parameters: {'n_d': 49, 'n_a': 26, 'n_step': 4, 'gamma': 1.2282632308789556, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:07s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:03s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:31:14,682]\u001b[0m Trial 5 finished with value: 0.7656666666666667 and parameters: {'n_d': 13, 'n_a': 32, 'n_step': 5, 'gamma': 1.4936850976503062, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:07s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:08s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:05s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:03s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:32:10,297]\u001b[0m Trial 6 finished with value: 0.7656666666666667 and parameters: {'n_d': 32, 'n_a': 58, 'n_step': 10, 'gamma': 1.5018366758843364, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:01s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:03s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:33:05,604]\u001b[0m Trial 7 finished with value: 0.7656666666666667 and parameters: {'n_d': 26, 'n_a': 31, 'n_step': 9, 'gamma': 1.2504553653965067, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:08s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:03s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:08s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:06s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:02s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:05s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:34:03,700]\u001b[0m Trial 8 finished with value: 0.7656666666666667 and parameters: {'n_d': 37, 'n_a': 42, 'n_step': 2, 'gamma': 1.8263408005068333, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:05s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:08s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:06s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:07s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:08s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n",
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:35:00,323]\u001b[0m Trial 9 finished with value: 0.7656666666666667 and parameters: {'n_d': 27, 'n_a': 25, 'n_step': 5, 'gamma': 1.6813007657927965, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:02s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:05s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n",
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:35:54,823]\u001b[0m Trial 10 finished with value: 0.7656666666666667 and parameters: {'n_d': 56, 'n_a': 8, 'n_step': 1, 'gamma': 1.0080611434040203, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:01s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:06s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:36:49,120]\u001b[0m Trial 11 finished with value: 0.7656666666666667 and parameters: {'n_d': 63, 'n_a': 51, 'n_step': 3, 'gamma': 1.9862890564016848, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:37:44,848]\u001b[0m Trial 12 finished with value: 0.7656666666666667 and parameters: {'n_d': 48, 'n_a': 46, 'n_step': 7, 'gamma': 1.555399472872045, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:05s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:08s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:38:40,678]\u001b[0m Trial 13 finished with value: 0.7656666666666667 and parameters: {'n_d': 64, 'n_a': 19, 'n_step': 7, 'gamma': 1.3631357691972947, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:39:35,045]\u001b[0m Trial 14 finished with value: 0.7656666666666667 and parameters: {'n_d': 49, 'n_a': 59, 'n_step': 3, 'gamma': 1.6071903264160659, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:05s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:01s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:40:30,787]\u001b[0m Trial 15 finished with value: 0.7656666666666667 and parameters: {'n_d': 56, 'n_a': 19, 'n_step': 1, 'gamma': 1.4511497032783554, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:02s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:41:27,051]\u001b[0m Trial 16 finished with value: 0.7656666666666667 and parameters: {'n_d': 44, 'n_a': 49, 'n_step': 6, 'gamma': 1.3844748717398336, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:01s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n",
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:42:21,674]\u001b[0m Trial 17 finished with value: 0.7656666666666667 and parameters: {'n_d': 57, 'n_a': 38, 'n_step': 3, 'gamma': 1.6228321701158495, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:05s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:08s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:06s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:43:17,846]\u001b[0m Trial 18 finished with value: 0.7656666666666667 and parameters: {'n_d': 13, 'n_a': 54, 'n_step': 6, 'gamma': 1.3222958430513911, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:44:12,759]\u001b[0m Trial 19 finished with value: 0.7656666666666667 and parameters: {'n_d': 43, 'n_a': 62, 'n_step': 8, 'gamma': 1.5520330411371615, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:45:08,441]\u001b[0m Trial 20 finished with value: 0.7656666666666667 and parameters: {'n_d': 59, 'n_a': 15, 'n_step': 4, 'gamma': 1.4356061202518677, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:06s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:46:05,297]\u001b[0m Trial 21 finished with value: 0.7656666666666667 and parameters: {'n_d': 21, 'n_a': 8, 'n_step': 4, 'gamma': 1.7069340307634664, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:08s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:01s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:05s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:46:59,923]\u001b[0m Trial 22 finished with value: 0.7656666666666667 and parameters: {'n_d': 29, 'n_a': 14, 'n_step': 2, 'gamma': 1.7163415570713012, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:47:54,900]\u001b[0m Trial 23 finished with value: 0.7656666666666667 and parameters: {'n_d': 20, 'n_a': 25, 'n_step': 5, 'gamma': 1.6119687787895545, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:01s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n",
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:48:50,379]\u001b[0m Trial 24 finished with value: 0.7656666666666667 and parameters: {'n_d': 41, 'n_a': 31, 'n_step': 4, 'gamma': 1.7913032879236999, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:08s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:06s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:05s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:06s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:49:47,427]\u001b[0m Trial 25 finished with value: 0.7656666666666667 and parameters: {'n_d': 33, 'n_a': 14, 'n_step': 2, 'gamma': 1.494434901957632, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:02s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:04s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:06s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:07s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:09s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:50:44,496]\u001b[0m Trial 26 finished with value: 0.7656666666666667 and parameters: {'n_d': 52, 'n_a': 19, 'n_step': 3, 'gamma': 1.7716585404282987, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n",
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:51:39,812]\u001b[0m Trial 27 finished with value: 0.7656666666666667 and parameters: {'n_d': 22, 'n_a': 42, 'n_step': 6, 'gamma': 1.6495702502566643, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:01s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:52:36,215]\u001b[0m Trial 28 finished with value: 0.7656666666666667 and parameters: {'n_d': 53, 'n_a': 44, 'n_step': 5, 'gamma': 1.570458959494639, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:06s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:53:31,376]\u001b[0m Trial 29 finished with value: 0.7656666666666667 and parameters: {'n_d': 39, 'n_a': 23, 'n_step': 4, 'gamma': 1.864792365897348, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=random_state)\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd085928-9bb2-45d6-9e3c-bd091e44473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(best)=0.7657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_d': 47,\n",
       " 'n_a': 24,\n",
       " 'n_step': 3,\n",
       " 'gamma': 1.5513147690828912,\n",
       " 'mask_type': 'entmatx'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print('acc(best)={:.4f}'.format(trial.value))\n",
    "display(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b9c69c7-7198-4c8f-92a0-89ce861a6bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_d': 47,\n",
       " 'n_a': 24,\n",
       " 'n_step': 3,\n",
       " 'gamma': 1.5513147690828912,\n",
       " 'mask_type': 'entmax',\n",
       " 'optimizer_fn': torch.optim.adam.Adam,\n",
       " 'optimizer_params': {'lr': 0.02, 'weight_decay': 1e-05},\n",
       " 'scheduler_params': {'mode': 'min',\n",
       "  'patience': 5,\n",
       "  'min_lr': 1e-05,\n",
       "  'factor': 0.9,\n",
       "  'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau},\n",
       " 'verbose': 10,\n",
       " 'seed': 123}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_best = trial.params\n",
    "params_best.update(params_base)\n",
    "display(params_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
