{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9828789-bec1-4170-8a76-262379ab71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "#データ読み込み\n",
    "train = pd.read_csv(\"data_EDA/train.csv\")\n",
    "test = pd.read_csv(\"data_EDA/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "564c7484-3a88-48b9-8538-8ce80818836e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>...</th>\n",
       "      <th>Insulin_na</th>\n",
       "      <th>Pregnancies_na</th>\n",
       "      <th>Pre/age</th>\n",
       "      <th>SkinThickness_mean</th>\n",
       "      <th>BloodPressure_mean</th>\n",
       "      <th>Insulin_dpf_mean</th>\n",
       "      <th>Pregnancies_bin_0</th>\n",
       "      <th>Pregnancies_bin_-1</th>\n",
       "      <th>Pregnancies_bin_-3</th>\n",
       "      <th>Pregnancies_bin_3-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2509</td>\n",
       "      <td>3.584</td>\n",
       "      <td>114.3</td>\n",
       "      <td>68.77</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.86</td>\n",
       "      <td>35.59</td>\n",
       "      <td>0.4018</td>\n",
       "      <td>29.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.1203</td>\n",
       "      <td>26.71</td>\n",
       "      <td>71.37</td>\n",
       "      <td>136.5</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1438</td>\n",
       "      <td>3.054</td>\n",
       "      <td>21.99</td>\n",
       "      <td>16.17</td>\n",
       "      <td>14.06</td>\n",
       "      <td>49.83</td>\n",
       "      <td>6.937</td>\n",
       "      <td>0.2671</td>\n",
       "      <td>8.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2729</td>\n",
       "      <td>0.1876</td>\n",
       "      <td>0.09919</td>\n",
       "      <td>5.128</td>\n",
       "      <td>9.077</td>\n",
       "      <td>29.91</td>\n",
       "      <td>0.3245</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>0.4456</td>\n",
       "      <td>0.4346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.286</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1285</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.58</td>\n",
       "      <td>0.2346</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04545</td>\n",
       "      <td>26.88</td>\n",
       "      <td>64</td>\n",
       "      <td>135.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2550</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.81</td>\n",
       "      <td>0.2713</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09717</td>\n",
       "      <td>26.88</td>\n",
       "      <td>71.41</td>\n",
       "      <td>135.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3744</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>78</td>\n",
       "      <td>24.25</td>\n",
       "      <td>0</td>\n",
       "      <td>39.69</td>\n",
       "      <td>0.5064</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>26.88</td>\n",
       "      <td>78</td>\n",
       "      <td>135.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4995</td>\n",
       "      <td>13</td>\n",
       "      <td>199</td>\n",
       "      <td>110</td>\n",
       "      <td>52</td>\n",
       "      <td>744</td>\n",
       "      <td>52.96</td>\n",
       "      <td>2.176</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>52</td>\n",
       "      <td>110</td>\n",
       "      <td>744</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  \\\n",
       "count   2000         2000     2000           2000           2000     2000   \n",
       "mean    2509        3.584    114.3          68.77           11.2    11.86   \n",
       "std     1438        3.054    21.99          16.17          14.06    49.83   \n",
       "min        1            0       57              0              0        0   \n",
       "25%     1285            1      100             64              0        0   \n",
       "50%     2550            3      111             70              0        0   \n",
       "75%     3744            6      125             78          24.25        0   \n",
       "max     4995           13      199            110             52      744   \n",
       "\n",
       "        BMI  DiabetesPedigreeFunction   Age  Outcome  ...  Insulin_na  \\\n",
       "count  2000                      2000  2000        0  ...        2000   \n",
       "mean  35.59                    0.4018 29.08      NaN  ...       0.919   \n",
       "std   6.937                    0.2671 8.572      NaN  ...      0.2729   \n",
       "min   9.286                    0.1374    21      NaN  ...           0   \n",
       "25%   32.58                    0.2346    22      NaN  ...           1   \n",
       "50%   33.81                    0.2713    26      NaN  ...           1   \n",
       "75%   39.69                    0.5064    33      NaN  ...           1   \n",
       "max   52.96                     2.176    67      NaN  ...           1   \n",
       "\n",
       "       Pregnancies_na  Pre/age  SkinThickness_mean  BloodPressure_mean  \\\n",
       "count            2000     2000                2000                2000   \n",
       "mean           0.0365   0.1203               26.71               71.37   \n",
       "std            0.1876  0.09919               5.128               9.077   \n",
       "min                 0        0                   8                  38   \n",
       "25%                 0  0.04545               26.88                  64   \n",
       "50%                 0  0.09717               26.88               71.41   \n",
       "75%                 0   0.1717               26.88                  78   \n",
       "max                 1   0.5909                  52                 110   \n",
       "\n",
       "       Insulin_dpf_mean  Pregnancies_bin_0  Pregnancies_bin_-1  \\\n",
       "count              2000               2000                2000   \n",
       "mean              136.5             0.1195               0.355   \n",
       "std               29.91             0.3245              0.4786   \n",
       "min                  15                  0                   0   \n",
       "25%               135.6                  0                   0   \n",
       "50%               135.6                  0                   0   \n",
       "75%               135.6                  0                   1   \n",
       "max                 744                  1                   1   \n",
       "\n",
       "       Pregnancies_bin_-3  Pregnancies_bin_3-  \n",
       "count                2000                2000  \n",
       "mean                0.273              0.2525  \n",
       "std                0.4456              0.4346  \n",
       "min                     0                   0  \n",
       "25%                     0                   0  \n",
       "50%                     0                   0  \n",
       "75%                     1                   1  \n",
       "max                     1                   1  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4df67cb-c4bd-4f8c-8fb7-ef2b18cc8a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>...</th>\n",
       "      <th>Insulin_na</th>\n",
       "      <th>Pregnancies_na</th>\n",
       "      <th>Pre/age</th>\n",
       "      <th>SkinThickness_mean</th>\n",
       "      <th>BloodPressure_mean</th>\n",
       "      <th>Insulin_dpf_mean</th>\n",
       "      <th>Pregnancies_bin_0</th>\n",
       "      <th>Pregnancies_bin_-1</th>\n",
       "      <th>Pregnancies_bin_-3</th>\n",
       "      <th>Pregnancies_bin_3-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>...</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2493</td>\n",
       "      <td>3.557</td>\n",
       "      <td>113.7</td>\n",
       "      <td>68.74</td>\n",
       "      <td>11.16</td>\n",
       "      <td>11.66</td>\n",
       "      <td>35.41</td>\n",
       "      <td>0.4005</td>\n",
       "      <td>28.93</td>\n",
       "      <td>0.239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9147</td>\n",
       "      <td>0.03767</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>26.98</td>\n",
       "      <td>71.43</td>\n",
       "      <td>135.7</td>\n",
       "      <td>0.1433</td>\n",
       "      <td>0.3307</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1447</td>\n",
       "      <td>3.032</td>\n",
       "      <td>20.89</td>\n",
       "      <td>16.33</td>\n",
       "      <td>14.35</td>\n",
       "      <td>45.06</td>\n",
       "      <td>6.99</td>\n",
       "      <td>0.2747</td>\n",
       "      <td>8.469</td>\n",
       "      <td>0.4265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2794</td>\n",
       "      <td>0.1904</td>\n",
       "      <td>0.1003</td>\n",
       "      <td>5.248</td>\n",
       "      <td>9.04</td>\n",
       "      <td>23.92</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>0.4705</td>\n",
       "      <td>0.4451</td>\n",
       "      <td>0.4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.748</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1219</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.3</td>\n",
       "      <td>0.231</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04545</td>\n",
       "      <td>26.88</td>\n",
       "      <td>64</td>\n",
       "      <td>135.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2466</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.84</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09878</td>\n",
       "      <td>26.88</td>\n",
       "      <td>71.41</td>\n",
       "      <td>135.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3750</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>78</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>39.58</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>26.88</td>\n",
       "      <td>78</td>\n",
       "      <td>135.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4999</td>\n",
       "      <td>13</td>\n",
       "      <td>196</td>\n",
       "      <td>110</td>\n",
       "      <td>49</td>\n",
       "      <td>579</td>\n",
       "      <td>53.4</td>\n",
       "      <td>2.302</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619</td>\n",
       "      <td>49</td>\n",
       "      <td>110</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  \\\n",
       "count   3000         3000     3000           3000           3000     3000   \n",
       "mean    2493        3.557    113.7          68.74          11.16    11.66   \n",
       "std     1447        3.032    20.89          16.33          14.35    45.06   \n",
       "min        0            0       57              0              0        0   \n",
       "25%     1219            1      100             64              0        0   \n",
       "50%     2466            3      111             70              0        0   \n",
       "75%     3750            6      125             78             24        0   \n",
       "max     4999           13      196            110             49      579   \n",
       "\n",
       "        BMI  DiabetesPedigreeFunction   Age  Outcome  ...  Insulin_na  \\\n",
       "count  3000                      3000  3000     3000  ...        3000   \n",
       "mean  35.41                    0.4005 28.93    0.239  ...      0.9147   \n",
       "std    6.99                    0.2747 8.469   0.4265  ...      0.2794   \n",
       "min   7.748                    0.1458    21        0  ...           0   \n",
       "25%    32.3                     0.231    22        0  ...           1   \n",
       "50%   33.84                    0.2687    26        0  ...           1   \n",
       "75%   39.58                    0.5068    33        0  ...           1   \n",
       "max    53.4                     2.302    67        1  ...           1   \n",
       "\n",
       "       Pregnancies_na  Pre/age  SkinThickness_mean  BloodPressure_mean  \\\n",
       "count            3000     3000                3000                3000   \n",
       "mean          0.03767   0.1201               26.98               71.43   \n",
       "std            0.1904   0.1003               5.248                9.04   \n",
       "min                 0        0                   7                  46   \n",
       "25%                 0  0.04545               26.88                  64   \n",
       "50%                 0  0.09878               26.88               71.41   \n",
       "75%                 0   0.1724               26.88                  78   \n",
       "max                 1    0.619                  49                 110   \n",
       "\n",
       "       Insulin_dpf_mean  Pregnancies_bin_0  Pregnancies_bin_-1  \\\n",
       "count              3000               3000                3000   \n",
       "mean              135.7             0.1433              0.3307   \n",
       "std               23.92             0.3505              0.4705   \n",
       "min                  15                  0                   0   \n",
       "25%               135.6                  0                   0   \n",
       "50%               135.6                  0                   0   \n",
       "75%               135.6                  0                   1   \n",
       "max                 579                  1                   1   \n",
       "\n",
       "       Pregnancies_bin_-3  Pregnancies_bin_3-  \n",
       "count                3000                3000  \n",
       "mean                0.272               0.254  \n",
       "std                0.4451              0.4354  \n",
       "min                     0                   0  \n",
       "25%                     0                   0  \n",
       "50%                     0                   0  \n",
       "75%                     1                   1  \n",
       "max                     1                   1  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d779c6c7-9002-4310-9dca-a315b29a770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# まずは少ない特徴量から検討していく\n",
    "X_train = train[['DiabetesPedigreeFunction',\n",
    "                 'BMI',\n",
    "                 'Glucose',\n",
    "                 'Age',\n",
    "                 'Pregnancies',\n",
    "                 'SkinThickness',\n",
    "                 'Insulin',\n",
    "                 'BloodPressure',\n",
    "                 \n",
    "                 \n",
    "                 \n",
    "                \n",
    "             ]]\n",
    "id_train = train[['index']]\n",
    "y_train = train[['Outcome']]\n",
    "\n",
    "\n",
    "X_test = test[X_train.columns]\n",
    "id_test = test[id_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9456c50-0e72-466d-85c5-662a952f5c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiabetesPedigreeFunction\n",
      "BMI\n",
      "Glucose\n",
      "Age\n",
      "Pregnancies\n",
      "SkinThickness\n",
      "Insulin\n",
      "BloodPressure\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# 数値データ\n",
    "col_num = X_train.columns[X_train.dtypes!='object'].values.tolist()\n",
    "\n",
    "dict_num = {}\n",
    "for col in col_num:\n",
    "    print(col)\n",
    "    # 欠損値を0へ\n",
    "    value_fillna = 0 \n",
    "    X_train[col] = X_train[col].fillna(value_fillna)\n",
    "    # 正規化\n",
    "    value_min = X_train[col].min()\n",
    "    value_max = X_train[col].max()\n",
    "    value_mean = X_train[col].mean()\n",
    "    value_std = X_train[col].std()\n",
    "    #X_train[col] = (X_train[col] - value_min) / (value_max -value_min)\n",
    "    X_train[col] = (X_train[col] - value_mean) / value_std\n",
    "    \n",
    "    dict_num[col] = {}\n",
    "    dict_num[col]['fillna'] = value_fillna\n",
    "    dict_num[col]['min'] = value_min\n",
    "    dict_num[col]['max'] = value_max\n",
    "    dict_num[col]['mean'] = value_mean    \n",
    "    dict_num[col]['std'] = value_std  \n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b441ffe4-8346-4f77-ade1-571a4a1d180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# カテゴリデータ\n",
    "# （embedding予定でラベルエンコーダー）\n",
    "col_cat = X_train.columns[X_train.dtypes=='object'].values.tolist()\n",
    "\n",
    "dict_cat = {}\n",
    "for col in col_cat:\n",
    "    print(col)\n",
    "    value_fillna = 'unknown'\n",
    "    X_train[col] = X_train[cal].fillna(value_fillna)\n",
    "    \n",
    "    X_train[caol] = X_train[col].astype(str)\n",
    "    # strに変換\n",
    "    le = LabelEncorder()\n",
    "    le.fit(X_train[col])\n",
    "    list_labelsorted(list(set(le.classes_) | set(['unknown'])))\n",
    "    map_label = {j:i for i,j in enumerate(list_label)}\n",
    "    X_train[col] = X_train[col].map(map_label)\n",
    "    \n",
    "    dict_cat[col] = {}\n",
    "    dict_cat[col]['fillna'] = value_fillna\n",
    "    dict_cat[col]['map_label'] = map_label\n",
    "    dict_cat[col]['num_label'] = len(list_label)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ca4da6d-792c-41f7-a397-68d69834b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(input_x):\n",
    "    output_x = input_x.copy()\n",
    "    \n",
    "    for col in col_num:\n",
    "        value_fillna = dict_num[col]['fillna']\n",
    "        output_x[col] = output_x[col].fillna(value_fillna)\n",
    "        \n",
    "        value_min = dict_num[col]['min']\n",
    "        value_max = dict_num[col]['max']\n",
    "        value_mean = dict_num[col]['mean']\n",
    "        value_std = dict_num[col]['std']\n",
    "        \n",
    "        output_x[col]  = (output_x[col] - value_mean ) / (value_std)\n",
    "        \n",
    "    for col in col_cat:\n",
    "        value_fillna = dict_cat[col]['fillna']\n",
    "        output_x[col] = output_x[col].fillna(value_fillna)\n",
    "        \n",
    "        output_x[col] = output_x[col].astype(str)\n",
    "        \n",
    "        map_label = dict_catt[col]['map_label']\n",
    "        output_x[col] = output_x[col].map(map_label)\n",
    "        \n",
    "        #対応するものがない場合はunkoumn\n",
    "        output_x[col] = output_x[col].fillna(map_label['unknown'])\n",
    "        \n",
    "    return output_x\n",
    "\n",
    "X_test = transform_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b322d24d-594b-43f5-98e9-037f78b28046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BloodPressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.599e-16</td>\n",
       "      <td>-5.797e-16</td>\n",
       "      <td>1.007e-16</td>\n",
       "      <td>1.563e-16</td>\n",
       "      <td>4.619e-17</td>\n",
       "      <td>1.451e-17</td>\n",
       "      <td>4.441e-17</td>\n",
       "      <td>-1.918e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.9271</td>\n",
       "      <td>-3.957</td>\n",
       "      <td>-2.716</td>\n",
       "      <td>-0.9366</td>\n",
       "      <td>-1.173</td>\n",
       "      <td>-0.7779</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>-4.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.6171</td>\n",
       "      <td>-0.4445</td>\n",
       "      <td>-0.6576</td>\n",
       "      <td>-0.8185</td>\n",
       "      <td>-0.8433</td>\n",
       "      <td>-0.7779</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>-0.2904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.4799</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.1309</td>\n",
       "      <td>-0.3462</td>\n",
       "      <td>-0.1837</td>\n",
       "      <td>-0.7779</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>0.07692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.387</td>\n",
       "      <td>0.5965</td>\n",
       "      <td>0.5394</td>\n",
       "      <td>0.4803</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>0.8944</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>0.5667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.923</td>\n",
       "      <td>2.574</td>\n",
       "      <td>3.939</td>\n",
       "      <td>4.495</td>\n",
       "      <td>3.114</td>\n",
       "      <td>2.636</td>\n",
       "      <td>12.59</td>\n",
       "      <td>2.526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DiabetesPedigreeFunction        BMI   Glucose       Age  Pregnancies  \\\n",
       "count                      3000       3000      3000      3000         3000   \n",
       "mean                  1.599e-16 -5.797e-16 1.007e-16 1.563e-16    4.619e-17   \n",
       "std                           1          1         1         1            1   \n",
       "min                     -0.9271     -3.957    -2.716   -0.9366       -1.173   \n",
       "25%                     -0.6171    -0.4445   -0.6576   -0.8185      -0.8433   \n",
       "50%                     -0.4799     -0.225   -0.1309   -0.3462      -0.1837   \n",
       "75%                       0.387     0.5965    0.5394    0.4803       0.8057   \n",
       "max                       6.923      2.574     3.939     4.495        3.114   \n",
       "\n",
       "       SkinThickness   Insulin  BloodPressure  \n",
       "count           3000      3000           3000  \n",
       "mean       1.451e-17 4.441e-17     -1.918e-16  \n",
       "std                1         1              1  \n",
       "min          -0.7779   -0.2588         -4.209  \n",
       "25%          -0.7779   -0.2588        -0.2904  \n",
       "50%          -0.7779   -0.2588        0.07692  \n",
       "75%           0.8944   -0.2588         0.5667  \n",
       "max            2.636     12.59          2.526  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.4g}'.format\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1638f98-c1b6-48ee-a765-6369e686e7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BloodPressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.01694</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.001398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.9723</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>1.053</td>\n",
       "      <td>1.012</td>\n",
       "      <td>1.007</td>\n",
       "      <td>0.9794</td>\n",
       "      <td>1.106</td>\n",
       "      <td>0.9903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.9579</td>\n",
       "      <td>-3.737</td>\n",
       "      <td>-2.716</td>\n",
       "      <td>-0.9366</td>\n",
       "      <td>-1.173</td>\n",
       "      <td>-0.7779</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>-4.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.6038</td>\n",
       "      <td>-0.4045</td>\n",
       "      <td>-0.6576</td>\n",
       "      <td>-0.8185</td>\n",
       "      <td>-0.8433</td>\n",
       "      <td>-0.7779</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>-0.2904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.4704</td>\n",
       "      <td>-0.2281</td>\n",
       "      <td>-0.1309</td>\n",
       "      <td>-0.3462</td>\n",
       "      <td>-0.1837</td>\n",
       "      <td>-0.7779</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>0.07692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.3858</td>\n",
       "      <td>0.6131</td>\n",
       "      <td>0.5394</td>\n",
       "      <td>0.4803</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>0.9118</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>0.5667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.464</td>\n",
       "      <td>2.511</td>\n",
       "      <td>4.083</td>\n",
       "      <td>4.495</td>\n",
       "      <td>3.114</td>\n",
       "      <td>2.845</td>\n",
       "      <td>16.25</td>\n",
       "      <td>2.526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DiabetesPedigreeFunction     BMI  Glucose     Age  Pregnancies  \\\n",
       "count                      2000    2000     2000    2000         2000   \n",
       "mean                   0.004658 0.02542   0.0268 0.01694     0.008905   \n",
       "std                      0.9723  0.9924    1.053   1.012        1.007   \n",
       "min                     -0.9579  -3.737   -2.716 -0.9366       -1.173   \n",
       "25%                     -0.6038 -0.4045  -0.6576 -0.8185      -0.8433   \n",
       "50%                     -0.4704 -0.2281  -0.1309 -0.3462      -0.1837   \n",
       "75%                      0.3858  0.6131   0.5394  0.4803       0.8057   \n",
       "max                       6.464   2.511    4.083   4.495        3.114   \n",
       "\n",
       "       SkinThickness  Insulin  BloodPressure  \n",
       "count           2000     2000           2000  \n",
       "mean        0.002787 0.004342       0.001398  \n",
       "std           0.9794    1.106         0.9903  \n",
       "min          -0.7779  -0.2588         -4.209  \n",
       "25%          -0.7779  -0.2588        -0.2904  \n",
       "50%          -0.7779  -0.2588        0.07692  \n",
       "75%           0.9118  -0.2588         0.5667  \n",
       "max            2.845    16.25          2.526  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b84c0a7-0533-442f-94a4-cf5d5b9720f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 07:26:28.677734: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-20 07:26:30.821632: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-20 07:26:30.821692: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-20 07:26:31.222617: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-20 07:26:35.586951: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 07:26:35.587407: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 07:26:35.587419: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "random_state=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "188c5d42-7fcd-4c2c-a2d6-e9a8896de4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1,\n",
    "        inter_op_parallelism_threads=1\n",
    "    )\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11843a2-84ac-4a99-8f3d-bc716ae893f7",
   "metadata": {},
   "source": [
    "## validation方法 NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81657fd1-039d-4c1a-a464-20b69ac9ff4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_num = Input(shape=(8,))\n",
    "    x_num = Dense(10, activation='relu')(input_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.3)(x_num)\n",
    "    x_num = Dense(10, activation='relu')(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.2)(x_num)\n",
    "    x_num = Dense(5, activation='relu')(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.1)(x_num)\n",
    "    out = Dense(1, activation='sigmoid')(x_num)\n",
    "    \n",
    "    model = Model(inputs=input_num, outputs=out,)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='Adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_crossentropy'],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44798591-6ec9-4ec6-9d9a-d8fd8c8701a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                90        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10)               40        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 07:26:50.390773: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-20 07:26:50.394042: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-20 07:26:50.394799: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (3ed327de65ae): /proc/driver/nvidia/version does not exist\n",
      "2023-03-20 07:26:50.400223: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_1 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 5)                20        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 361\n",
      "Trainable params: 311\n",
      "Non-trainable params: 50\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデルの確認\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43777692-d1d6-45ed-b5ae-e6c75760d1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 0.657030223390276, 0.0: 2.092050209205021}\n"
     ]
    }
   ],
   "source": [
    "#不均衡データ用の重み\n",
    "class_weights = list(class_weight.compute_class_weight('balanced', \n",
    "                                                           classes=np.unique(y_train['Outcome']),\n",
    "                                                           y=y_train['Outcome'])\n",
    "                        )\n",
    "# fit時にclass_weightに辞書でに有力\n",
    "weight_dict = dict(zip(y_train['Outcome'], class_weights))\n",
    "print(weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79e21f82-16fc-49ed-b576-42909918c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvでの評価用\n",
    "def train_nn(input_x,\n",
    "              input_y,\n",
    "              input_id,\n",
    "              list_nfold=[0,1,2,3,4],\n",
    "              n_splits=5,\n",
    "              random_state=123\n",
    "            ):\n",
    "    train_oof = np.zeros(len(input_x))\n",
    "    # foldごとの推論値\n",
    "    metrics = []\n",
    "    imp = pd.DataFrame()\n",
    "                         \n",
    "    cv = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state).\n",
    "              split(input_x, input_y))\n",
    "    \n",
    "    for nfold in list_nfold:\n",
    "        print('-'*20, nfold, '-'*20)\n",
    "        \n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = input_x.loc[idx_tr, :], input_y.loc[idx_tr, :]\n",
    "        x_va, y_va = input_x.loc[idx_va, :], input_y.loc[idx_va, :]\n",
    "        print(x_tr.shape, y_tr.shape)\n",
    "        print(x_va.shape, y_va.shape)\n",
    "        print('y_train:{:.3f}, y_tr:{:.3f}, y_va{:.3f}'.\n",
    "              format(y_train['Outcome'].mean(), y_tr['Outcome'].mean(), y_va['Outcome'].mean(),))\n",
    "\n",
    "        model = create_model()\n",
    "        model.fit(x=x_tr,\n",
    "                  y=y_tr,\n",
    "                 validation_data=(x_va, y_va),\n",
    "                 batch_size=8,\n",
    "                 epochs=1000,\n",
    "                 class_weight=None,\n",
    "                 callbacks=[ModelCheckpoint(filepath='model_keras.h5',\n",
    "                                            moniter='val_loss',\n",
    "                                            mode='min', \n",
    "                                            verbose=1,\n",
    "                                            save_best_only=True,\n",
    "                                            ),\n",
    "                            EarlyStopping(monitor='val_loss',\n",
    "                                          mode='min',\n",
    "                                          min_delta=0,\n",
    "                                          patience=5,\n",
    "                                          verbose=1,\n",
    "                                          restore_best_weights=True),\n",
    "                            ReduceLROnPlateau(moniter='val_loss',\n",
    "                                             mode='min',\n",
    "                                             factor=0.1,\n",
    "                                             patience=5,\n",
    "                                             verbose=1),\n",
    "                           ],\n",
    "                  verbose=1,\n",
    "                 )\n",
    "\n",
    "        # モデルの保存\n",
    "        fname_nn = 'model/nn/model_nn_fold{}.pickle'.format(nfold)\n",
    "        with open(fname_nn, 'wb')as f:\n",
    "            pickle.dump(model, f, protocol=4)\n",
    "            \n",
    "            \n",
    "        # 評価\n",
    "        y_tr_pred = model.predict(x_tr)\n",
    "        y_va_pred = model.predict(x_va)\n",
    "        metric_tr = accuracy_score(y_tr, np.where(y_tr_pred>=0.5,1,0))\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>=0.5,1,0))\n",
    "        print('[accuracy] tr: {:.2f}, va: {:2f}'.\n",
    "             format(metric_tr, metric_va))\n",
    "        metrics.append([nfold, metric_tr, metric_va])\n",
    "        \n",
    "        # oof\n",
    "        train_oof[idx_va] = np.squeeze(y_va_pred)\n",
    "        \n",
    "        \n",
    "        print('-'*20, 'result', '-'*20)\n",
    "    \n",
    "    # metrix出力\n",
    "    metrics = np.array(metrics)\n",
    "    print(metrics)\n",
    "    print('[cv] tr: {:.2f}+-{:.2f}, va: {:.2f}'.format(\n",
    "        metrics[:,1].mean(), metrics[:,1].std(),\n",
    "        metrics[:,2].mean(), metrics[:,2].std()\n",
    "    ))\n",
    "    print('[oof] {:.4f}'.format(\n",
    "        accuracy_score(input_y, np.where(train_oof>=0.5,1,0))))\n",
    "    # oof出力  \n",
    "    train_oof = pd.concat([\n",
    "        input_id,\n",
    "        pd.DataFrame({'pred':train_oof})]\n",
    "        ,axis=1)\n",
    "\n",
    "    print('Done')\n",
    "    \n",
    "    return train_oof, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf1c7951-6b35-4f07-894d-814aa7eca215",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "(2400, 8) (2400, 1)\n",
      "(600, 8) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.240\n",
      "Epoch 1/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.7672 - binary_crossentropy: 0.7672\n",
      "Epoch 1: val_loss improved from inf to 0.60935, saving model to model_keras.h5\n",
      "300/300 [==============================] - 3s 4ms/step - loss: 0.7614 - binary_crossentropy: 0.7614 - val_loss: 0.6093 - val_binary_crossentropy: 0.6093 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.5961 - binary_crossentropy: 0.5961\n",
      "Epoch 2: val_loss improved from 0.60935 to 0.55619, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5968 - binary_crossentropy: 0.5968 - val_loss: 0.5562 - val_binary_crossentropy: 0.5562 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.5595 - binary_crossentropy: 0.5595\n",
      "Epoch 3: val_loss improved from 0.55619 to 0.53921, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5597 - binary_crossentropy: 0.5597 - val_loss: 0.5392 - val_binary_crossentropy: 0.5392 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.5384 - binary_crossentropy: 0.5384\n",
      "Epoch 4: val_loss improved from 0.53921 to 0.53110, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5391 - binary_crossentropy: 0.5391 - val_loss: 0.5311 - val_binary_crossentropy: 0.5311 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.5401 - binary_crossentropy: 0.5401\n",
      "Epoch 5: val_loss improved from 0.53110 to 0.51777, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5396 - binary_crossentropy: 0.5396 - val_loss: 0.5178 - val_binary_crossentropy: 0.5178 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "283/300 [===========================>..] - ETA: 0s - loss: 0.5385 - binary_crossentropy: 0.5385\n",
      "Epoch 6: val_loss improved from 0.51777 to 0.50675, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5340 - binary_crossentropy: 0.5340 - val_loss: 0.5067 - val_binary_crossentropy: 0.5067 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.5356 - binary_crossentropy: 0.5356\n",
      "Epoch 7: val_loss improved from 0.50675 to 0.49808, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5338 - binary_crossentropy: 0.5338 - val_loss: 0.4981 - val_binary_crossentropy: 0.4981 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "279/300 [==========================>...] - ETA: 0s - loss: 0.5251 - binary_crossentropy: 0.5251\n",
      "Epoch 8: val_loss improved from 0.49808 to 0.49421, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5229 - binary_crossentropy: 0.5229 - val_loss: 0.4942 - val_binary_crossentropy: 0.4942 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.5195 - binary_crossentropy: 0.5195\n",
      "Epoch 9: val_loss improved from 0.49421 to 0.48422, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5193 - binary_crossentropy: 0.5193 - val_loss: 0.4842 - val_binary_crossentropy: 0.4842 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.5098 - binary_crossentropy: 0.5098\n",
      "Epoch 10: val_loss improved from 0.48422 to 0.47902, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5105 - binary_crossentropy: 0.5105 - val_loss: 0.4790 - val_binary_crossentropy: 0.4790 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.5121 - binary_crossentropy: 0.5121\n",
      "Epoch 11: val_loss improved from 0.47902 to 0.47594, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5125 - binary_crossentropy: 0.5125 - val_loss: 0.4759 - val_binary_crossentropy: 0.4759 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "282/300 [===========================>..] - ETA: 0s - loss: 0.5179 - binary_crossentropy: 0.5179\n",
      "Epoch 12: val_loss improved from 0.47594 to 0.47422, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5175 - binary_crossentropy: 0.5175 - val_loss: 0.4742 - val_binary_crossentropy: 0.4742 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.5170 - binary_crossentropy: 0.5170\n",
      "Epoch 13: val_loss did not improve from 0.47422\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5200 - binary_crossentropy: 0.5200 - val_loss: 0.4777 - val_binary_crossentropy: 0.4777 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.5067 - binary_crossentropy: 0.5067\n",
      "Epoch 14: val_loss improved from 0.47422 to 0.47340, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5067 - binary_crossentropy: 0.5067 - val_loss: 0.4734 - val_binary_crossentropy: 0.4734 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.5111 - binary_crossentropy: 0.5111\n",
      "Epoch 15: val_loss improved from 0.47340 to 0.47098, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5119 - binary_crossentropy: 0.5119 - val_loss: 0.4710 - val_binary_crossentropy: 0.4710 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.5138 - binary_crossentropy: 0.5138\n",
      "Epoch 16: val_loss improved from 0.47098 to 0.46713, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5077 - binary_crossentropy: 0.5077 - val_loss: 0.4671 - val_binary_crossentropy: 0.4671 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "282/300 [===========================>..] - ETA: 0s - loss: 0.5056 - binary_crossentropy: 0.5056\n",
      "Epoch 17: val_loss improved from 0.46713 to 0.46591, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5047 - binary_crossentropy: 0.5047 - val_loss: 0.4659 - val_binary_crossentropy: 0.4659 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.5014 - binary_crossentropy: 0.5014\n",
      "Epoch 18: val_loss did not improve from 0.46591\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5062 - binary_crossentropy: 0.5062 - val_loss: 0.4663 - val_binary_crossentropy: 0.4663 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "283/300 [===========================>..] - ETA: 0s - loss: 0.5022 - binary_crossentropy: 0.5022\n",
      "Epoch 19: val_loss improved from 0.46591 to 0.46398, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5007 - binary_crossentropy: 0.5007 - val_loss: 0.4640 - val_binary_crossentropy: 0.4640 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4963 - binary_crossentropy: 0.4963\n",
      "Epoch 20: val_loss improved from 0.46398 to 0.46051, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4965 - binary_crossentropy: 0.4965 - val_loss: 0.4605 - val_binary_crossentropy: 0.4605 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.5060 - binary_crossentropy: 0.5060\n",
      "Epoch 21: val_loss did not improve from 0.46051\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5068 - binary_crossentropy: 0.5068 - val_loss: 0.4626 - val_binary_crossentropy: 0.4626 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.4935 - binary_crossentropy: 0.4935\n",
      "Epoch 22: val_loss improved from 0.46051 to 0.45899, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4955 - binary_crossentropy: 0.4955 - val_loss: 0.4590 - val_binary_crossentropy: 0.4590 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4979 - binary_crossentropy: 0.4979\n",
      "Epoch 23: val_loss did not improve from 0.45899\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4970 - binary_crossentropy: 0.4970 - val_loss: 0.4618 - val_binary_crossentropy: 0.4618 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.4933 - binary_crossentropy: 0.4933\n",
      "Epoch 24: val_loss did not improve from 0.45899\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4930 - binary_crossentropy: 0.4930 - val_loss: 0.4601 - val_binary_crossentropy: 0.4601 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.4973 - binary_crossentropy: 0.4973\n",
      "Epoch 25: val_loss did not improve from 0.45899\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4996 - binary_crossentropy: 0.4996 - val_loss: 0.4606 - val_binary_crossentropy: 0.4606 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "282/300 [===========================>..] - ETA: 0s - loss: 0.5005 - binary_crossentropy: 0.5005\n",
      "Epoch 26: val_loss improved from 0.45899 to 0.45866, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4954 - binary_crossentropy: 0.4954 - val_loss: 0.4587 - val_binary_crossentropy: 0.4587 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.5003 - binary_crossentropy: 0.5003\n",
      "Epoch 27: val_loss did not improve from 0.45866\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5011 - binary_crossentropy: 0.5011 - val_loss: 0.4590 - val_binary_crossentropy: 0.4590 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.4970 - binary_crossentropy: 0.4970\n",
      "Epoch 28: val_loss improved from 0.45866 to 0.45796, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4995 - binary_crossentropy: 0.4995 - val_loss: 0.4580 - val_binary_crossentropy: 0.4580 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.4967 - binary_crossentropy: 0.4967\n",
      "Epoch 29: val_loss improved from 0.45796 to 0.45463, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4960 - binary_crossentropy: 0.4960 - val_loss: 0.4546 - val_binary_crossentropy: 0.4546 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.5017 - binary_crossentropy: 0.5017\n",
      "Epoch 30: val_loss did not improve from 0.45463\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4999 - binary_crossentropy: 0.4999 - val_loss: 0.4554 - val_binary_crossentropy: 0.4554 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.4979 - binary_crossentropy: 0.4979\n",
      "Epoch 31: val_loss improved from 0.45463 to 0.45431, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4982 - binary_crossentropy: 0.4982 - val_loss: 0.4543 - val_binary_crossentropy: 0.4543 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.5055 - binary_crossentropy: 0.5055\n",
      "Epoch 32: val_loss did not improve from 0.45431\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5026 - binary_crossentropy: 0.5026 - val_loss: 0.4564 - val_binary_crossentropy: 0.4564 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "283/300 [===========================>..] - ETA: 0s - loss: 0.4998 - binary_crossentropy: 0.4998\n",
      "Epoch 33: val_loss did not improve from 0.45431\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4977 - binary_crossentropy: 0.4977 - val_loss: 0.4567 - val_binary_crossentropy: 0.4567 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.5052 - binary_crossentropy: 0.5052\n",
      "Epoch 34: val_loss did not improve from 0.45431\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5006 - binary_crossentropy: 0.5006 - val_loss: 0.4596 - val_binary_crossentropy: 0.4596 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.4985 - binary_crossentropy: 0.4985\n",
      "Epoch 35: val_loss did not improve from 0.45431\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4967 - binary_crossentropy: 0.4967 - val_loss: 0.4570 - val_binary_crossentropy: 0.4570 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4864 - binary_crossentropy: 0.4864\n",
      "Epoch 36: val_loss improved from 0.45431 to 0.45166, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4868 - binary_crossentropy: 0.4868 - val_loss: 0.4517 - val_binary_crossentropy: 0.4517 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4914 - binary_crossentropy: 0.4914\n",
      "Epoch 37: val_loss did not improve from 0.45166\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4896 - binary_crossentropy: 0.4896 - val_loss: 0.4518 - val_binary_crossentropy: 0.4518 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.5035 - binary_crossentropy: 0.5035\n",
      "Epoch 38: val_loss did not improve from 0.45166\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5019 - binary_crossentropy: 0.5019 - val_loss: 0.4567 - val_binary_crossentropy: 0.4567 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.4964 - binary_crossentropy: 0.4964\n",
      "Epoch 39: val_loss did not improve from 0.45166\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4936 - binary_crossentropy: 0.4936 - val_loss: 0.4547 - val_binary_crossentropy: 0.4547 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.4899 - binary_crossentropy: 0.4899\n",
      "Epoch 40: val_loss did not improve from 0.45166\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4903 - binary_crossentropy: 0.4903 - val_loss: 0.4548 - val_binary_crossentropy: 0.4548 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.4907 - binary_crossentropy: 0.4907\n",
      "Epoch 41: val_loss did not improve from 0.45166\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4914 - binary_crossentropy: 0.4914 - val_loss: 0.4545 - val_binary_crossentropy: 0.4545 - lr: 0.0010\n",
      "Epoch 41: early stopping\n",
      "INFO:tensorflow:Assets written to: ram://7c78a713-04b0-4cf0-b8c6-ed1342133f4c/assets\n",
      "75/75 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "[accuracy] tr: 0.77, va: 0.771667\n",
      "-------------------- result --------------------\n",
      "-------------------- 1 --------------------\n",
      "(2400, 8) (2400, 1)\n",
      "(600, 8) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.240\n",
      "Epoch 1/1000\n",
      "280/300 [===========================>..] - ETA: 0s - loss: 0.7132 - binary_crossentropy: 0.7132\n",
      "Epoch 1: val_loss improved from inf to 0.56291, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.7053 - binary_crossentropy: 0.7053 - val_loss: 0.5629 - val_binary_crossentropy: 0.5629 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.5510 - binary_crossentropy: 0.5510\n",
      "Epoch 2: val_loss improved from 0.56291 to 0.49832, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5492 - binary_crossentropy: 0.5492 - val_loss: 0.4983 - val_binary_crossentropy: 0.4983 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.5276 - binary_crossentropy: 0.5276\n",
      "Epoch 3: val_loss improved from 0.49832 to 0.48716, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5283 - binary_crossentropy: 0.5283 - val_loss: 0.4872 - val_binary_crossentropy: 0.4872 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.5194 - binary_crossentropy: 0.5194\n",
      "Epoch 4: val_loss improved from 0.48716 to 0.48612, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5230 - binary_crossentropy: 0.5230 - val_loss: 0.4861 - val_binary_crossentropy: 0.4861 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.5157 - binary_crossentropy: 0.5157\n",
      "Epoch 5: val_loss improved from 0.48612 to 0.48406, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5156 - binary_crossentropy: 0.5156 - val_loss: 0.4841 - val_binary_crossentropy: 0.4841 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "298/300 [============================>.] - ETA: 0s - loss: 0.5106 - binary_crossentropy: 0.5106\n",
      "Epoch 6: val_loss improved from 0.48406 to 0.48160, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5102 - binary_crossentropy: 0.5102 - val_loss: 0.4816 - val_binary_crossentropy: 0.4816 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.5111 - binary_crossentropy: 0.5111\n",
      "Epoch 7: val_loss improved from 0.48160 to 0.47834, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5107 - binary_crossentropy: 0.5107 - val_loss: 0.4783 - val_binary_crossentropy: 0.4783 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "298/300 [============================>.] - ETA: 0s - loss: 0.5058 - binary_crossentropy: 0.5058\n",
      "Epoch 8: val_loss improved from 0.47834 to 0.47471, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5057 - binary_crossentropy: 0.5057 - val_loss: 0.4747 - val_binary_crossentropy: 0.4747 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.5121 - binary_crossentropy: 0.5121\n",
      "Epoch 9: val_loss improved from 0.47471 to 0.47292, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5113 - binary_crossentropy: 0.5113 - val_loss: 0.4729 - val_binary_crossentropy: 0.4729 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "282/300 [===========================>..] - ETA: 0s - loss: 0.5118 - binary_crossentropy: 0.5118\n",
      "Epoch 10: val_loss did not improve from 0.47292\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5139 - binary_crossentropy: 0.5139 - val_loss: 0.4732 - val_binary_crossentropy: 0.4732 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.5058 - binary_crossentropy: 0.5058\n",
      "Epoch 11: val_loss did not improve from 0.47292\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5089 - binary_crossentropy: 0.5089 - val_loss: 0.4732 - val_binary_crossentropy: 0.4732 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.5009 - binary_crossentropy: 0.5009\n",
      "Epoch 12: val_loss improved from 0.47292 to 0.47061, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5018 - binary_crossentropy: 0.5018 - val_loss: 0.4706 - val_binary_crossentropy: 0.4706 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.4996 - binary_crossentropy: 0.4996\n",
      "Epoch 13: val_loss did not improve from 0.47061\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4999 - binary_crossentropy: 0.4999 - val_loss: 0.4714 - val_binary_crossentropy: 0.4714 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "282/300 [===========================>..] - ETA: 0s - loss: 0.4913 - binary_crossentropy: 0.4913\n",
      "Epoch 14: val_loss improved from 0.47061 to 0.46877, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4966 - binary_crossentropy: 0.4966 - val_loss: 0.4688 - val_binary_crossentropy: 0.4688 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.5054 - binary_crossentropy: 0.5054\n",
      "Epoch 15: val_loss improved from 0.46877 to 0.46860, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5028 - binary_crossentropy: 0.5028 - val_loss: 0.4686 - val_binary_crossentropy: 0.4686 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.4985 - binary_crossentropy: 0.4985\n",
      "Epoch 16: val_loss did not improve from 0.46860\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4971 - binary_crossentropy: 0.4971 - val_loss: 0.4703 - val_binary_crossentropy: 0.4703 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.4963 - binary_crossentropy: 0.4963\n",
      "Epoch 17: val_loss did not improve from 0.46860\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4967 - binary_crossentropy: 0.4967 - val_loss: 0.4694 - val_binary_crossentropy: 0.4694 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.4930 - binary_crossentropy: 0.4930\n",
      "Epoch 18: val_loss improved from 0.46860 to 0.46830, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4925 - binary_crossentropy: 0.4925 - val_loss: 0.4683 - val_binary_crossentropy: 0.4683 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.4989 - binary_crossentropy: 0.4989\n",
      "Epoch 19: val_loss did not improve from 0.46830\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5039 - binary_crossentropy: 0.5039 - val_loss: 0.4688 - val_binary_crossentropy: 0.4688 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.4987 - binary_crossentropy: 0.4987\n",
      "Epoch 20: val_loss improved from 0.46830 to 0.46805, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4975 - binary_crossentropy: 0.4975 - val_loss: 0.4681 - val_binary_crossentropy: 0.4681 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.4970 - binary_crossentropy: 0.4970\n",
      "Epoch 21: val_loss improved from 0.46805 to 0.46729, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4960 - binary_crossentropy: 0.4960 - val_loss: 0.4673 - val_binary_crossentropy: 0.4673 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4977 - binary_crossentropy: 0.4977\n",
      "Epoch 22: val_loss did not improve from 0.46729\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4972 - binary_crossentropy: 0.4972 - val_loss: 0.4687 - val_binary_crossentropy: 0.4687 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.4932 - binary_crossentropy: 0.4932\n",
      "Epoch 23: val_loss did not improve from 0.46729\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4921 - binary_crossentropy: 0.4921 - val_loss: 0.4692 - val_binary_crossentropy: 0.4692 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4968 - binary_crossentropy: 0.4968\n",
      "Epoch 24: val_loss did not improve from 0.46729\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4961 - binary_crossentropy: 0.4961 - val_loss: 0.4696 - val_binary_crossentropy: 0.4696 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.4974 - binary_crossentropy: 0.4974\n",
      "Epoch 25: val_loss did not improve from 0.46729\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4968 - binary_crossentropy: 0.4968 - val_loss: 0.4704 - val_binary_crossentropy: 0.4704 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4895 - binary_crossentropy: 0.4895\n",
      "Epoch 26: val_loss did not improve from 0.46729\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4895 - binary_crossentropy: 0.4895 - val_loss: 0.4679 - val_binary_crossentropy: 0.4679 - lr: 0.0010\n",
      "Epoch 26: early stopping\n",
      "INFO:tensorflow:Assets written to: ram://7c6f46bd-9d8f-42f4-b342-fdfcc9a62888/assets\n",
      "75/75 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "[accuracy] tr: 0.77, va: 0.780000\n",
      "-------------------- result --------------------\n",
      "-------------------- 2 --------------------\n",
      "(2400, 8) (2400, 1)\n",
      "(600, 8) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.238\n",
      "Epoch 1/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.7068 - binary_crossentropy: 0.7068\n",
      "Epoch 1: val_loss improved from inf to 0.57802, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.7021 - binary_crossentropy: 0.7021 - val_loss: 0.5780 - val_binary_crossentropy: 0.5780 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.5837 - binary_crossentropy: 0.5837\n",
      "Epoch 2: val_loss improved from 0.57802 to 0.53908, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5825 - binary_crossentropy: 0.5825 - val_loss: 0.5391 - val_binary_crossentropy: 0.5391 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "298/300 [============================>.] - ETA: 0s - loss: 0.5416 - binary_crossentropy: 0.5416\n",
      "Epoch 3: val_loss improved from 0.53908 to 0.52553, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5426 - binary_crossentropy: 0.5426 - val_loss: 0.5255 - val_binary_crossentropy: 0.5255 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.5328 - binary_crossentropy: 0.5328\n",
      "Epoch 4: val_loss improved from 0.52553 to 0.52041, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5378 - binary_crossentropy: 0.5378 - val_loss: 0.5204 - val_binary_crossentropy: 0.5204 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "283/300 [===========================>..] - ETA: 0s - loss: 0.5443 - binary_crossentropy: 0.5443\n",
      "Epoch 5: val_loss improved from 0.52041 to 0.51628, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5395 - binary_crossentropy: 0.5395 - val_loss: 0.5163 - val_binary_crossentropy: 0.5163 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.5398 - binary_crossentropy: 0.5398\n",
      "Epoch 6: val_loss improved from 0.51628 to 0.51284, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5401 - binary_crossentropy: 0.5401 - val_loss: 0.5128 - val_binary_crossentropy: 0.5128 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.5305 - binary_crossentropy: 0.5305\n",
      "Epoch 7: val_loss improved from 0.51284 to 0.51024, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5279 - binary_crossentropy: 0.5279 - val_loss: 0.5102 - val_binary_crossentropy: 0.5102 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5136 - binary_crossentropy: 0.5136\n",
      "Epoch 8: val_loss improved from 0.51024 to 0.50565, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5136 - binary_crossentropy: 0.5136 - val_loss: 0.5057 - val_binary_crossentropy: 0.5057 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.5188 - binary_crossentropy: 0.5188\n",
      "Epoch 9: val_loss improved from 0.50565 to 0.50520, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5183 - binary_crossentropy: 0.5183 - val_loss: 0.5052 - val_binary_crossentropy: 0.5052 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.5131 - binary_crossentropy: 0.5131\n",
      "Epoch 10: val_loss improved from 0.50520 to 0.50508, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5141 - binary_crossentropy: 0.5141 - val_loss: 0.5051 - val_binary_crossentropy: 0.5051 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.5189 - binary_crossentropy: 0.5189\n",
      "Epoch 11: val_loss improved from 0.50508 to 0.50358, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5154 - binary_crossentropy: 0.5154 - val_loss: 0.5036 - val_binary_crossentropy: 0.5036 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.5192 - binary_crossentropy: 0.5192\n",
      "Epoch 12: val_loss improved from 0.50358 to 0.50257, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5160 - binary_crossentropy: 0.5160 - val_loss: 0.5026 - val_binary_crossentropy: 0.5026 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.5090 - binary_crossentropy: 0.5090\n",
      "Epoch 13: val_loss improved from 0.50257 to 0.50063, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5143 - binary_crossentropy: 0.5143 - val_loss: 0.5006 - val_binary_crossentropy: 0.5006 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.5161 - binary_crossentropy: 0.5161\n",
      "Epoch 14: val_loss did not improve from 0.50063\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5160 - binary_crossentropy: 0.5160 - val_loss: 0.5012 - val_binary_crossentropy: 0.5012 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4998 - binary_crossentropy: 0.4998\n",
      "Epoch 15: val_loss improved from 0.50063 to 0.50003, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5021 - binary_crossentropy: 0.5021 - val_loss: 0.5000 - val_binary_crossentropy: 0.5000 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.4964 - binary_crossentropy: 0.4964\n",
      "Epoch 16: val_loss improved from 0.50003 to 0.49944, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5002 - binary_crossentropy: 0.5002 - val_loss: 0.4994 - val_binary_crossentropy: 0.4994 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.5012 - binary_crossentropy: 0.5012\n",
      "Epoch 17: val_loss improved from 0.49944 to 0.49862, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5017 - binary_crossentropy: 0.5017 - val_loss: 0.4986 - val_binary_crossentropy: 0.4986 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.5020 - binary_crossentropy: 0.5020\n",
      "Epoch 18: val_loss improved from 0.49862 to 0.49839, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4981 - binary_crossentropy: 0.4981 - val_loss: 0.4984 - val_binary_crossentropy: 0.4984 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.4978 - binary_crossentropy: 0.4978\n",
      "Epoch 19: val_loss improved from 0.49839 to 0.49689, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4963 - binary_crossentropy: 0.4963 - val_loss: 0.4969 - val_binary_crossentropy: 0.4969 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4944 - binary_crossentropy: 0.4944\n",
      "Epoch 20: val_loss improved from 0.49689 to 0.49552, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4948 - binary_crossentropy: 0.4948 - val_loss: 0.4955 - val_binary_crossentropy: 0.4955 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.4930 - binary_crossentropy: 0.4930\n",
      "Epoch 21: val_loss improved from 0.49552 to 0.49481, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4947 - binary_crossentropy: 0.4947 - val_loss: 0.4948 - val_binary_crossentropy: 0.4948 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.4968 - binary_crossentropy: 0.4968\n",
      "Epoch 22: val_loss improved from 0.49481 to 0.49458, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4977 - binary_crossentropy: 0.4977 - val_loss: 0.4946 - val_binary_crossentropy: 0.4946 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "281/300 [===========================>..] - ETA: 0s - loss: 0.4945 - binary_crossentropy: 0.4945\n",
      "Epoch 23: val_loss improved from 0.49458 to 0.49446, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4957 - binary_crossentropy: 0.4957 - val_loss: 0.4945 - val_binary_crossentropy: 0.4945 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.5036 - binary_crossentropy: 0.5036\n",
      "Epoch 24: val_loss improved from 0.49446 to 0.49359, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5020 - binary_crossentropy: 0.5020 - val_loss: 0.4936 - val_binary_crossentropy: 0.4936 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.4936 - binary_crossentropy: 0.4936\n",
      "Epoch 25: val_loss improved from 0.49359 to 0.49344, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4940 - binary_crossentropy: 0.4940 - val_loss: 0.4934 - val_binary_crossentropy: 0.4934 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4884 - binary_crossentropy: 0.4884\n",
      "Epoch 26: val_loss did not improve from 0.49344\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4870 - binary_crossentropy: 0.4870 - val_loss: 0.4939 - val_binary_crossentropy: 0.4939 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.4912 - binary_crossentropy: 0.4912\n",
      "Epoch 27: val_loss did not improve from 0.49344\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4906 - binary_crossentropy: 0.4906 - val_loss: 0.4935 - val_binary_crossentropy: 0.4935 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4893 - binary_crossentropy: 0.4893\n",
      "Epoch 28: val_loss improved from 0.49344 to 0.49292, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4903 - binary_crossentropy: 0.4903 - val_loss: 0.4929 - val_binary_crossentropy: 0.4929 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.4758 - binary_crossentropy: 0.4758\n",
      "Epoch 29: val_loss did not improve from 0.49292\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4796 - binary_crossentropy: 0.4796 - val_loss: 0.4941 - val_binary_crossentropy: 0.4941 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.4883 - binary_crossentropy: 0.4883\n",
      "Epoch 30: val_loss did not improve from 0.49292\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4898 - binary_crossentropy: 0.4898 - val_loss: 0.4930 - val_binary_crossentropy: 0.4930 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.4918 - binary_crossentropy: 0.4918\n",
      "Epoch 31: val_loss did not improve from 0.49292\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4897 - binary_crossentropy: 0.4897 - val_loss: 0.4937 - val_binary_crossentropy: 0.4937 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.4864 - binary_crossentropy: 0.4864\n",
      "Epoch 32: val_loss did not improve from 0.49292\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4892 - binary_crossentropy: 0.4892 - val_loss: 0.4929 - val_binary_crossentropy: 0.4929 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.4895 - binary_crossentropy: 0.4895\n",
      "Epoch 33: val_loss improved from 0.49292 to 0.49212, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4903 - binary_crossentropy: 0.4903 - val_loss: 0.4921 - val_binary_crossentropy: 0.4921 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "282/300 [===========================>..] - ETA: 0s - loss: 0.4897 - binary_crossentropy: 0.4897\n",
      "Epoch 34: val_loss improved from 0.49212 to 0.49096, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4912 - binary_crossentropy: 0.4912 - val_loss: 0.4910 - val_binary_crossentropy: 0.4910 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4895 - binary_crossentropy: 0.4895\n",
      "Epoch 35: val_loss did not improve from 0.49096\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4908 - binary_crossentropy: 0.4908 - val_loss: 0.4926 - val_binary_crossentropy: 0.4926 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.4873 - binary_crossentropy: 0.4873\n",
      "Epoch 36: val_loss did not improve from 0.49096\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4865 - binary_crossentropy: 0.4865 - val_loss: 0.4934 - val_binary_crossentropy: 0.4934 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4891 - binary_crossentropy: 0.4891\n",
      "Epoch 37: val_loss did not improve from 0.49096\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4875 - binary_crossentropy: 0.4875 - val_loss: 0.4943 - val_binary_crossentropy: 0.4943 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.4884 - binary_crossentropy: 0.4884\n",
      "Epoch 38: val_loss did not improve from 0.49096\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4880 - binary_crossentropy: 0.4880 - val_loss: 0.4935 - val_binary_crossentropy: 0.4935 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "288/300 [===========================>..] - ETA: 0s - loss: 0.4873 - binary_crossentropy: 0.4873\n",
      "Epoch 39: val_loss did not improve from 0.49096\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4875 - binary_crossentropy: 0.4875 - val_loss: 0.4918 - val_binary_crossentropy: 0.4918 - lr: 0.0010\n",
      "Epoch 39: early stopping\n",
      "INFO:tensorflow:Assets written to: ram://6a7a88a7-4134-463f-877b-cbca2ea413c1/assets\n",
      "75/75 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[accuracy] tr: 0.77, va: 0.765000\n",
      "-------------------- result --------------------\n",
      "-------------------- 3 --------------------\n",
      "(2400, 8) (2400, 1)\n",
      "(600, 8) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.238\n",
      "Epoch 1/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.6793 - binary_crossentropy: 0.6793\n",
      "Epoch 1: val_loss improved from inf to 0.56984, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.6778 - binary_crossentropy: 0.6778 - val_loss: 0.5698 - val_binary_crossentropy: 0.5698 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.5762 - binary_crossentropy: 0.5762\n",
      "Epoch 2: val_loss improved from 0.56984 to 0.52609, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5760 - binary_crossentropy: 0.5760 - val_loss: 0.5261 - val_binary_crossentropy: 0.5261 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.5423 - binary_crossentropy: 0.5423\n",
      "Epoch 3: val_loss improved from 0.52609 to 0.50875, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5420 - binary_crossentropy: 0.5420 - val_loss: 0.5088 - val_binary_crossentropy: 0.5088 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.5353 - binary_crossentropy: 0.5353\n",
      "Epoch 4: val_loss improved from 0.50875 to 0.50342, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5355 - binary_crossentropy: 0.5355 - val_loss: 0.5034 - val_binary_crossentropy: 0.5034 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5277 - binary_crossentropy: 0.5277\n",
      "Epoch 5: val_loss improved from 0.50342 to 0.49959, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5277 - binary_crossentropy: 0.5277 - val_loss: 0.4996 - val_binary_crossentropy: 0.4996 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.5219 - binary_crossentropy: 0.5219\n",
      "Epoch 6: val_loss improved from 0.49959 to 0.49162, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5203 - binary_crossentropy: 0.5203 - val_loss: 0.4916 - val_binary_crossentropy: 0.4916 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.5066 - binary_crossentropy: 0.5066\n",
      "Epoch 7: val_loss improved from 0.49162 to 0.48717, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5095 - binary_crossentropy: 0.5095 - val_loss: 0.4872 - val_binary_crossentropy: 0.4872 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.5212 - binary_crossentropy: 0.5212\n",
      "Epoch 8: val_loss did not improve from 0.48717\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5159 - binary_crossentropy: 0.5159 - val_loss: 0.4881 - val_binary_crossentropy: 0.4881 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.5192 - binary_crossentropy: 0.5192\n",
      "Epoch 9: val_loss improved from 0.48717 to 0.48570, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5177 - binary_crossentropy: 0.5177 - val_loss: 0.4857 - val_binary_crossentropy: 0.4857 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.5119 - binary_crossentropy: 0.5119\n",
      "Epoch 10: val_loss improved from 0.48570 to 0.48548, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5119 - binary_crossentropy: 0.5119 - val_loss: 0.4855 - val_binary_crossentropy: 0.4855 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.5111 - binary_crossentropy: 0.5111\n",
      "Epoch 11: val_loss improved from 0.48548 to 0.47876, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5121 - binary_crossentropy: 0.5121 - val_loss: 0.4788 - val_binary_crossentropy: 0.4788 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.5062 - binary_crossentropy: 0.5062\n",
      "Epoch 12: val_loss improved from 0.47876 to 0.47551, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5054 - binary_crossentropy: 0.5054 - val_loss: 0.4755 - val_binary_crossentropy: 0.4755 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.5033 - binary_crossentropy: 0.5033\n",
      "Epoch 13: val_loss improved from 0.47551 to 0.47243, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5035 - binary_crossentropy: 0.5035 - val_loss: 0.4724 - val_binary_crossentropy: 0.4724 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.5032 - binary_crossentropy: 0.5032\n",
      "Epoch 14: val_loss did not improve from 0.47243\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5022 - binary_crossentropy: 0.5022 - val_loss: 0.4726 - val_binary_crossentropy: 0.4726 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "283/300 [===========================>..] - ETA: 0s - loss: 0.4998 - binary_crossentropy: 0.4998\n",
      "Epoch 15: val_loss did not improve from 0.47243\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5013 - binary_crossentropy: 0.5013 - val_loss: 0.4725 - val_binary_crossentropy: 0.4725 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.4992 - binary_crossentropy: 0.4992\n",
      "Epoch 16: val_loss did not improve from 0.47243\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4991 - binary_crossentropy: 0.4991 - val_loss: 0.4726 - val_binary_crossentropy: 0.4726 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.5019 - binary_crossentropy: 0.5019\n",
      "Epoch 17: val_loss improved from 0.47243 to 0.46854, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5023 - binary_crossentropy: 0.5023 - val_loss: 0.4685 - val_binary_crossentropy: 0.4685 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.4960 - binary_crossentropy: 0.4960\n",
      "Epoch 18: val_loss improved from 0.46854 to 0.46849, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4948 - binary_crossentropy: 0.4948 - val_loss: 0.4685 - val_binary_crossentropy: 0.4685 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.4967 - binary_crossentropy: 0.4967\n",
      "Epoch 19: val_loss did not improve from 0.46849\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4961 - binary_crossentropy: 0.4961 - val_loss: 0.4689 - val_binary_crossentropy: 0.4689 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4947 - binary_crossentropy: 0.4947\n",
      "Epoch 20: val_loss improved from 0.46849 to 0.46702, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4928 - binary_crossentropy: 0.4928 - val_loss: 0.4670 - val_binary_crossentropy: 0.4670 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.4962 - binary_crossentropy: 0.4962\n",
      "Epoch 21: val_loss did not improve from 0.46702\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4958 - binary_crossentropy: 0.4958 - val_loss: 0.4676 - val_binary_crossentropy: 0.4676 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4951 - binary_crossentropy: 0.4951\n",
      "Epoch 22: val_loss did not improve from 0.46702\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4951 - binary_crossentropy: 0.4951 - val_loss: 0.4674 - val_binary_crossentropy: 0.4674 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "287/300 [===========================>..] - ETA: 0s - loss: 0.4886 - binary_crossentropy: 0.4886\n",
      "Epoch 23: val_loss improved from 0.46702 to 0.46579, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4896 - binary_crossentropy: 0.4896 - val_loss: 0.4658 - val_binary_crossentropy: 0.4658 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.5020 - binary_crossentropy: 0.5020\n",
      "Epoch 24: val_loss did not improve from 0.46579\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4986 - binary_crossentropy: 0.4986 - val_loss: 0.4688 - val_binary_crossentropy: 0.4688 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "298/300 [============================>.] - ETA: 0s - loss: 0.4939 - binary_crossentropy: 0.4939\n",
      "Epoch 25: val_loss did not improve from 0.46579\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4930 - binary_crossentropy: 0.4930 - val_loss: 0.4689 - val_binary_crossentropy: 0.4689 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.4898 - binary_crossentropy: 0.4898\n",
      "Epoch 26: val_loss did not improve from 0.46579\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4922 - binary_crossentropy: 0.4922 - val_loss: 0.4685 - val_binary_crossentropy: 0.4685 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.4967 - binary_crossentropy: 0.4967\n",
      "Epoch 27: val_loss did not improve from 0.46579\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4943 - binary_crossentropy: 0.4943 - val_loss: 0.4680 - val_binary_crossentropy: 0.4680 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.4997 - binary_crossentropy: 0.4997\n",
      "Epoch 28: val_loss did not improve from 0.46579\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4992 - binary_crossentropy: 0.4992 - val_loss: 0.4670 - val_binary_crossentropy: 0.4670 - lr: 0.0010\n",
      "Epoch 28: early stopping\n",
      "INFO:tensorflow:Assets written to: ram://e06ac976-7bfb-47c4-8dd5-70d24d694e9b/assets\n",
      "75/75 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[accuracy] tr: 0.78, va: 0.775000\n",
      "-------------------- result --------------------\n",
      "-------------------- 4 --------------------\n",
      "(2400, 8) (2400, 1)\n",
      "(600, 8) (600, 1)\n",
      "y_train:0.239, y_tr:0.239, y_va0.238\n",
      "Epoch 1/1000\n",
      "280/300 [===========================>..] - ETA: 0s - loss: 0.6478 - binary_crossentropy: 0.6478\n",
      "Epoch 1: val_loss improved from inf to 0.55715, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.6457 - binary_crossentropy: 0.6457 - val_loss: 0.5572 - val_binary_crossentropy: 0.5572 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.5572 - binary_crossentropy: 0.5572\n",
      "Epoch 2: val_loss improved from 0.55715 to 0.53072, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5558 - binary_crossentropy: 0.5558 - val_loss: 0.5307 - val_binary_crossentropy: 0.5307 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.5433 - binary_crossentropy: 0.5433\n",
      "Epoch 3: val_loss improved from 0.53072 to 0.52643, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5444 - binary_crossentropy: 0.5444 - val_loss: 0.5264 - val_binary_crossentropy: 0.5264 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.5209 - binary_crossentropy: 0.5209\n",
      "Epoch 4: val_loss improved from 0.52643 to 0.52314, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5199 - binary_crossentropy: 0.5199 - val_loss: 0.5231 - val_binary_crossentropy: 0.5231 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.5236 - binary_crossentropy: 0.5236\n",
      "Epoch 5: val_loss improved from 0.52314 to 0.52104, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5230 - binary_crossentropy: 0.5230 - val_loss: 0.5210 - val_binary_crossentropy: 0.5210 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.5149 - binary_crossentropy: 0.5149\n",
      "Epoch 6: val_loss improved from 0.52104 to 0.51918, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5161 - binary_crossentropy: 0.5161 - val_loss: 0.5192 - val_binary_crossentropy: 0.5192 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "289/300 [===========================>..] - ETA: 0s - loss: 0.5107 - binary_crossentropy: 0.5107\n",
      "Epoch 7: val_loss improved from 0.51918 to 0.51830, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5123 - binary_crossentropy: 0.5123 - val_loss: 0.5183 - val_binary_crossentropy: 0.5183 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "283/300 [===========================>..] - ETA: 0s - loss: 0.5171 - binary_crossentropy: 0.5171\n",
      "Epoch 8: val_loss improved from 0.51830 to 0.51604, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5155 - binary_crossentropy: 0.5155 - val_loss: 0.5160 - val_binary_crossentropy: 0.5160 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.5046 - binary_crossentropy: 0.5046\n",
      "Epoch 9: val_loss improved from 0.51604 to 0.51040, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5037 - binary_crossentropy: 0.5037 - val_loss: 0.5104 - val_binary_crossentropy: 0.5104 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.5076 - binary_crossentropy: 0.5076\n",
      "Epoch 10: val_loss improved from 0.51040 to 0.50990, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5072 - binary_crossentropy: 0.5072 - val_loss: 0.5099 - val_binary_crossentropy: 0.5099 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.5073 - binary_crossentropy: 0.5073\n",
      "Epoch 11: val_loss improved from 0.50990 to 0.50761, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5042 - binary_crossentropy: 0.5042 - val_loss: 0.5076 - val_binary_crossentropy: 0.5076 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.5013 - binary_crossentropy: 0.5013\n",
      "Epoch 12: val_loss improved from 0.50761 to 0.50653, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5011 - binary_crossentropy: 0.5011 - val_loss: 0.5065 - val_binary_crossentropy: 0.5065 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.5016 - binary_crossentropy: 0.5016\n",
      "Epoch 13: val_loss did not improve from 0.50653\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5015 - binary_crossentropy: 0.5015 - val_loss: 0.5067 - val_binary_crossentropy: 0.5067 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "282/300 [===========================>..] - ETA: 0s - loss: 0.5028 - binary_crossentropy: 0.5028\n",
      "Epoch 14: val_loss did not improve from 0.50653\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5018 - binary_crossentropy: 0.5018 - val_loss: 0.5072 - val_binary_crossentropy: 0.5072 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "290/300 [============================>.] - ETA: 0s - loss: 0.5041 - binary_crossentropy: 0.5041\n",
      "Epoch 15: val_loss improved from 0.50653 to 0.50432, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5014 - binary_crossentropy: 0.5014 - val_loss: 0.5043 - val_binary_crossentropy: 0.5043 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "284/300 [===========================>..] - ETA: 0s - loss: 0.4954 - binary_crossentropy: 0.4954\n",
      "Epoch 16: val_loss improved from 0.50432 to 0.50326, saving model to model_keras.h5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4931 - binary_crossentropy: 0.4931 - val_loss: 0.5033 - val_binary_crossentropy: 0.5033 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.4875 - binary_crossentropy: 0.4875\n",
      "Epoch 17: val_loss did not improve from 0.50326\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4881 - binary_crossentropy: 0.4881 - val_loss: 0.5038 - val_binary_crossentropy: 0.5038 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "285/300 [===========================>..] - ETA: 0s - loss: 0.4871 - binary_crossentropy: 0.4871\n",
      "Epoch 18: val_loss improved from 0.50326 to 0.50284, saving model to model_keras.h5\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.4894 - binary_crossentropy: 0.4894 - val_loss: 0.5028 - val_binary_crossentropy: 0.5028 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "279/300 [==========================>...] - ETA: 0s - loss: 0.4943 - binary_crossentropy: 0.4943\n",
      "Epoch 19: val_loss improved from 0.50284 to 0.50119, saving model to model_keras.h5\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4938 - binary_crossentropy: 0.4938 - val_loss: 0.5012 - val_binary_crossentropy: 0.5012 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.4903 - binary_crossentropy: 0.4903\n",
      "Epoch 20: val_loss did not improve from 0.50119\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4897 - binary_crossentropy: 0.4897 - val_loss: 0.5014 - val_binary_crossentropy: 0.5014 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "286/300 [===========================>..] - ETA: 0s - loss: 0.4815 - binary_crossentropy: 0.4815\n",
      "Epoch 21: val_loss did not improve from 0.50119\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4856 - binary_crossentropy: 0.4856 - val_loss: 0.5028 - val_binary_crossentropy: 0.5028 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "283/300 [===========================>..] - ETA: 0s - loss: 0.4926 - binary_crossentropy: 0.4926\n",
      "Epoch 22: val_loss did not improve from 0.50119\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4923 - binary_crossentropy: 0.4923 - val_loss: 0.5012 - val_binary_crossentropy: 0.5012 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4905 - binary_crossentropy: 0.4905\n",
      "Epoch 23: val_loss did not improve from 0.50119\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4905 - binary_crossentropy: 0.4905 - val_loss: 0.5026 - val_binary_crossentropy: 0.5026 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.4929 - binary_crossentropy: 0.4929\n",
      "Epoch 24: val_loss did not improve from 0.50119\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4931 - binary_crossentropy: 0.4931 - val_loss: 0.5012 - val_binary_crossentropy: 0.5012 - lr: 0.0010\n",
      "Epoch 24: early stopping\n",
      "INFO:tensorflow:Assets written to: ram://bb9563d0-a84b-442d-9461-822f4a1d102d/assets\n",
      "75/75 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "[accuracy] tr: 0.78, va: 0.771667\n",
      "-------------------- result --------------------\n",
      "[[0.         0.76916667 0.77166667]\n",
      " [1.         0.77083333 0.78      ]\n",
      " [2.         0.77166667 0.765     ]\n",
      " [3.         0.77708333 0.775     ]\n",
      " [4.         0.775      0.77166667]]\n",
      "[cv] tr: 0.77+-0.00, va: 0.77\n",
      "[oof] 0.7727\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "train_oof, metrics = train_nn(X_train, y_train, id_train, list_nfold=[0,1,2,3,4], n_splits=5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "669556ca-f257-450a-8f6b-17ea79cff3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.4109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3832</td>\n",
       "      <td>0.1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4927</td>\n",
       "      <td>0.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   pred\n",
       "0    200 0.4109\n",
       "1   3832 0.1097\n",
       "2   4927  0.385"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oof[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaffb7f-6fa3-431f-bd0a-26028e65a3f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c6f5328-321e-4d4c-b9e3-54e304d25b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_nn(input_x,\n",
    "               input_id,\n",
    "               list_nfold=[0,1,2,3,4],\n",
    "               ):\n",
    "    pred = np.zeros((len(input_x), len(list_nfold)))\n",
    "    for nfold in list_nfold:\n",
    "        print('-'*20, nfold, '-'*20)\n",
    "        fname_nn = 'model/nn/model_nn_fold{}.pickle'.format(nfold)\n",
    "        with open(fname_nn, 'rb')as f:\n",
    "            model = pickle.load(f)\n",
    "        pred[:,nfold] = np.squeeze(model.predict(input_x))\n",
    "        \n",
    "    pred = pd.concat([\n",
    "        input_id,\n",
    "        pd.DataFrame({'pred':pred.mean(axis=1)}),], axis=1)\n",
    "    \n",
    "    print('Done')\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52c0dba4-b4e5-4909-98a9-4e004551adef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "-------------------- 1 --------------------\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "-------------------- 2 --------------------\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "-------------------- 3 --------------------\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "-------------------- 4 --------------------\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "test_pred_proba = predict_nn(X_test,\n",
    "                    id_test,\n",
    "                    list_nfold=[0,1,2,3,4],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c5584d0-f263-4fdf-a668-3baa08295883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>0.2406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3833</td>\n",
       "      <td>0.1395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4836</td>\n",
       "      <td>0.1011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   pred\n",
       "0    398 0.2406\n",
       "1   3833 0.1395\n",
       "2   4836 0.1011"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_proba[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "107ce42c-c7be-4a6d-9cdf-a96ae39d26ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  pred\n",
       "0    398     0\n",
       "1   3833     0\n",
       "2   4836     0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = test_pred_proba.copy()  \n",
    "test_pred['pred']=np.where(test_pred['pred'] < 0.5, 0, 1)\n",
    "test_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce77972c-1165-472e-b3ef-a618d3337493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.4109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3832</td>\n",
       "      <td>0.1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4927</td>\n",
       "      <td>0.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   pred\n",
       "0    200 0.4109\n",
       "1   3832 0.1097\n",
       "2   4927  0.385"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oof[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25b5152f-4db6-4adf-95f5-e6ce25a30cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.to_csv('sub/submission_nn.csv', index=None, header=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92863fdc-93b2-4de1-8c86-bc5de5eef7c5",
   "metadata": {},
   "source": [
    "## アンサンブル用データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c848410-f964-4be3-bcd6-2af32407dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "with open('ensamble/nn_train.pickle', mode='wb') as fo:\n",
    "    pickle.dump(train_oof, fo)\n",
    "    \n",
    "with open('ensamble/nn_test.pickle', mode='wb') as fo:\n",
    "    pickle.dump(test_pred_proba, fo)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d692713-afd8-49ea-ad14-b8521a8744de",
   "metadata": {},
   "source": [
    "## ベースライン検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d92d4c-6746-4881-be65-1672bae19199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証データ:  (2400, 8) (2400, 1)\n",
      "ベースライン検証データ:  (600, 8) (600, 1)\n",
      "検証データ(train):  (1920, 8) (1920, 1)\n",
      "検証データ(test):  (480, 8) (480, 1)\n"
     ]
    }
   ],
   "source": [
    "random_state=123\n",
    "\n",
    "x_tr, x_va2, y_tr, y_va2 = train_test_split(X_train,\n",
    "                                           y_train,\n",
    "                                           test_size=0.2,\n",
    "                                           shuffle=True,\n",
    "                                           stratify=y_train,\n",
    "                                           random_state=random_state)\n",
    "print('検証データ: ',x_tr.shape, y_tr.shape)\n",
    "print('ベースライン検証データ: ',x_va2.shape, y_va2.shape)\n",
    "\n",
    "x_tr1, x_va1, y_tr1, y_va1 = train_test_split(x_tr,\n",
    "                                              y_tr,\n",
    "                                              test_size=0.2,\n",
    "                                              shuffle=True,\n",
    "                                              stratify=y_tr,\n",
    "                                              random_state=random_state)\n",
    "print('検証データ(train): ',x_tr1.shape, y_tr1.shape)\n",
    "print('検証データ(test): ',x_va1.shape, y_va1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8879aee-6be5-4f03-a54e-9e0c18a4514e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.09 , 2.09 , 0.657, ..., 0.657, 2.09 , 0.657], dtype=float16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules import Add_class_wight\n",
    "class_weights = Add_class_wight(y_tr['Outcome'])\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8ab0e25-c221-4477-9610-d177b1a72b44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TabNetPretrainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#validation結果\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pretrainer \u001b[38;5;241m=\u001b[39m \u001b[43mTabNetPretrainer\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m      3\u001b[0m pretrainer\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      4\u001b[0m     X_train\u001b[38;5;241m=\u001b[39mx_tr1,\n\u001b[1;32m      5\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39m[x_va1],\n\u001b[1;32m      6\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m      7\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, virtual_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      8\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m TabNetClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TabNetPretrainer' is not defined"
     ]
    }
   ],
   "source": [
    "#validation結果\n",
    "model = create_model()\n",
    "model.fit(\n",
    "    x=x_tr,\n",
    "    y=y_tr,\n",
    "    validation_data=(x_va, y_va),\n",
    "    batch_size=8,\n",
    "    epochs=1000,\n",
    "    class_weight=None,\n",
    "    callbacks=[ModelCheckpoint(filepath='model_keras.h5',\n",
    "                            moniter='val_loss',\n",
    "                            mode='min', \n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            ),\n",
    "            EarlyStopping(monitor='val_loss',\n",
    "                          mode='min',\n",
    "                          min_delta=0,\n",
    "                          patience=5,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True),\n",
    "            ReduceLROnPlateau(moniter='val_loss',\n",
    "                             mode='min',\n",
    "                             factor=0.1,\n",
    "                             patience=5,\n",
    "                             verbose=1),\n",
    "           ],\n",
    "    verbose=1,\n",
    "    class_weight=class_weight\n",
    "\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "31d4307d-4a67-4228-85a7-140c68b0f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m y_va1_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_va1)\n\u001b[1;32m      3\u001b[0m y_va2_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_va2)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[検証データ] acc: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_va1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_va1_pred\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[ベースライン検証データ] acc: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(accuracy_score(y_va2, y_va2_pred)))\n\u001b[1;32m      7\u001b[0m y_va1_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(x_va1)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "#評価指標の差\n",
    "y_va1_pred = model.predict(x_va1)\n",
    "y_va2_pred = model.predict(x_va2)\n",
    "print('[検証データ] acc: {:.4f}'.format(accuracy_score(y_va1, y_va1_pred)))\n",
    "print('[ベースライン検証データ] acc: {:.4f}'.format(accuracy_score(y_va2, y_va2_pred)))\n",
    "\n",
    "y_va1_pred_proba = model.predict_proba(x_va1)\n",
    "y_va2_pred_proba = model.predict_proba(x_va2)\n",
    "print('[検証データ] auc: {:.4f}'.format(roc_auc_score(y_va1, y_va1_pred_proba[:,1])))\n",
    "print('[ベースライン検証データ] auc: {:.4f}'.format(roc_auc_score(y_va2, y_va2_pred_proba[:,1])))\n",
    "\n",
    "\n",
    "for param in ['loss', 'valid_auc']:\n",
    "    plt.plot(model.history[param], label=param)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b503ae-74e3-4b01-a728-9919ca203629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#誤分類の分布\n",
    "print('検証データ')\n",
    "print(confusion_matrix(y_va1, y_va1_pred))\n",
    "print(confusion_matrix(y_va1, y_va1_pred, normalize='all'))\n",
    "\n",
    "print('ベースライン検証データ')\n",
    "print(confusion_matrix(y_va2, y_va2_pred))\n",
    "print(confusion_matrix(y_va2, y_va2_pred, normalize='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da92e26-8aee-4c0d-983d-d5e7271a59b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測値の分布\n",
    "y_va1_pred_prob = model.predict_proba(x_va1)[:,1]\n",
    "y_va2_pred_prob = model.predict_proba(x_va2)[:,1]\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "fig.add_subplot(2,1,1)\n",
    "plt.title('validation_data')\n",
    "plt.hist(y_va1_pred_prob[np.array(y_va1).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va1_pred_prob[np.array(y_va1).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(2,1,2)\n",
    "plt.title('basreline_validation_data')\n",
    "plt.hist(y_va2_pred_prob[np.array(y_va2).reshape(-1)==1], bins=10, alpha=0.5, label='1')\n",
    "plt.hist(y_va2_pred_prob[np.array(y_va2).reshape(-1)==0], bins=10, alpha=0.5, label='0')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537739d4-699c-4dde-ae15-fe05b29a4163",
   "metadata": {},
   "source": [
    "## チューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c70df6-ccf0-4d7b-87cb-e03980d2e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70364048-9098-4c29-aae7-26d2fc215125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索しないパラメータ\n",
    "\n",
    "params_base = {\n",
    "   'optimizer_fn': torch.optim.Adam,\n",
    "   'optimizer_params': {'lr':2e-2,'weight_decay':1e-5},\n",
    "   'mask_type': \"entmax\",#AttentiveTransformerでマスク作るのにどっちの関数を使うか'sparsemax'or'entmax'\n",
    "   'scheduler_params':{'mode': \"min\",'patience': 5,'min_lr': 1e-5,'factor': 0.9, 'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,},\n",
    "   'verbose':10,\n",
    "   'seed': 123,\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # 探索するパラメータ\n",
    "    params_tuning = {\n",
    "        'n_d': trial.suggest_int('n_d',8,64),\n",
    "        'n_a': trial.suggest_int('n_a',8,64),\n",
    "        'n_steps': trial.suggest_int('n_steps', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n",
    "        'mask_type': trial.suggest_categorical('mask_type', ['entmatx','sparsemax']),\n",
    "    }\n",
    "    params_tuning.update(params_base)\n",
    "    \n",
    "    # モデル学習・評価\n",
    "    list_metrics = []\n",
    "    cv = list(StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state).split(X_train, y_train))\n",
    "    for nfold in np.arange(4):\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = X_train.loc[idx_tr, :], y_train.loc[idx_tr, :]\n",
    "        x_va, y_va = X_train.loc[idx_va, :], y_train.loc[idx_va, :]\n",
    "       \n",
    "        y_va_pred = model.predict_proba(x_va)[:,1]\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>0.5, 1, 0))\n",
    "        list_metrics.append(metric_va)\n",
    "        \n",
    "    # 評価値の計算\n",
    "    metrics = np.mean(list_metrics)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "690a0925-a533-485e-94d9-ac5e95f7fab5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:25:48,430]\u001b[0m A new study created in memory with name: no-name-c35efe1d-ef61-45ef-ad8a-57bab052cf43\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:01s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:07s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:03s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:26:41,692]\u001b[0m Trial 0 finished with value: 0.7656666666666667 and parameters: {'n_d': 47, 'n_a': 24, 'n_step': 3, 'gamma': 1.5513147690828912, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:03s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:06s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:07s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:03s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:27:34,868]\u001b[0m Trial 1 finished with value: 0.7656666666666667 and parameters: {'n_d': 63, 'n_a': 47, 'n_step': 5, 'gamma': 1.3921175181941505, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:03s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:05s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:06s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:07s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:05s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:07s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:08s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:03s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:28:29,472]\u001b[0m Trial 2 finished with value: 0.7656666666666667 and parameters: {'n_d': 32, 'n_a': 11, 'n_step': 4, 'gamma': 1.7379954057320357, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:03s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:05s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:06s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:07s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:29:23,197]\u001b[0m Trial 3 finished with value: 0.7656666666666667 and parameters: {'n_d': 38, 'n_a': 38, 'n_step': 7, 'gamma': 1.8494317940777896, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:06s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:07s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:08s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:05s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:06s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n",
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:30:20,692]\u001b[0m Trial 4 finished with value: 0.7656666666666667 and parameters: {'n_d': 49, 'n_a': 26, 'n_step': 4, 'gamma': 1.2282632308789556, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:07s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:03s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:31:14,682]\u001b[0m Trial 5 finished with value: 0.7656666666666667 and parameters: {'n_d': 13, 'n_a': 32, 'n_step': 5, 'gamma': 1.4936850976503062, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:07s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:08s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:05s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:03s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:32:10,297]\u001b[0m Trial 6 finished with value: 0.7656666666666667 and parameters: {'n_d': 32, 'n_a': 58, 'n_step': 10, 'gamma': 1.5018366758843364, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:01s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:03s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:33:05,604]\u001b[0m Trial 7 finished with value: 0.7656666666666667 and parameters: {'n_d': 26, 'n_a': 31, 'n_step': 9, 'gamma': 1.2504553653965067, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:08s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:03s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:08s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:06s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:02s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:05s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:34:03,700]\u001b[0m Trial 8 finished with value: 0.7656666666666667 and parameters: {'n_d': 37, 'n_a': 42, 'n_step': 2, 'gamma': 1.8263408005068333, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:05s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:08s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:06s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:07s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:08s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n",
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:35:00,323]\u001b[0m Trial 9 finished with value: 0.7656666666666667 and parameters: {'n_d': 27, 'n_a': 25, 'n_step': 5, 'gamma': 1.6813007657927965, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:02s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:05s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n",
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:35:54,823]\u001b[0m Trial 10 finished with value: 0.7656666666666667 and parameters: {'n_d': 56, 'n_a': 8, 'n_step': 1, 'gamma': 1.0080611434040203, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:01s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:06s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:36:49,120]\u001b[0m Trial 11 finished with value: 0.7656666666666667 and parameters: {'n_d': 63, 'n_a': 51, 'n_step': 3, 'gamma': 1.9862890564016848, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:37:44,848]\u001b[0m Trial 12 finished with value: 0.7656666666666667 and parameters: {'n_d': 48, 'n_a': 46, 'n_step': 7, 'gamma': 1.555399472872045, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:05s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:08s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:38:40,678]\u001b[0m Trial 13 finished with value: 0.7656666666666667 and parameters: {'n_d': 64, 'n_a': 19, 'n_step': 7, 'gamma': 1.3631357691972947, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:39:35,045]\u001b[0m Trial 14 finished with value: 0.7656666666666667 and parameters: {'n_d': 49, 'n_a': 59, 'n_step': 3, 'gamma': 1.6071903264160659, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:05s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:01s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:40:30,787]\u001b[0m Trial 15 finished with value: 0.7656666666666667 and parameters: {'n_d': 56, 'n_a': 19, 'n_step': 1, 'gamma': 1.4511497032783554, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:02s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:41:27,051]\u001b[0m Trial 16 finished with value: 0.7656666666666667 and parameters: {'n_d': 44, 'n_a': 49, 'n_step': 6, 'gamma': 1.3844748717398336, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:01s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n",
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:42:21,674]\u001b[0m Trial 17 finished with value: 0.7656666666666667 and parameters: {'n_d': 57, 'n_a': 38, 'n_step': 3, 'gamma': 1.6228321701158495, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:05s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:08s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:06s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:43:17,846]\u001b[0m Trial 18 finished with value: 0.7656666666666667 and parameters: {'n_d': 13, 'n_a': 54, 'n_step': 6, 'gamma': 1.3222958430513911, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:44:12,759]\u001b[0m Trial 19 finished with value: 0.7656666666666667 and parameters: {'n_d': 43, 'n_a': 62, 'n_step': 8, 'gamma': 1.5520330411371615, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:45:08,441]\u001b[0m Trial 20 finished with value: 0.7656666666666667 and parameters: {'n_d': 59, 'n_a': 15, 'n_step': 4, 'gamma': 1.4356061202518677, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:06s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:46:05,297]\u001b[0m Trial 21 finished with value: 0.7656666666666667 and parameters: {'n_d': 21, 'n_a': 8, 'n_step': 4, 'gamma': 1.7069340307634664, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:08s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:01s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:05s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:46:59,923]\u001b[0m Trial 22 finished with value: 0.7656666666666667 and parameters: {'n_d': 29, 'n_a': 14, 'n_step': 2, 'gamma': 1.7163415570713012, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:47:54,900]\u001b[0m Trial 23 finished with value: 0.7656666666666667 and parameters: {'n_d': 20, 'n_a': 25, 'n_step': 5, 'gamma': 1.6119687787895545, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:01s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n",
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:48:50,379]\u001b[0m Trial 24 finished with value: 0.7656666666666667 and parameters: {'n_d': 41, 'n_a': 31, 'n_step': 4, 'gamma': 1.7913032879236999, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:08s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:06s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:05s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:06s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:07s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:49:47,427]\u001b[0m Trial 25 finished with value: 0.7656666666666667 and parameters: {'n_d': 33, 'n_a': 14, 'n_step': 2, 'gamma': 1.494434901957632, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:02s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:04s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:06s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:07s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:09s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:50:44,496]\u001b[0m Trial 26 finished with value: 0.7656666666666667 and parameters: {'n_d': 52, 'n_a': 19, 'n_step': 3, 'gamma': 1.7716585404282987, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:04s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n",
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:51:39,812]\u001b[0m Trial 27 finished with value: 0.7656666666666667 and parameters: {'n_d': 22, 'n_a': 42, 'n_step': 6, 'gamma': 1.6495702502566643, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:04s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:05s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:08s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:01s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:52:36,215]\u001b[0m Trial 28 finished with value: 0.7656666666666667 and parameters: {'n_d': 53, 'n_a': 44, 'n_step': 5, 'gamma': 1.570458959494639, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n",
      "epoch 0  | loss: 110376.18994| val_0_unsup_loss_numpy: 73749.171875|  0:00:00s\n",
      "epoch 10 | loss: 711.68524| val_0_unsup_loss_numpy: 1904.2930908203125|  0:00:01s\n",
      "epoch 20 | loss: 38.57199| val_0_unsup_loss_numpy: 564.6282958984375|  0:00:03s\n",
      "epoch 30 | loss: 33.08686| val_0_unsup_loss_numpy: 261.15325927734375|  0:00:04s\n",
      "epoch 40 | loss: 56.23543| val_0_unsup_loss_numpy: 73.16909790039062|  0:00:06s\n",
      "epoch 50 | loss: 17.6799 | val_0_unsup_loss_numpy: 213.44993591308594|  0:00:07s\n",
      "epoch 60 | loss: 63.28276| val_0_unsup_loss_numpy: 203.166259765625|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 21.714920043945312\n",
      "epoch 0  | loss: 0.65593 | valid_auc: 0.52988 |  0:00:00s\n",
      "epoch 10 | loss: 0.46077 | valid_auc: 0.48522 |  0:00:00s\n",
      "epoch 20 | loss: 0.44638 | valid_auc: 0.6017  |  0:00:01s\n",
      "epoch 30 | loss: 0.42583 | valid_auc: 0.68155 |  0:00:02s\n",
      "epoch 40 | loss: 0.41678 | valid_auc: 0.71286 |  0:00:03s\n",
      "epoch 50 | loss: 0.41089 | valid_auc: 0.73018 |  0:00:04s\n",
      "epoch 60 | loss: 0.40975 | valid_auc: 0.73012 |  0:00:05s\n",
      "epoch 70 | loss: 0.39049 | valid_auc: 0.74623 |  0:00:06s\n",
      "epoch 80 | loss: 0.38759 | valid_auc: 0.74778 |  0:00:06s\n",
      "epoch 90 | loss: 0.37898 | valid_auc: 0.73636 |  0:00:07s\n",
      "epoch 100| loss: 0.37382 | valid_auc: 0.74636 |  0:00:08s\n",
      "epoch 110| loss: 0.3718  | valid_auc: 0.74494 |  0:00:09s\n",
      "epoch 120| loss: 0.35987 | valid_auc: 0.75244 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 122 with best_epoch = 102 and best_valid_auc = 0.75667\n",
      "epoch 0  | loss: 94370.03027| val_0_unsup_loss_numpy: 17508.9921875|  0:00:00s\n",
      "epoch 10 | loss: 50.14755| val_0_unsup_loss_numpy: 386726.625|  0:00:01s\n",
      "epoch 20 | loss: 26.16672| val_0_unsup_loss_numpy: 3018.63134765625|  0:00:03s\n",
      "epoch 30 | loss: 66.98974| val_0_unsup_loss_numpy: 114.78819274902344|  0:00:04s\n",
      "epoch 40 | loss: 21.48916| val_0_unsup_loss_numpy: 5724.16064453125|  0:00:06s\n",
      "epoch 50 | loss: 14.70267| val_0_unsup_loss_numpy: 458.03485107421875|  0:00:07s\n",
      "epoch 60 | loss: 5.83688 | val_0_unsup_loss_numpy: 18.403139114379883|  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_unsup_loss_numpy = 4.336289882659912\n",
      "epoch 0  | loss: 0.61599 | valid_auc: 0.5856  |  0:00:00s\n",
      "epoch 10 | loss: 0.44422 | valid_auc: 0.68138 |  0:00:00s\n",
      "epoch 20 | loss: 0.43285 | valid_auc: 0.68199 |  0:00:01s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_auc = 0.7296\n",
      "epoch 0  | loss: 172606.04688| val_0_unsup_loss_numpy: 443988.1875|  0:00:00s\n",
      "epoch 10 | loss: 302.13637| val_0_unsup_loss_numpy: 122103.421875|  0:00:01s\n",
      "epoch 20 | loss: 50.9832 | val_0_unsup_loss_numpy: 21448.150390625|  0:00:03s\n",
      "epoch 30 | loss: 101.98731| val_0_unsup_loss_numpy: 1743.913330078125|  0:00:04s\n",
      "epoch 40 | loss: 14.66358| val_0_unsup_loss_numpy: 7841.11767578125|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_unsup_loss_numpy = 1078.7030029296875\n",
      "epoch 0  | loss: 0.63946 | valid_auc: 0.49185 |  0:00:00s\n",
      "epoch 10 | loss: 0.45231 | valid_auc: 0.6158  |  0:00:00s\n",
      "epoch 20 | loss: 0.44445 | valid_auc: 0.66228 |  0:00:01s\n",
      "epoch 30 | loss: 0.42855 | valid_auc: 0.6914  |  0:00:02s\n",
      "epoch 40 | loss: 0.41515 | valid_auc: 0.71254 |  0:00:03s\n",
      "epoch 50 | loss: 0.40289 | valid_auc: 0.72965 |  0:00:04s\n",
      "epoch 60 | loss: 0.38184 | valid_auc: 0.7246  |  0:00:05s\n",
      "epoch 70 | loss: 0.3712  | valid_auc: 0.72264 |  0:00:05s\n",
      "epoch 80 | loss: 0.37229 | valid_auc: 0.69919 |  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_valid_auc = 0.73217\n",
      "epoch 0  | loss: 94648.92773| val_0_unsup_loss_numpy: 26948.091796875|  0:00:00s\n",
      "epoch 10 | loss: 66.31772| val_0_unsup_loss_numpy: 398369.0|  0:00:01s\n",
      "epoch 20 | loss: 58.88721| val_0_unsup_loss_numpy: 15123.94921875|  0:00:03s\n",
      "epoch 30 | loss: 253.05495| val_0_unsup_loss_numpy: 10266.33984375|  0:00:04s\n",
      "epoch 40 | loss: 15.11711| val_0_unsup_loss_numpy: 19079.060546875|  0:00:06s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_unsup_loss_numpy = 202.38461303710938\n",
      "epoch 0  | loss: 0.66325 | valid_auc: 0.59274 |  0:00:00s\n",
      "epoch 10 | loss: 0.44115 | valid_auc: 0.64124 |  0:00:00s\n",
      "epoch 20 | loss: 0.43025 | valid_auc: 0.5524  |  0:00:01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-19 14:53:31,376]\u001b[0m Trial 29 finished with value: 0.7656666666666667 and parameters: {'n_d': 39, 'n_a': 23, 'n_step': 4, 'gamma': 1.864792365897348, 'mask_type': 'entmatx'}. Best is trial 0 with value: 0.7656666666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 | loss: 0.42158 | valid_auc: 0.6189  |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_valid_auc = 0.67009\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=random_state)\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd085928-9bb2-45d6-9e3c-bd091e44473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(best)=0.7657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_d': 47,\n",
       " 'n_a': 24,\n",
       " 'n_step': 3,\n",
       " 'gamma': 1.5513147690828912,\n",
       " 'mask_type': 'entmatx'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print('acc(best)={:.4f}'.format(trial.value))\n",
    "display(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b9c69c7-7198-4c8f-92a0-89ce861a6bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_d': 47,\n",
       " 'n_a': 24,\n",
       " 'n_step': 3,\n",
       " 'gamma': 1.5513147690828912,\n",
       " 'mask_type': 'entmax',\n",
       " 'optimizer_fn': torch.optim.adam.Adam,\n",
       " 'optimizer_params': {'lr': 0.02, 'weight_decay': 1e-05},\n",
       " 'scheduler_params': {'mode': 'min',\n",
       "  'patience': 5,\n",
       "  'min_lr': 1e-05,\n",
       "  'factor': 0.9,\n",
       "  'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau},\n",
       " 'verbose': 10,\n",
       " 'seed': 123}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_best = trial.params\n",
    "params_best.update(params_base)\n",
    "display(params_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
